<!DOCTYPE html>
<html lang="zh-cn" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Tensorflow Object Detection API 入门笔记 - 基于 Google Cloud 与 阿里云 | YPLAM</title>
<meta name="keywords" content="MachineLearning, Tensorflow">
<meta name="description" content="跟风关注机器学习已有一段时间，最近需要做一个图像识别的项目，刚好 Google 开源了 Tensorflow Object Detection API ，
于是在此基础上做了一次尝试。本笔记从一名程序员的角度记录一次基于 Tensorflow Object Detection API 的图像物体识别项目过程，项目使用 Google Cloud Machine Learning 进行模型训练，
使用阿里云 GPU 服务器进行模型测试评估。">
<meta name="author" content="">
<link rel="canonical" href="https://yplam.com/posts/machinelearning/tensorflow-object-detection-note/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.8a2a5b863c538395920b4f077c6697be31878d530618647d78daca2883f21ff1.css" integrity="sha256-iipbhjxTg5WSC08HfGaXvjGHjVMGGGR9eNrKKIPyH/E=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://yplam.com/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://yplam.com/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://yplam.com/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://yplam.com/apple-touch-icon.png">
<link rel="mask-icon" href="https://yplam.com/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="zh-cn" href="https://yplam.com/posts/machinelearning/tensorflow-object-detection-note/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
      <script async src="https://www.googletagmanager.com/gtag/js?id=G-960JLZS3KY"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-960JLZS3KY');
        }
      </script><meta property="og:url" content="https://yplam.com/posts/machinelearning/tensorflow-object-detection-note/">
  <meta property="og:site_name" content="YPLAM">
  <meta property="og:title" content="Tensorflow Object Detection API 入门笔记 - 基于 Google Cloud 与 阿里云">
  <meta property="og:description" content="跟风关注机器学习已有一段时间，最近需要做一个图像识别的项目，刚好 Google 开源了 Tensorflow Object Detection API ， 于是在此基础上做了一次尝试。本笔记从一名程序员的角度记录一次基于 Tensorflow Object Detection API 的图像物体识别项目过程，项目使用 Google Cloud Machine Learning 进行模型训练， 使用阿里云 GPU 服务器进行模型测试评估。">
  <meta property="og:locale" content="zh-cn">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2017-10-21T00:00:00+00:00">
    <meta property="article:modified_time" content="2017-10-21T00:00:00+00:00">
    <meta property="article:tag" content="MachineLearning">
    <meta property="article:tag" content="Tensorflow">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Tensorflow Object Detection API 入门笔记 - 基于 Google Cloud 与 阿里云">
<meta name="twitter:description" content="跟风关注机器学习已有一段时间，最近需要做一个图像识别的项目，刚好 Google 开源了 Tensorflow Object Detection API ，
于是在此基础上做了一次尝试。本笔记从一名程序员的角度记录一次基于 Tensorflow Object Detection API 的图像物体识别项目过程，项目使用 Google Cloud Machine Learning 进行模型训练，
使用阿里云 GPU 服务器进行模型测试评估。">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://yplam.com/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Tensorflow Object Detection API 入门笔记 - 基于 Google Cloud 与 阿里云",
      "item": "https://yplam.com/posts/machinelearning/tensorflow-object-detection-note/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Tensorflow Object Detection API 入门笔记 - 基于 Google Cloud 与 阿里云",
  "name": "Tensorflow Object Detection API 入门笔记 - 基于 Google Cloud 与 阿里云",
  "description": "跟风关注机器学习已有一段时间，最近需要做一个图像识别的项目，刚好 Google 开源了 Tensorflow Object Detection API ， 于是在此基础上做了一次尝试。本笔记从一名程序员的角度记录一次基于 Tensorflow Object Detection API 的图像物体识别项目过程，项目使用 Google Cloud Machine Learning 进行模型训练， 使用阿里云 GPU 服务器进行模型测试评估。\n",
  "keywords": [
    "MachineLearning", "Tensorflow"
  ],
  "articleBody": "跟风关注机器学习已有一段时间，最近需要做一个图像识别的项目，刚好 Google 开源了 Tensorflow Object Detection API ， 于是在此基础上做了一次尝试。本笔记从一名程序员的角度记录一次基于 Tensorflow Object Detection API 的图像物体识别项目过程，项目使用 Google Cloud Machine Learning 进行模型训练， 使用阿里云 GPU 服务器进行模型测试评估。\n**目的：**在一批图片中找出包含物体A的图片，并且标出图片中各物体A的位置。\n**环境：**Ubuntu 16.04，python 2.7，virtualenv, tensorflow 1.3, tensorflow-models@d43c736eae267f98061b2cc9aa4f1936e10e2c4e (注：tensorflow models在快速变化中，并且无release版本，如果您按照本文的方式测试出错的话可以尝试checkout这个commit，然后重新生成protobuf)\n过程：\n安装 Tensorflow 与 Tensorflow models 获取与标注图片 生成训练集与测试集 配置、提交 Google Cloud 训练 使用阿里云 GPU 服务器进行测试 安装 CPU 环境下的 Tensorflow 安装非常简单，可以参考官网安装文档，其中 python 版本建议选择 2.7，因为现时（2017年10月） Google Cloud Machine Learning 的命令行对 python3 支持有问题。\nGPU 下的安装稍微复杂，主要是需要解决 NVIDIA 显卡驱动问题，可以参考之前的文章 http://yplam.com/machinelearning/2016/12/12/aws-cuda-tensorflow.html。需要注意的是1.3官方编译版本的Tensorflow使用的是8.0版本的cuda以及6.0版本的cudnn，可以在发布说明页面搜\"CUDA\"找到相关说明。\n如果你需要在阿里云的GPU服务器上使用，可以使用这个Ansible脚本进行快速初始化。\n简要步骤如下：(详细参考https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md)\n# For CPU pip install tensorflow # For GPU pip install tensorflow-gpu apt-get install protobuf-compiler pip install pillow pip install lxml pip install jupyter pip install matplotlib 编译Protobuf\ncd tensorflow/models/research/ protoc object_detection/protos/*.proto --python_out=. 编辑~/.bashrc，将 Object Detection 库加入python（注：请根据你的实际路径设置）\n# From tensorflow/models/research/ export PYTHONPATH=$PYTHONPATH:tensorflow/models/research:tensorflow/models/research/slim 安装完成后可以跑一下下面的 jupyter notebook 测试 research/object_detection/object_detection_tutorial.ipynb\n数据获取与标注 在进行下面步骤前可以先看看官方的这个文档Quick Start: Distributed Training on the Oxford-IIIT Pets Dataset on Google Cloud，下面的内容均是基于官方文档并且根据本项目情况进行修改。\n所谓数据就是用于训练与测试的预标注图片。图片可以是预先准备好的，或者是通过 Scrapy 等爬虫工具获取。图片可能大小不一，下载下来后可以通过下面命令缩小到1000px宽度：\nconvert '*.jpg[1000x]' -set filename:base \"%[base]\" \"1000/%[filename:base].jpg\" 需要注意的是过小的图片可能无法在某些模型中使用。\n然后就到了整个过程中最耗时最无聊的步骤：数据标注（所谓人工智能真的有一大堆人工…）。\n在此使用 labelimg 进行图片标注，安装与使用方法请参考github项目页面。分享一个技巧就是熟记快捷键，如果有多个类别的话可以设定默认label，并且每次只标注一个类别。\n图片标注后会在目标目录生成一个同名的 xml 文件。\n生成训练集与测试集 Tensorflow Object Detection 使用的是 TFRecord 格式的数据，所以需要将上面标注好的图片与xml文件根据模型的数据格式需要打包到一个 TFRecord 文件中。\n首先，我们需要一个 label.pbtxt 文件，标识分类 id 以及 label 的对应关系，如：\nitem { id: 1 name: 'toy' } 然后参考 research/object_detection/create_pet_tf_record.py ，编写自己的 python 脚本生成你的 训练集与测试集 record 文件。\n配置与提交到 Google Cloud 进行模型训练 20171102更新： 突然发现阿里云的GPU竞价实例是个性价比不错的选择，可能是现在用GPU服务器的人不多，竞价实例可以以N分之一的价格拿到，值得一试，还免去科学上网的麻烦。\nTensorflow models 项目页面提供多中模型的配置范例，在此我们使用预训练的 faster_rcnn_resnet101 模型。\n由于需要使用 Google Cloud Machine Learning 服务进行模型训练，所以需要先安装 Google Cloud 相关的客户端，开通 Google Cloud 账号，并且启用 Machine Learning 与 Cloud Storage。可参考下面链接：\nCreate a GCP project. Install the Google Cloud SDK. Enable the ML Engine APIs. Set up a Google Cloud Storage (GCS) bucket. 如果你使用的是ubuntu系统的话这个过程应该还算简单。当然，这还需要你具备“科学上网”技能，以及proxychains等工具的使用。\n将我们前面生成的record文件以及label.pbtxt文件拷贝到Google Cloud Storage，如（请根据实际情况修改）：\n# From tensorflow/models/research/ gsutil cp pet_train.record gs://${YOUR_GCS_BUCKET}/data/pet_train.record gsutil cp pet_val.record gs://${YOUR_GCS_BUCKET}/data/pet_val.record gsutil cp object_detection/data/label.pbtxt gs://${YOUR_GCS_BUCKET}/data/label.pbtxt 下载 COCO-pretrained Faster R-CNN with Resnet-101 模型，解压到 Google Cloud，解压的文件本地也要留一份，后面会用到。\nwget http://storage.googleapis.com/download.tensorflow.org/models/object_detection/faster_rcnn_resnet101_coco_11_06_2017.tar.gz tar -xvf faster_rcnn_resnet101_coco_11_06_2017.tar.gz gsutil cp faster_rcnn_resnet101_coco_11_06_2017/model.ckpt.* gs://${YOUR_GCS_BUCKET}/data/ 参考 faster_rcnn_resnet101_pets.config ，编写我们的config文件，主要是修改 num_classes，fine_tune_checkpoint，input_path，label_map_path，可以先使用本地路径，而不是官方教程中的 “gs://***” 路径，方便本地调试好再发上去正式训练。因为发到 Google Cloud 训练会有个初始化等待过程，并且由于调用的GPU数量较多，如果因为配置文件不符而导致需要不断修改调试，在这过程中可能会浪费比较多的时间跟费用。\n现在，你本地会有以下文件(名字可能不一样)：\n- faster_rcnn_resnet101_pets.config - model.ckpt.index - model.ckpt.meta - model.ckpt.data-00000-of-00001 - label.pbtxt - pet_train.record - pet_val.record 先在本地测试一下是否能正常训练，开始前尽量把不必要的其他应用关掉，因为将耗费 N 多 cpu 与内存资源。\npython object_detection/train.py --train_dir=tmp --pipeline_config_path=${YOUR_CONFIG_FILE}.config 如果能正常进入训练进程，则说明各种配置正常，那么可以将 faster_rcnn_resnet101_pets.config 中的文件路径设为 gs:// 上面路径。然后提交训练（提交前先将本地faster_rcnn_resnet101_pets.config拷贝到gs://${YOUR_GCS_BUCKET}/data）\n# From tensorflow/models/research/ python setup.py sdist (cd slim \u0026\u0026 python setup.py sdist) # From tensorflow/models/research/ gcloud ml-engine jobs submit training `whoami`_object_detection_`date +%s` \\ --job-dir=gs://${YOUR_GCS_BUCKET}/train \\ --packages dist/object_detection-0.1.tar.gz,slim/dist/slim-0.1.tar.gz \\ --module-name object_detection.train \\ --region us-central1 \\ --config object_detection/samples/cloud/cloud.yml \\ -- \\ --train_dir=gs://${YOUR_GCS_BUCKET}/train \\ --pipeline_config_path=gs://${YOUR_GCS_BUCKET}/data/faster_rcnn_resnet101_pets.config 然后可以登录 Google Cloud Console 查看训练进度，需要注意的是费用大概是 $10 一小时，所以如果看到loss降低到一个合适的程度时可以提前停止训练。\n训练后的模型会存储在配置的 –train_dir 中，包含类似下面三个文件：\nmodel.ckpt-${CHECKPOINT_NUMBER}.data-00000-of-00001 model.ckpt-${CHECKPOINT_NUMBER}.index model.ckpt-${CHECKPOINT_NUMBER}.meta 下载下来后可以通过下面命令导出：\npython object_detection/export_inference_graph.py \\ --input_type image_tensor \\ --pipeline_config_path object_detection/samples/configs/faster_rcnn_resnet101_pets.config \\ --trained_checkpoint_prefix model.ckpt-${CHECKPOINT_NUMBER} \\ --output_directory output_inference_graph.pb output_inference_graph.pb 文件就是导出后的模型文件，可以留作后续使用。\n在阿里云上运行训练后的模型 Resnet 101 模型在本地 i5 台式机上跑预测一次时间大概是30秒，而在阿里云最低配的 M40 GPU AWS 上运行一次只需要不到1秒，所以对于大批量的预测任务，配置一台阿里云的GPU服务器来跑是一个不错的选择。现时阿里云 M40 服务器价格为 ￥10 一小时，相对于动辄过万的GPU台式机，还算是个相对便宜的选择(ps: 如果只是用来测试，可以购买阿里云的竞价实例，可以省更多)。\n使用这个Ansible脚本进行快速初始化Tensorflow环境，本脚本在 阿里云M40 GPU AWS、UBUNTU 16.04、cuda 8、tensorflow 1.3 上测试通过。\n参考资料：\nTensorflow Object Detection API Building a Toy Detector with Tensorflow Object Detection API A Brief History of CNNs in Image Segmentation: From R-CNN to Mask R-CNN ",
  "wordCount" : "423",
  "inLanguage": "zh-cn",
  "datePublished": "2017-10-21T00:00:00Z",
  "dateModified": "2017-10-21T00:00:00Z",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://yplam.com/posts/machinelearning/tensorflow-object-detection-note/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "YPLAM",
    "logo": {
      "@type": "ImageObject",
      "url": "https://yplam.com/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <div class="logo-switches">
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://yplam.com/" title="YPLAM">
                    <span>HOME</span>

                </a>
            </li>
            <li>
                <a href="https://yplam.com/about/" title="关于YPLam">
                    <span>ABOUT</span>

                </a>
            </li>
            <li>
                <a href="https://github.com/yplam" title="GITHUB">
                    <span>GITHUB</span>

                </a>
            </li>
            <li>
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Tensorflow Object Detection API 入门笔记 - 基于 Google Cloud 与 阿里云
    </h1>
    <div class="post-meta"><span title='2017-10-21 00:00:00 +0000 UTC'>2017-10-21</span>

</div>
  </header> 
  <div class="post-content"><p>跟风关注机器学习已有一段时间，最近需要做一个图像识别的项目，刚好 Google 开源了 <a href="https://github.com/tensorflow/models/tree/master/research/object_detection">Tensorflow Object Detection API</a> ，
于是在此基础上做了一次尝试。本笔记从一名程序员的角度记录一次基于 Tensorflow Object Detection API 的图像物体识别项目过程，项目使用 Google Cloud Machine Learning 进行模型训练，
使用阿里云 GPU 服务器进行模型测试评估。</p>
<p>**目的：**在一批图片中找出包含物体A的图片，并且标出图片中各物体A的位置。</p>
<p>**环境：**Ubuntu 16.04，python 2.7，virtualenv, tensorflow 1.3, tensorflow-models@d43c736eae267f98061b2cc9aa4f1936e10e2c4e (注：tensorflow models在快速变化中，并且无release版本，如果您按照本文的方式测试出错的话可以尝试checkout这个commit，然后重新生成protobuf)</p>
<p><strong>过程：</strong></p>
<ol>
<li>安装 Tensorflow 与 Tensorflow models</li>
<li>获取与标注图片</li>
<li>生成训练集与测试集</li>
<li>配置、提交 Google Cloud 训练</li>
<li>使用阿里云 GPU 服务器进行测试</li>
</ol>
<h2 id="安装">安装<a hidden class="anchor" aria-hidden="true" href="#安装">#</a></h2>
<p>CPU 环境下的 Tensorflow 安装非常简单，可以参考<a href="https://www.tensorflow.org/install/install_linux">官网安装文档</a>，其中 python 版本建议选择 2.7，因为现时（2017年10月） Google Cloud Machine Learning 的命令行对 python3 支持有问题。</p>
<p>GPU 下的安装稍微复杂，主要是需要解决 NVIDIA 显卡驱动问题，可以参考之前的文章 <a href="http://yplam.com/machinelearning/2016/12/12/aws-cuda-tensorflow.html">http://yplam.com/machinelearning/2016/12/12/aws-cuda-tensorflow.html</a>。需要注意的是1.3官方编译版本的Tensorflow使用的是8.0版本的cuda以及6.0版本的cudnn，可以在<a href="https://github.com/tensorflow/tensorflow/releases">发布说明页面</a>搜&quot;CUDA&quot;找到相关说明。</p>
<p>如果你需要在阿里云的GPU服务器上使用，可以使用<a href="https://github.com/yplam/AliyunTensorflowGPUAnsible">这个Ansible脚本</a>进行快速初始化。</p>
<p>简要步骤如下：(详细参考<a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md">https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md</a>)</p>
<pre tabindex="0"><code># For CPU
pip install tensorflow
# For GPU
pip install tensorflow-gpu

apt-get install protobuf-compiler

pip install pillow
pip install lxml
pip install jupyter
pip install matplotlib
</code></pre><p>编译Protobuf</p>
<pre tabindex="0"><code>cd tensorflow/models/research/
protoc object_detection/protos/*.proto --python_out=.
</code></pre><p>编辑~/.bashrc，将 Object Detection 库加入python（注：请根据你的实际路径设置）</p>
<pre tabindex="0"><code># From tensorflow/models/research/
export PYTHONPATH=$PYTHONPATH:tensorflow/models/research:tensorflow/models/research/slim
</code></pre><p>安装完成后可以跑一下下面的 jupyter notebook 测试 research/object_detection/object_detection_tutorial.ipynb</p>
<h2 id="数据获取与标注">数据获取与标注<a hidden class="anchor" aria-hidden="true" href="#数据获取与标注">#</a></h2>
<p>在进行下面步骤前可以先看看官方的这个文档<a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_pets.md">Quick Start: Distributed Training on the Oxford-IIIT Pets Dataset on Google Cloud</a>，下面的内容均是基于官方文档并且根据本项目情况进行修改。</p>
<p>所谓数据就是用于训练与测试的预标注图片。图片可以是预先准备好的，或者是通过 Scrapy 等爬虫工具获取。图片可能大小不一，下载下来后可以通过下面命令缩小到1000px宽度：</p>
<pre tabindex="0"><code>convert &#39;*.jpg[1000x]&#39; -set filename:base &#34;%[base]&#34; &#34;1000/%[filename:base].jpg&#34;
</code></pre><p>需要注意的是过小的图片可能无法在某些模型中使用。</p>
<p>然后就到了整个过程中最耗时最无聊的步骤：数据标注（所谓人工智能真的有一大堆人工&hellip;）。</p>
<p>在此使用 <a href="https://github.com/tzutalin/labelImg">labelimg</a> 进行图片标注，安装与使用方法请参考github项目页面。分享一个技巧就是熟记快捷键，如果有多个类别的话可以设定默认label，并且每次只标注一个类别。</p>
<p>图片标注后会在目标目录生成一个同名的 xml 文件。</p>
<h2 id="生成训练集与测试集">生成训练集与测试集<a hidden class="anchor" aria-hidden="true" href="#生成训练集与测试集">#</a></h2>
<p>Tensorflow Object Detection 使用的是 TFRecord 格式的数据，所以需要将上面标注好的图片与xml文件根据模型的数据格式需要打包到一个 TFRecord 文件中。</p>
<p>首先，我们需要一个 label.pbtxt 文件，标识分类 id 以及 label 的对应关系，如：</p>
<pre tabindex="0"><code>item {
 id: 1
 name: &#39;toy&#39;
}
</code></pre><p>然后参考 research/object_detection/create_pet_tf_record.py ，编写自己的 python 脚本生成你的 训练集与测试集 record 文件。</p>
<h2 id="配置与提交到-google-cloud-进行模型训练">配置与提交到 Google Cloud 进行模型训练<a hidden class="anchor" aria-hidden="true" href="#配置与提交到-google-cloud-进行模型训练">#</a></h2>
<p><strong>20171102更新：</strong> 突然发现阿里云的GPU竞价实例是个性价比不错的选择，可能是现在用GPU服务器的人不多，竞价实例可以以N分之一的价格拿到，值得一试，还免去科学上网的麻烦。</p>
<p>Tensorflow models 项目页面提供多中模型的<a href="https://github.com/tensorflow/models/tree/master/research/object_detection/samples/configs">配置范例</a>，在此我们使用预训练的 faster_rcnn_resnet101 模型。</p>
<p>由于需要使用 Google Cloud Machine Learning 服务进行模型训练，所以需要先安装 Google Cloud 相关的客户端，开通 Google Cloud 账号，并且启用 Machine Learning 与 Cloud Storage。可参考下面链接：</p>
<ul>
<li><a href="https://cloud.google.com/resource-manager/docs/creating-managing-projects">Create a GCP project.</a></li>
<li><a href="https://cloud.google.com/sdk/downloads">Install the Google Cloud SDK.</a></li>
<li><a href="https://console.cloud.google.com/flows/enableapi?apiid=ml.googleapis.com,compute_component&amp;_ga=1.73374291.1570145678.1496689256">Enable the ML Engine APIs.</a></li>
<li><a href="https://cloud.google.com/storage/docs/creating-buckets">Set up a Google Cloud Storage (GCS) bucket.</a></li>
</ul>
<p>如果你使用的是ubuntu系统的话这个过程应该还算简单。当然，这还需要你具备“科学上网”技能，以及proxychains等工具的使用。</p>
<p>将我们前面生成的record文件以及label.pbtxt文件拷贝到Google Cloud Storage，如（请根据实际情况修改）：</p>
<pre tabindex="0"><code># From tensorflow/models/research/
gsutil cp pet_train.record gs://${YOUR_GCS_BUCKET}/data/pet_train.record
gsutil cp pet_val.record gs://${YOUR_GCS_BUCKET}/data/pet_val.record
gsutil cp object_detection/data/label.pbtxt gs://${YOUR_GCS_BUCKET}/data/label.pbtxt
</code></pre><p>下载 COCO-pretrained Faster R-CNN with Resnet-101 模型，解压到 Google Cloud，解压的文件本地也要留一份，后面会用到。</p>
<pre tabindex="0"><code>wget http://storage.googleapis.com/download.tensorflow.org/models/object_detection/faster_rcnn_resnet101_coco_11_06_2017.tar.gz
tar -xvf faster_rcnn_resnet101_coco_11_06_2017.tar.gz
gsutil cp faster_rcnn_resnet101_coco_11_06_2017/model.ckpt.* gs://${YOUR_GCS_BUCKET}/data/
</code></pre><p>参考 faster_rcnn_resnet101_pets.config ，编写我们的config文件，主要是修改 num_classes，fine_tune_checkpoint，input_path，label_map_path，可以先使用本地路径，而不是官方教程中的 &ldquo;gs://***&rdquo; 路径，方便本地调试好再发上去正式训练。因为发到 Google Cloud 训练会有个初始化等待过程，并且由于调用的GPU数量较多，如果因为配置文件不符而导致需要不断修改调试，在这过程中可能会浪费比较多的时间跟费用。</p>
<p>现在，你本地会有以下文件(名字可能不一样)：</p>
<pre tabindex="0"><code>    - faster_rcnn_resnet101_pets.config
    - model.ckpt.index
    - model.ckpt.meta
    - model.ckpt.data-00000-of-00001
    - label.pbtxt
    - pet_train.record
    - pet_val.record
</code></pre><p>先在本地测试一下是否能正常训练，开始前尽量把不必要的其他应用关掉，因为将耗费 N 多 cpu 与内存资源。</p>
<pre tabindex="0"><code>python object_detection/train.py --train_dir=tmp --pipeline_config_path=${YOUR_CONFIG_FILE}.config
</code></pre><p>如果能正常进入训练进程，则说明各种配置正常，那么可以将 faster_rcnn_resnet101_pets.config 中的文件路径设为 gs:// 上面路径。然后提交训练（提交前先将本地faster_rcnn_resnet101_pets.config拷贝到gs://${YOUR_GCS_BUCKET}/data）</p>
<pre tabindex="0"><code>
# From tensorflow/models/research/
python setup.py sdist
(cd slim &amp;&amp; python setup.py sdist)
</code></pre><pre tabindex="0"><code># From tensorflow/models/research/
gcloud ml-engine jobs submit training `whoami`_object_detection_`date +%s` \
    --job-dir=gs://${YOUR_GCS_BUCKET}/train \
    --packages dist/object_detection-0.1.tar.gz,slim/dist/slim-0.1.tar.gz \
    --module-name object_detection.train \
    --region us-central1 \
    --config object_detection/samples/cloud/cloud.yml \
    -- \
    --train_dir=gs://${YOUR_GCS_BUCKET}/train \
    --pipeline_config_path=gs://${YOUR_GCS_BUCKET}/data/faster_rcnn_resnet101_pets.config
</code></pre><p>然后可以登录 Google Cloud Console 查看训练进度，需要注意的是费用大概是 $10 一小时，所以如果看到loss降低到一个合适的程度时可以提前停止训练。</p>
<p>训练后的模型会存储在配置的 &ndash;train_dir 中，包含类似下面三个文件：</p>
<pre tabindex="0"><code>model.ckpt-${CHECKPOINT_NUMBER}.data-00000-of-00001
model.ckpt-${CHECKPOINT_NUMBER}.index
model.ckpt-${CHECKPOINT_NUMBER}.meta
</code></pre><p>下载下来后可以通过下面命令导出：</p>
<pre tabindex="0"><code>python object_detection/export_inference_graph.py \
    --input_type image_tensor \
    --pipeline_config_path object_detection/samples/configs/faster_rcnn_resnet101_pets.config \
    --trained_checkpoint_prefix model.ckpt-${CHECKPOINT_NUMBER} \
    --output_directory output_inference_graph.pb
    
</code></pre><p>output_inference_graph.pb 文件就是导出后的模型文件，可以留作后续使用。</p>
<h2 id="在阿里云上运行训练后的模型">在阿里云上运行训练后的模型<a hidden class="anchor" aria-hidden="true" href="#在阿里云上运行训练后的模型">#</a></h2>
<p>Resnet 101 模型在本地 i5 台式机上跑预测一次时间大概是30秒，而在阿里云最低配的 M40 GPU AWS 上运行一次只需要不到1秒，所以对于大批量的预测任务，配置一台阿里云的GPU服务器来跑是一个不错的选择。现时阿里云 M40 服务器价格为 ￥10 一小时，相对于动辄过万的GPU台式机，还算是个相对便宜的选择(ps: 如果只是用来测试，可以购买阿里云的竞价实例，可以省更多)。</p>
<p>使用<a href="https://github.com/yplam/AliyunTensorflowGPUAnsible">这个Ansible脚本</a>进行快速初始化Tensorflow环境，本脚本在 阿里云M40 GPU AWS、UBUNTU 16.04、cuda 8、tensorflow 1.3 上测试通过。</p>
<p>参考资料：</p>
<ul>
<li><a href="https://github.com/tensorflow/models/tree/master/research/object_detection">Tensorflow Object Detection API</a></li>
<li><a href="https://medium.com/towards-data-science/building-a-toy-detector-with-tensorflow-object-detection-api-63c0fdf2ac95">Building a Toy Detector with Tensorflow Object Detection API</a></li>
<li><a href="https://blog.athelas.com/a-brief-history-of-cnns-in-image-segmentation-from-r-cnn-to-mask-r-cnn-34ea83205de4">A Brief History of CNNs in Image Segmentation: From R-CNN to Mask R-CNN</a></li>
</ul>

  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://yplam.com/tags/machinelearning/">MachineLearning</a></li>
      <li><a href="https://yplam.com/tags/tensorflow/">Tensorflow</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://yplam.com/">YPLAM</a></span> · 

    <a href="https://creativecommons.org/licenses/by-sa/4.0/">
        CC BY-SA 4.0
    </a>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
