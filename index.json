[{"content":"Flutter 官方最近发布了 GenUI SDK for Flutter , 其理念就是通过 GenUI SDK 作为编排层，将用户与 AI Agent 间的交互从文本转变为丰富的交互式UI。\nGenUI 如何工作？ GenUI 由多个组件组成：\nGenUiConversation： GenUI 的主要交互入口。它包含 GenUiManager 和 ContentGenerator 类，管理对话历史记录，并协调整个生成式 UI 流程。 Catalog： CatalogItem 对象集合，定义了 AI 可以使用的组件集。每个 CatalogItem 都指定一个组件的名称（供 AI 引用）、其属性的数据模式以及用于渲染 Flutter 组件的构建器函数。 DataModel： 一个集中式的、可观察的动态 UI 状态存储。组件绑定到此模型中的数据。当数据更改时，仅重建依赖于该特定数据的组件。 ContentGenerator： 用于与生成式 AI 模型通信的接口。此接口使用流将 A2uiMessage 命令、文本响应和错误发送回 GenUiConversation。 A2uiMessage： AI（通过内容生成器）向 UI 发送的消息，指示 UI 执行诸如 beginRendering、surfaceUpdate、dataModelUpdate 或 deleteSurface 之类的操作。 其基础流程就是，开发者通过 CatalogItem 定义一些 UI 组件，每一个 UI 组件 包含以下主要元素：\nname: CatalogItem 名称，在 json 返回时会用出字段作为 key dataSchema： 通过 json schema 描述的组件状态数据结构 widgetBuilder： 如何基于模型根据 dataSchema 格式返回的数据来渲染组件 可选的 example ContentGenerator 在发送请求到后端 LLM API 时，会将开发者定义的 CatalogItem 列表作为 surfaceUpdate function call 的参数定义，同时发送到后端。LLM 通过 functionCall 的方式调用 surfaceUpdate 来更新、定义 UI 组件以及状态，然后通过 beginRendering 的 functionCall 来触发 GenUiManager 渲染界面。而其中用到的数据结构就是 A2uiMessage。而用户在 UI 界面上的交互也会用 UserMessage 的方式将组件状态数据上报。\n其中的关键是，GenUI SDK 并不仅仅是预定义若干固定的 UI 组件，而是尝试让 LLM 通过组合 UI 组件的方式去生成复杂的用户交互 UI。而其中的挑战是如何通过有限的 System Prompt 来让 LLM 根据需要组合出稳定可用的交互 UI，根据用户的交互确定用户目标。\nGenUI 基础功能测试 GenUI SDK 提供 18 个预定义的 CoreCatalogItems：\nstatic Catalog asCatalog() { return Catalog([ audioPlayer, button, card, checkBox, column, dateTimeInput, divider, icon, image, list, modal, multipleChoice, row, slider, tabs, text, textField, video, ]); } 然而初步测试下来，虽然已经在 System Prompt 上做了不少控制，也难以使用 gemini-2.5-flash 模型生成稳定可用的 UI，特别是 button、textField 等用户交互类组件。因此只使用几个简单的展示类组件，以及自己编写一个代码高亮组件供 GenUI 使用：\nfinal appCatalog = Catalog([ CoreCatalogItems.column, CoreCatalogItems.text, codeCatalogItem, ]); 参考官方教程 Get started with the GenUI SDK for Flutter , 对于国内用户需要实现自己的 GoogleGenerativeServiceInterface 来解决网络问题。目标是在 CycBox 中集成 AI 根据用户需求生成配置文件与 Lua 脚本功能。\nCycBox Chatbot 效果截图：\n总体而言， LLM 基本能理解用户意图生成可交互的组件组合，而由于 GenUiManager 帮忙接管了 UI 渲染，的确使得 AI Agent 的交互编程变得非常简单。\nGenUI SDK 后端 API 请求与响应 最后，通过对 GenUI SDK 接口请求与响应数据的抓包，可以更直观地看到以上交互是如何实现的：\n发送请求，带上组件定义：\n{ \u0026#34;contents\u0026#34;: [ { \u0026#34;parts\u0026#34;: [ { \u0026#34;text\u0026#34;: \u0026#34;You are a CycBox IoT debugging assistant specializing in Lua script generation. SystemPromptRemoved\u0026#34; } ] }, { \u0026#34;parts\u0026#34;: [ { \u0026#34;text\u0026#34;: \u0026#34;Could you help me debug PMS9103M Air Quality Sensor?\u0026#34; } ], \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34; } ], \u0026#34;model\u0026#34;: \u0026#34;models/gemini-2.5-flash\u0026#34;, \u0026#34;toolConfig\u0026#34;: { \u0026#34;functionCallingConfig\u0026#34;: { \u0026#34;allowedFunctionNames\u0026#34;: [ \u0026#34;surfaceUpdate\u0026#34;, \u0026#34;beginRendering\u0026#34;, \u0026#34;provideFinalOutput\u0026#34; ], \u0026#34;mode\u0026#34;: \u0026#34;ANY\u0026#34; } }, \u0026#34;tools\u0026#34;: [ { \u0026#34;functionDeclarations\u0026#34;: [ { \u0026#34;description\u0026#34;: \u0026#34;Updates a surface with a new set of components.\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;surfaceUpdate\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;components\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;A list of component definitions.\u0026#34;, \u0026#34;items\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;Represents a *single* component in a UI widget tree. This component could be one of many supported types.\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;component\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;A wrapper object that MUST contain exactly one key, which is the name of the component type (e.g., \u0026#39;Heading\u0026#39;). The value is an object containing the properties for that specific component.\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;Code\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;code\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;The source code to display\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;STRING\u0026#34; }, \u0026#34;filename\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;Optional filename or description to display as header\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;STRING\u0026#34; }, \u0026#34;language\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;Programming language for syntax highlighting\u0026#34;, \u0026#34;enum\u0026#34;: [ \u0026#34;dart\u0026#34;, \u0026#34;lua\u0026#34;, \u0026#34;yaml\u0026#34;, \u0026#34;javascript\u0026#34;, \u0026#34;python\u0026#34;, \u0026#34;json\u0026#34;, \u0026#34;bash\u0026#34;, \u0026#34;c\u0026#34;, \u0026#34;cpp\u0026#34;, \u0026#34;java\u0026#34;, \u0026#34;rust\u0026#34;, \u0026#34;go\u0026#34; ], \u0026#34;type\u0026#34;: \u0026#34;STRING\u0026#34; } }, \u0026#34;required\u0026#34;: [ \u0026#34;code\u0026#34;, \u0026#34;language\u0026#34; ], \u0026#34;type\u0026#34;: \u0026#34;OBJECT\u0026#34; }, \u0026#34;Column\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;alignment\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;How children are aligned on the cross axis. \u0026#34;, \u0026#34;enum\u0026#34;: [ \u0026#34;start\u0026#34;, \u0026#34;center\u0026#34;, \u0026#34;end\u0026#34;, \u0026#34;stretch\u0026#34;, \u0026#34;baseline\u0026#34; ], \u0026#34;type\u0026#34;: \u0026#34;STRING\u0026#34; }, \u0026#34;children\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;Either an explicit list of widget IDs for the children, or a template with a data binding to the list of children.\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;explicitList\u0026#34;: { \u0026#34;items\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;STRING\u0026#34; }, \u0026#34;type\u0026#34;: \u0026#34;ARRAY\u0026#34; }, \u0026#34;template\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;componentId\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;STRING\u0026#34; }, \u0026#34;dataBinding\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;STRING\u0026#34; } }, \u0026#34;required\u0026#34;: [ \u0026#34;componentId\u0026#34;, \u0026#34;dataBinding\u0026#34; ], \u0026#34;type\u0026#34;: \u0026#34;OBJECT\u0026#34; } }, \u0026#34;type\u0026#34;: \u0026#34;OBJECT\u0026#34; }, \u0026#34;distribution\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;How children are aligned on the main axis. \u0026#34;, \u0026#34;enum\u0026#34;: [ \u0026#34;start\u0026#34;, \u0026#34;center\u0026#34;, \u0026#34;end\u0026#34;, \u0026#34;spaceBetween\u0026#34;, \u0026#34;spaceAround\u0026#34;, \u0026#34;spaceEvenly\u0026#34; ], \u0026#34;type\u0026#34;: \u0026#34;STRING\u0026#34; } }, \u0026#34;type\u0026#34;: \u0026#34;OBJECT\u0026#34; }, \u0026#34;Text\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;text\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;While simple Markdown is supported (without HTML or image references), utilizing dedicated UI components is generally preferred for a richer and more structured presentation.\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;literalString\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;STRING\u0026#34; }, \u0026#34;path\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;A relative or absolute path in the data model.\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;STRING\u0026#34; } }, \u0026#34;type\u0026#34;: \u0026#34;OBJECT\u0026#34; }, \u0026#34;usageHint\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;A usage hint for the base text style.\u0026#34;, \u0026#34;enum\u0026#34;: [ \u0026#34;h1\u0026#34;, \u0026#34;h2\u0026#34;, \u0026#34;h3\u0026#34;, \u0026#34;h4\u0026#34;, \u0026#34;h5\u0026#34;, \u0026#34;caption\u0026#34;, \u0026#34;body\u0026#34; ], \u0026#34;type\u0026#34;: \u0026#34;STRING\u0026#34; } }, \u0026#34;required\u0026#34;: [ \u0026#34;text\u0026#34; ], \u0026#34;type\u0026#34;: \u0026#34;OBJECT\u0026#34; } }, \u0026#34;type\u0026#34;: \u0026#34;OBJECT\u0026#34; }, \u0026#34;id\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;STRING\u0026#34; }, \u0026#34;weight\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;Optional layout weight for use in Row/Column children.\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;INTEGER\u0026#34; } }, \u0026#34;required\u0026#34;: [ \u0026#34;id\u0026#34;, \u0026#34;component\u0026#34; ], \u0026#34;type\u0026#34;: \u0026#34;OBJECT\u0026#34; }, \u0026#34;type\u0026#34;: \u0026#34;ARRAY\u0026#34; }, \u0026#34;surfaceId\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;The unique identifier for the UI surface to create or update. If you are adding a new surface this *must* be a new, unique identified that has never been used for any existing surfaces shown.\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;STRING\u0026#34; } }, \u0026#34;required\u0026#34;: [ \u0026#34;surfaceId\u0026#34;, \u0026#34;components\u0026#34; ], \u0026#34;type\u0026#34;: \u0026#34;OBJECT\u0026#34; } }, { \u0026#34;description\u0026#34;: \u0026#34;Signals the client to begin rendering a surface with a root component.\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;beginRendering\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;root\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;The ID of the root widget. This ID must correspond to the ID of one of the widgets in the `components` list.\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;STRING\u0026#34; }, \u0026#34;surfaceId\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;The unique identifier for the UI surface to render.\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;STRING\u0026#34; } }, \u0026#34;required\u0026#34;: [ \u0026#34;surfaceId\u0026#34;, \u0026#34;root\u0026#34; ], \u0026#34;type\u0026#34;: \u0026#34;OBJECT\u0026#34; } }, { \u0026#34;description\u0026#34;: \u0026#34;Returns the final output. Call this function when you are done with the current turn of the conversation. Do not call this if you need to use other tools first. You MUST call this tool when you are done.\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;provideFinalOutput\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;output\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;response\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;STRING\u0026#34; } }, \u0026#34;type\u0026#34;: \u0026#34;OBJECT\u0026#34; } }, \u0026#34;type\u0026#34;: \u0026#34;OBJECT\u0026#34; } } ] } ] } LLM 返回响应，返回交互信息，实际上就是两个 functionCall， 包括 surfaceUpdate 与 beginRendering ，这个需要在 System Prompt 中详细说明，不然 LLM 可能无法生成正确的 UI 组件结构：\n{ \u0026#34;candidates\u0026#34;: [ { \u0026#34;content\u0026#34;: { \u0026#34;parts\u0026#34;: [ { \u0026#34;functionCall\u0026#34;: { \u0026#34;args\u0026#34;: { \u0026#34;components\u0026#34;: [ { \u0026#34;component\u0026#34;: { \u0026#34;Text\u0026#34;: { \u0026#34;text\u0026#34;: { \u0026#34;literalString\u0026#34;: \u0026#34;I can help you debug your PMS9103M Air Quality Sensor. To get started, please provide the following information:\u0026#34; }, \u0026#34;usageHint\u0026#34;: \u0026#34;h3\u0026#34; } }, \u0026#34;id\u0026#34;: \u0026#34;intro_text\u0026#34; }, { \u0026#34;component\u0026#34;: { \u0026#34;Text\u0026#34;: { \u0026#34;text\u0026#34;: { \u0026#34;literalString\u0026#34;: \u0026#34;1. Do you have the sensor\u0026#39;s datasheet or protocol documentation available? This will help me understand the message structure.\u0026#34; }, \u0026#34;usageHint\u0026#34;: \u0026#34;body\u0026#34; } }, \u0026#34;id\u0026#34;: \u0026#34;question_1\u0026#34; }, { \u0026#34;component\u0026#34;: { \u0026#34;Text\u0026#34;: { \u0026#34;text\u0026#34;: { \u0026#34;literalString\u0026#34;: \u0026#34;2. How is the sensor connected to your system (e.g., Serial, USB-to-Serial, etc.)? What are the serial port parameters (baud rate, data bits, parity, stop bits, flow control)?\u0026#34; }, \u0026#34;usageHint\u0026#34;: \u0026#34;body\u0026#34; } }, \u0026#34;id\u0026#34;: \u0026#34;question_2\u0026#34; }, { \u0026#34;component\u0026#34;: { \u0026#34;Text\u0026#34;: { \u0026#34;text\u0026#34;: { \u0026#34;literalString\u0026#34;: \u0026#34;3. Can you provide any sample raw data (in hexadecimal format, if possible) that the sensor is sending?\u0026#34; }, \u0026#34;usageHint\u0026#34;: \u0026#34;body\u0026#34; } }, \u0026#34;id\u0026#34;: \u0026#34;question_3\u0026#34; }, { \u0026#34;component\u0026#34;: { \u0026#34;Text\u0026#34;: { \u0026#34;text\u0026#34;: { \u0026#34;literalString\u0026#34;: \u0026#34;4. What specific values or measurements do you want to extract from the sensor\u0026#39;s data (e.g., PM1.0, PM2.5, PM10 concentrations)?\u0026#34; }, \u0026#34;usageHint\u0026#34;: \u0026#34;body\u0026#34; } }, \u0026#34;id\u0026#34;: \u0026#34;question_4\u0026#34; }, { \u0026#34;component\u0026#34;: { \u0026#34;Column\u0026#34;: { \u0026#34;children\u0026#34;: { \u0026#34;explicitList\u0026#34;: [ \u0026#34;intro_text\u0026#34;, \u0026#34;question_1\u0026#34;, \u0026#34;question_2\u0026#34;, \u0026#34;question_3\u0026#34;, \u0026#34;question_4\u0026#34; ] } } }, \u0026#34;id\u0026#34;: \u0026#34;main_column\u0026#34; } ], \u0026#34;surfaceId\u0026#34;: \u0026#34;pms9103m_debug\u0026#34; }, \u0026#34;name\u0026#34;: \u0026#34;surfaceUpdate\u0026#34; }, \u0026#34;thoughtSignature\u0026#34;: \u0026#34;removed\u0026#34; }, { \u0026#34;functionCall\u0026#34;: { \u0026#34;args\u0026#34;: { \u0026#34;root\u0026#34;: \u0026#34;main_column\u0026#34;, \u0026#34;surfaceId\u0026#34;: \u0026#34;pms9103m_debug\u0026#34; }, \u0026#34;name\u0026#34;: \u0026#34;beginRendering\u0026#34; } } ], \u0026#34;role\u0026#34;: \u0026#34;model\u0026#34; }, \u0026#34;finishMessage\u0026#34;: \u0026#34;Model generated function call(s).\u0026#34;, \u0026#34;finishReason\u0026#34;: \u0026#34;STOP\u0026#34;, \u0026#34;index\u0026#34;: 0 } ], \u0026#34;modelVersion\u0026#34;: \u0026#34;gemini-2.5-flash\u0026#34;, \u0026#34;responseId\u0026#34;: \u0026#34;B-removed\u0026#34;, \u0026#34;usageMetadata\u0026#34;: { \u0026#34;candidatesTokenCount\u0026#34;: 418, \u0026#34;promptTokenCount\u0026#34;: 5379, \u0026#34;promptTokensDetails\u0026#34;: [ { \u0026#34;modality\u0026#34;: \u0026#34;TEXT\u0026#34;, \u0026#34;tokenCount\u0026#34;: 5379 } ], \u0026#34;thoughtsTokenCount\u0026#34;: 184, \u0026#34;totalTokenCount\u0026#34;: 5981 } } Flutter 更新 UI，然后响应 functionResponse：\n{ \u0026#34;contents\u0026#34;: [ { \u0026#34;parts\u0026#34;: [ { \u0026#34;text\u0026#34;: \u0026#34;You are a CycBox IoT debugging assistant specializing in Lua script generation. SystemPromptRemoved\u0026#34; } ] }, { \u0026#34;parts\u0026#34;: [ { \u0026#34;text\u0026#34;: \u0026#34;Could you help me debug PMS9103M Air Quality Sensor?\u0026#34; } ], \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34; }, { \u0026#34;parts\u0026#34;: [ { \u0026#34;functionCall\u0026#34;: { \u0026#34;args\u0026#34;: { \u0026#34;components\u0026#34;: [ { \u0026#34;component\u0026#34;: { \u0026#34;Text\u0026#34;: { \u0026#34;text\u0026#34;: { \u0026#34;literalString\u0026#34;: \u0026#34;I can help you debug your PMS9103M Air Quality Sensor. To get started, please provide the following information:\u0026#34; }, \u0026#34;usageHint\u0026#34;: \u0026#34;h3\u0026#34; } }, \u0026#34;id\u0026#34;: \u0026#34;intro_text\u0026#34; }, { \u0026#34;component\u0026#34;: { \u0026#34;Text\u0026#34;: { \u0026#34;text\u0026#34;: { \u0026#34;literalString\u0026#34;: \u0026#34;1. Do you have the sensor\u0026#39;s datasheet or protocol documentation available? This will help me understand the message structure.\u0026#34; }, \u0026#34;usageHint\u0026#34;: \u0026#34;body\u0026#34; } }, \u0026#34;id\u0026#34;: \u0026#34;question_1\u0026#34; }, { \u0026#34;component\u0026#34;: { \u0026#34;Text\u0026#34;: { \u0026#34;text\u0026#34;: { \u0026#34;literalString\u0026#34;: \u0026#34;2. How is the sensor connected to your system (e.g., Serial, USB-to-Serial, etc.)? What are the serial port parameters (baud rate, data bits, parity, stop bits, flow control)?\u0026#34; }, \u0026#34;usageHint\u0026#34;: \u0026#34;body\u0026#34; } }, \u0026#34;id\u0026#34;: \u0026#34;question_2\u0026#34; }, { \u0026#34;component\u0026#34;: { \u0026#34;Text\u0026#34;: { \u0026#34;text\u0026#34;: { \u0026#34;literalString\u0026#34;: \u0026#34;3. Can you provide any sample raw data (in hexadecimal format, if possible) that the sensor is sending?\u0026#34; }, \u0026#34;usageHint\u0026#34;: \u0026#34;body\u0026#34; } }, \u0026#34;id\u0026#34;: \u0026#34;question_3\u0026#34; }, { \u0026#34;component\u0026#34;: { \u0026#34;Text\u0026#34;: { \u0026#34;text\u0026#34;: { \u0026#34;literalString\u0026#34;: \u0026#34;4. What specific values or measurements do you want to extract from the sensor\u0026#39;s data (e.g., PM1.0, PM2.5, PM10 concentrations)?\u0026#34; }, \u0026#34;usageHint\u0026#34;: \u0026#34;body\u0026#34; } }, \u0026#34;id\u0026#34;: \u0026#34;question_4\u0026#34; }, { \u0026#34;component\u0026#34;: { \u0026#34;Column\u0026#34;: { \u0026#34;children\u0026#34;: { \u0026#34;explicitList\u0026#34;: [ \u0026#34;intro_text\u0026#34;, \u0026#34;question_1\u0026#34;, \u0026#34;question_2\u0026#34;, \u0026#34;question_3\u0026#34;, \u0026#34;question_4\u0026#34; ] } } }, \u0026#34;id\u0026#34;: \u0026#34;main_column\u0026#34; } ], \u0026#34;surfaceId\u0026#34;: \u0026#34;pms9103m_debug\u0026#34; }, \u0026#34;name\u0026#34;: \u0026#34;surfaceUpdate\u0026#34; }, \u0026#34;thoughtSignature\u0026#34;: \u0026#34;removed\u0026#34; }, { \u0026#34;functionCall\u0026#34;: { \u0026#34;args\u0026#34;: { \u0026#34;root\u0026#34;: \u0026#34;main_column\u0026#34;, \u0026#34;surfaceId\u0026#34;: \u0026#34;pms9103m_debug\u0026#34; }, \u0026#34;name\u0026#34;: \u0026#34;beginRendering\u0026#34; } } ], \u0026#34;role\u0026#34;: \u0026#34;model\u0026#34; }, { \u0026#34;parts\u0026#34;: [ { \u0026#34;functionResponse\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;surfaceUpdate\u0026#34;, \u0026#34;response\u0026#34;: { \u0026#34;status\u0026#34;: \u0026#34;UI Surface pms9103m_debug updated.\u0026#34;, \u0026#34;surfaceId\u0026#34;: \u0026#34;pms9103m_debug\u0026#34; } } }, { \u0026#34;functionResponse\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;beginRendering\u0026#34;, \u0026#34;response\u0026#34;: { \u0026#34;status\u0026#34;: \u0026#34;Surface pms9103m_debug rendered and waiting for user input.\u0026#34; } } } ], \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34; } ], \u0026#34;model\u0026#34;: \u0026#34;models/gemini-2.5-flash\u0026#34;, \u0026#34;toolConfig\u0026#34;: { \u0026#34;functionCallingConfig\u0026#34;: { \u0026#34;allowedFunctionNames\u0026#34;: [ \u0026#34;surfaceUpdate\u0026#34;, \u0026#34;beginRendering\u0026#34;, \u0026#34;provideFinalOutput\u0026#34; ], \u0026#34;mode\u0026#34;: \u0026#34;ANY\u0026#34; } }, \u0026#34;tools\u0026#34;: [ { \u0026#34;functionDeclarations\u0026#34;: [ { \u0026#34;description\u0026#34;: \u0026#34;Updates a surface with a new set of components.\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;surfaceUpdate\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;components\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;A list of component definitions.\u0026#34;, \u0026#34;items\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;Represents a *single* component in a UI widget tree. This component could be one of many supported types.\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;component\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;A wrapper object that MUST contain exactly one key, which is the name of the component type (e.g., \u0026#39;Heading\u0026#39;). The value is an object containing the properties for that specific component.\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;Code\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;code\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;The source code to display\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;STRING\u0026#34; }, \u0026#34;filename\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;Optional filename or description to display as header\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;STRING\u0026#34; }, \u0026#34;language\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;Programming language for syntax highlighting\u0026#34;, \u0026#34;enum\u0026#34;: [ \u0026#34;dart\u0026#34;, \u0026#34;lua\u0026#34;, \u0026#34;yaml\u0026#34;, \u0026#34;javascript\u0026#34;, \u0026#34;python\u0026#34;, \u0026#34;json\u0026#34;, \u0026#34;bash\u0026#34;, \u0026#34;c\u0026#34;, \u0026#34;cpp\u0026#34;, \u0026#34;java\u0026#34;, \u0026#34;rust\u0026#34;, \u0026#34;go\u0026#34; ], \u0026#34;type\u0026#34;: \u0026#34;STRING\u0026#34; } }, \u0026#34;required\u0026#34;: [ \u0026#34;code\u0026#34;, \u0026#34;language\u0026#34; ], \u0026#34;type\u0026#34;: \u0026#34;OBJECT\u0026#34; }, \u0026#34;Column\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;alignment\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;How children are aligned on the cross axis. \u0026#34;, \u0026#34;enum\u0026#34;: [ \u0026#34;start\u0026#34;, \u0026#34;center\u0026#34;, \u0026#34;end\u0026#34;, \u0026#34;stretch\u0026#34;, \u0026#34;baseline\u0026#34; ], \u0026#34;type\u0026#34;: \u0026#34;STRING\u0026#34; }, \u0026#34;children\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;Either an explicit list of widget IDs for the children, or a template with a data binding to the list of children.\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;explicitList\u0026#34;: { \u0026#34;items\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;STRING\u0026#34; }, \u0026#34;type\u0026#34;: \u0026#34;ARRAY\u0026#34; }, \u0026#34;template\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;componentId\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;STRING\u0026#34; }, \u0026#34;dataBinding\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;STRING\u0026#34; } }, \u0026#34;required\u0026#34;: [ \u0026#34;componentId\u0026#34;, \u0026#34;dataBinding\u0026#34; ], \u0026#34;type\u0026#34;: \u0026#34;OBJECT\u0026#34; } }, \u0026#34;type\u0026#34;: \u0026#34;OBJECT\u0026#34; }, \u0026#34;distribution\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;How children are aligned on the main axis. \u0026#34;, \u0026#34;enum\u0026#34;: [ \u0026#34;start\u0026#34;, \u0026#34;center\u0026#34;, \u0026#34;end\u0026#34;, \u0026#34;spaceBetween\u0026#34;, \u0026#34;spaceAround\u0026#34;, \u0026#34;spaceEvenly\u0026#34; ], \u0026#34;type\u0026#34;: \u0026#34;STRING\u0026#34; } }, \u0026#34;type\u0026#34;: \u0026#34;OBJECT\u0026#34; }, \u0026#34;Text\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;text\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;While simple Markdown is supported (without HTML or image references), utilizing dedicated UI components is generally preferred for a richer and more structured presentation.\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;literalString\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;STRING\u0026#34; }, \u0026#34;path\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;A relative or absolute path in the data model.\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;STRING\u0026#34; } }, \u0026#34;type\u0026#34;: \u0026#34;OBJECT\u0026#34; }, \u0026#34;usageHint\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;A usage hint for the base text style.\u0026#34;, \u0026#34;enum\u0026#34;: [ \u0026#34;h1\u0026#34;, \u0026#34;h2\u0026#34;, \u0026#34;h3\u0026#34;, \u0026#34;h4\u0026#34;, \u0026#34;h5\u0026#34;, \u0026#34;caption\u0026#34;, \u0026#34;body\u0026#34; ], \u0026#34;type\u0026#34;: \u0026#34;STRING\u0026#34; } }, \u0026#34;required\u0026#34;: [ \u0026#34;text\u0026#34; ], \u0026#34;type\u0026#34;: \u0026#34;OBJECT\u0026#34; } }, \u0026#34;type\u0026#34;: \u0026#34;OBJECT\u0026#34; }, \u0026#34;id\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;STRING\u0026#34; }, \u0026#34;weight\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;Optional layout weight for use in Row/Column children.\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;INTEGER\u0026#34; } }, \u0026#34;required\u0026#34;: [ \u0026#34;id\u0026#34;, \u0026#34;component\u0026#34; ], \u0026#34;type\u0026#34;: \u0026#34;OBJECT\u0026#34; }, \u0026#34;type\u0026#34;: \u0026#34;ARRAY\u0026#34; }, \u0026#34;surfaceId\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;The unique identifier for the UI surface to create or update. If you are adding a new surface this *must* be a new, unique identified that has never been used for any existing surfaces shown.\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;STRING\u0026#34; } }, \u0026#34;required\u0026#34;: [ \u0026#34;surfaceId\u0026#34;, \u0026#34;components\u0026#34; ], \u0026#34;type\u0026#34;: \u0026#34;OBJECT\u0026#34; } }, { \u0026#34;description\u0026#34;: \u0026#34;Signals the client to begin rendering a surface with a root component.\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;beginRendering\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;root\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;The ID of the root widget. This ID must correspond to the ID of one of the widgets in the `components` list.\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;STRING\u0026#34; }, \u0026#34;surfaceId\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;The unique identifier for the UI surface to render.\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;STRING\u0026#34; } }, \u0026#34;required\u0026#34;: [ \u0026#34;surfaceId\u0026#34;, \u0026#34;root\u0026#34; ], \u0026#34;type\u0026#34;: \u0026#34;OBJECT\u0026#34; } }, { \u0026#34;description\u0026#34;: \u0026#34;Returns the final output. Call this function when you are done with the current turn of the conversation. Do not call this if you need to use other tools first. You MUST call this tool when you are done.\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;provideFinalOutput\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;output\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;response\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;STRING\u0026#34; } }, \u0026#34;type\u0026#34;: \u0026#34;OBJECT\u0026#34; } }, \u0026#34;type\u0026#34;: \u0026#34;OBJECT\u0026#34; } } ] } ] } LLM 在接收到响应后会输出 provideFinalOutput，单个交互过程结束：\n{ \u0026#34;candidates\u0026#34;: [ { \u0026#34;content\u0026#34;: { \u0026#34;parts\u0026#34;: [ { \u0026#34;functionCall\u0026#34;: { \u0026#34;args\u0026#34;: { \u0026#34;output\u0026#34;: { \u0026#34;response\u0026#34;: \u0026#34;I\u0026#39;ve displayed some questions to help me understand your setup. Please provide the requested information so I can generate the appropriate CycBox configuration and Lua script.\u0026#34; } }, \u0026#34;name\u0026#34;: \u0026#34;provideFinalOutput\u0026#34; }, \u0026#34;thoughtSignature\u0026#34;: \u0026#34;\u0026#34; } ], \u0026#34;role\u0026#34;: \u0026#34;model\u0026#34; }, \u0026#34;finishMessage\u0026#34;: \u0026#34;Model generated function call(s).\u0026#34;, \u0026#34;finishReason\u0026#34;: \u0026#34;STOP\u0026#34;, \u0026#34;index\u0026#34;: 0 } ], \u0026#34;modelVersion\u0026#34;: \u0026#34;gemini-2.5-flash\u0026#34;, \u0026#34;responseId\u0026#34;: \u0026#34;removed\u0026#34;, \u0026#34;usageMetadata\u0026#34;: { \u0026#34;candidatesTokenCount\u0026#34;: 49, \u0026#34;promptTokenCount\u0026#34;: 5865, \u0026#34;promptTokensDetails\u0026#34;: [ { \u0026#34;modality\u0026#34;: \u0026#34;TEXT\u0026#34;, \u0026#34;tokenCount\u0026#34;: 5865 } ], \u0026#34;thoughtsTokenCount\u0026#34;: 82, \u0026#34;totalTokenCount\u0026#34;: 5996 } } 用户再次输入，请求：\n{ \u0026#34;contents\u0026#34;: [ { \u0026#34;parts\u0026#34;: [ { \u0026#34;text\u0026#34;: \u0026#34;You are a CycBox IoT debugging assistant specializing in Lua script generation. SystemPromptRemoved\u0026#34; } ] }, { \u0026#34;parts\u0026#34;: [ { \u0026#34;text\u0026#34;: \u0026#34;Could you help me debug PMS9103M Air Quality Sensor?\u0026#34; } ], \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34; }, { \u0026#34;parts\u0026#34;: [ { \u0026#34;text\u0026#34;: \u0026#34;A user interface is shown with the following content:\\n{\\\u0026#34;surfaceId\\\u0026#34;:\\\u0026#34;pms9103m_debug\\\u0026#34;,\\\u0026#34;rootComponentId\\\u0026#34;:\\\u0026#34;main_column\\\u0026#34;,\\\u0026#34;components\\\u0026#34;:{\\\u0026#34;intro_text\\\u0026#34;:{\\\u0026#34;id\\\u0026#34;:\\\u0026#34;intro_text\\\u0026#34;,\\\u0026#34;component\\\u0026#34;:{\\\u0026#34;Text\\\u0026#34;:{\\\u0026#34;text\\\u0026#34;:{\\\u0026#34;literalString\\\u0026#34;:\\\u0026#34;I can help you debug your PMS9103M Air Quality Sensor. To get started, please provide the following information:\\\u0026#34;},\\\u0026#34;usageHint\\\u0026#34;:\\\u0026#34;h3\\\u0026#34;}}},\\\u0026#34;question_1\\\u0026#34;:{\\\u0026#34;id\\\u0026#34;:\\\u0026#34;question_1\\\u0026#34;,\\\u0026#34;component\\\u0026#34;:{\\\u0026#34;Text\\\u0026#34;:{\\\u0026#34;text\\\u0026#34;:{\\\u0026#34;literalString\\\u0026#34;:\\\u0026#34;1. Do you have the sensor\u0026#39;s datasheet or protocol documentation available? This will help me understand the message structure.\\\u0026#34;},\\\u0026#34;usageHint\\\u0026#34;:\\\u0026#34;body\\\u0026#34;}}},\\\u0026#34;question_2\\\u0026#34;:{\\\u0026#34;id\\\u0026#34;:\\\u0026#34;question_2\\\u0026#34;,\\\u0026#34;component\\\u0026#34;:{\\\u0026#34;Text\\\u0026#34;:{\\\u0026#34;usageHint\\\u0026#34;:\\\u0026#34;body\\\u0026#34;,\\\u0026#34;text\\\u0026#34;:{\\\u0026#34;literalString\\\u0026#34;:\\\u0026#34;2. How is the sensor connected to your system (e.g., Serial, USB-to-Serial, etc.)? What are the serial port parameters (baud rate, data bits, parity, stop bits, flow control)?\\\u0026#34;}}}},\\\u0026#34;question_3\\\u0026#34;:{\\\u0026#34;id\\\u0026#34;:\\\u0026#34;question_3\\\u0026#34;,\\\u0026#34;component\\\u0026#34;:{\\\u0026#34;Text\\\u0026#34;:{\\\u0026#34;text\\\u0026#34;:{\\\u0026#34;literalString\\\u0026#34;:\\\u0026#34;3. Can you provide any sample raw data (in hexadecimal format, if possible) that the sensor is sending?\\\u0026#34;},\\\u0026#34;usageHint\\\u0026#34;:\\\u0026#34;body\\\u0026#34;}}},\\\u0026#34;question_4\\\u0026#34;:{\\\u0026#34;id\\\u0026#34;:\\\u0026#34;question_4\\\u0026#34;,\\\u0026#34;component\\\u0026#34;:{\\\u0026#34;Text\\\u0026#34;:{\\\u0026#34;text\\\u0026#34;:{\\\u0026#34;literalString\\\u0026#34;:\\\u0026#34;4. What specific values or measurements do you want to extract from the sensor\u0026#39;s data (e.g., PM1.0, PM2.5, PM10 concentrations)?\\\u0026#34;},\\\u0026#34;usageHint\\\u0026#34;:\\\u0026#34;body\\\u0026#34;}}},\\\u0026#34;main_column\\\u0026#34;:{\\\u0026#34;id\\\u0026#34;:\\\u0026#34;main_column\\\u0026#34;,\\\u0026#34;component\\\u0026#34;:{\\\u0026#34;Column\\\u0026#34;:{\\\u0026#34;children\\\u0026#34;:{\\\u0026#34;explicitList\\\u0026#34;:[\\\u0026#34;intro_text\\\u0026#34;,\\\u0026#34;question_1\\\u0026#34;,\\\u0026#34;question_2\\\u0026#34;,\\\u0026#34;question_3\\\u0026#34;,\\\u0026#34;question_4\\\u0026#34;]}}}}}}.\u0026#34; } ], \u0026#34;role\u0026#34;: \u0026#34;model\u0026#34; }, { \u0026#34;parts\u0026#34;: [ { \u0026#34;text\u0026#34;: \u0026#34;I\u0026#39;ve displayed some questions to help me understand your setup. Please provide the requested information so I can generate the appropriate CycBox configuration and Lua script.\u0026#34; } ], \u0026#34;role\u0026#34;: \u0026#34;model\u0026#34; }, { \u0026#34;parts\u0026#34;: [ { \u0026#34;text\u0026#34;: \u0026#34;The sensor uses a standard UART (Serial) interface with Baud Rate: 9600 bps, Data Bits: 8, Parity: None, Stop Bits: 1, Flow Control: None\\n\\nThe data packet is **32 Bytes** long. The format is Big-Endian (High Byte first).\\n\\n\\n| Byte Index | Value/Description | Note |\\n| :--- | :--- | :--- |\\n| 0 | **0x42** | Start Character 1 (Fixed) |\\n| 1 | **0x4D** | Start Character 2 (Fixed) |\\n| 2 | Frame Length High | Fixed at 0x00 |\\n| 3 | Frame Length Low | Fixed at 0x1C (28 decimal) |\\n| 4 | **PM1.0 (Standard) High** | CF=1, Standard Particle |\\n| 5 | **PM1.0 (Standard) Low** | Unit: μg/m³ |\\n| 6 | **PM2.5 (Standard) High** | CF=1, Standard Particle |\\n| 7 | **PM2.5 (Standard) Low** | Unit: μg/m³ |\\n| 8 | **PM10 (Standard) High** | CF=1, Standard Particle |\\n| 9 | **PM10 (Standard) Low** | Unit: μg/m³ |\\n| 10 | **PM1.0 (Atmospheric) High** | **Use this for Air Quality** |\\n| 11 | **PM1.0 (Atmospheric) Low** | Unit: μg/m³ |\\n| 12 | **PM2.5 (Atmospheric) High** | **Use this for Air Quality** |\\n| 13 | **PM2.5 (Atmospheric) Low** | Unit: μg/m³ |\\n| 14 | **PM10 (Atmospheric) High** | **Use this for Air Quality** |\\n| 15 | **PM10 (Atmospheric) Low** | Unit: μg/m³ |\\n| 16-27 | Particle Counts | \u0026gt;0.3um, \u0026gt;0.5um, \u0026gt;1.0um, \u0026gt;2.5um, \u0026gt;5.0um, \u0026gt;10um |\\n| 28 | Version No. | |\\n| 29 | Error Code | |\\n| 30 | **Checksum High** | |\\n| 31 | **Checksum Low** | |\u0026#34; } ], \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34; } ], \u0026#34;model\u0026#34;: \u0026#34;models/gemini-2.5-flash\u0026#34;, \u0026#34;toolConfig\u0026#34;: { \u0026#34;functionCallingConfig\u0026#34;: { \u0026#34;allowedFunctionNames\u0026#34;: [ \u0026#34;surfaceUpdate\u0026#34;, \u0026#34;beginRendering\u0026#34;, \u0026#34;provideFinalOutput\u0026#34; ], \u0026#34;mode\u0026#34;: \u0026#34;ANY\u0026#34; } }, \u0026#34;tools\u0026#34;: [ { \u0026#34;functionDeclarations\u0026#34;: [ { \u0026#34;description\u0026#34;: \u0026#34;Updates a surface with a new set of components.\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;surfaceUpdate\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;components\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;A list of component definitions.\u0026#34;, \u0026#34;items\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;Represents a *single* component in a UI widget tree. This component could be one of many supported types.\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;component\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;A wrapper object that MUST contain exactly one key, which is the name of the component type (e.g., \u0026#39;Heading\u0026#39;). The value is an object containing the properties for that specific component.\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;Code\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;code\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;The source code to display\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;STRING\u0026#34; }, \u0026#34;filename\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;Optional filename or description to display as header\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;STRING\u0026#34; }, \u0026#34;language\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;Programming language for syntax highlighting\u0026#34;, \u0026#34;enum\u0026#34;: [ \u0026#34;dart\u0026#34;, \u0026#34;lua\u0026#34;, \u0026#34;yaml\u0026#34;, \u0026#34;javascript\u0026#34;, \u0026#34;python\u0026#34;, \u0026#34;json\u0026#34;, \u0026#34;bash\u0026#34;, \u0026#34;c\u0026#34;, \u0026#34;cpp\u0026#34;, \u0026#34;java\u0026#34;, \u0026#34;rust\u0026#34;, \u0026#34;go\u0026#34; ], \u0026#34;type\u0026#34;: \u0026#34;STRING\u0026#34; } }, \u0026#34;required\u0026#34;: [ \u0026#34;code\u0026#34;, \u0026#34;language\u0026#34; ], \u0026#34;type\u0026#34;: \u0026#34;OBJECT\u0026#34; }, \u0026#34;Column\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;alignment\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;How children are aligned on the cross axis. \u0026#34;, \u0026#34;enum\u0026#34;: [ \u0026#34;start\u0026#34;, \u0026#34;center\u0026#34;, \u0026#34;end\u0026#34;, \u0026#34;stretch\u0026#34;, \u0026#34;baseline\u0026#34; ], \u0026#34;type\u0026#34;: \u0026#34;STRING\u0026#34; }, \u0026#34;children\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;Either an explicit list of widget IDs for the children, or a template with a data binding to the list of children.\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;explicitList\u0026#34;: { \u0026#34;items\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;STRING\u0026#34; }, \u0026#34;type\u0026#34;: \u0026#34;ARRAY\u0026#34; }, \u0026#34;template\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;componentId\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;STRING\u0026#34; }, \u0026#34;dataBinding\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;STRING\u0026#34; } }, \u0026#34;required\u0026#34;: [ \u0026#34;componentId\u0026#34;, \u0026#34;dataBinding\u0026#34; ], \u0026#34;type\u0026#34;: \u0026#34;OBJECT\u0026#34; } }, \u0026#34;type\u0026#34;: \u0026#34;OBJECT\u0026#34; }, \u0026#34;distribution\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;How children are aligned on the main axis. \u0026#34;, \u0026#34;enum\u0026#34;: [ \u0026#34;start\u0026#34;, \u0026#34;center\u0026#34;, \u0026#34;end\u0026#34;, \u0026#34;spaceBetween\u0026#34;, \u0026#34;spaceAround\u0026#34;, \u0026#34;spaceEvenly\u0026#34; ], \u0026#34;type\u0026#34;: \u0026#34;STRING\u0026#34; } }, \u0026#34;type\u0026#34;: \u0026#34;OBJECT\u0026#34; }, \u0026#34;Text\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;text\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;While simple Markdown is supported (without HTML or image references), utilizing dedicated UI components is generally preferred for a richer and more structured presentation.\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;literalString\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;STRING\u0026#34; }, \u0026#34;path\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;A relative or absolute path in the data model.\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;STRING\u0026#34; } }, \u0026#34;type\u0026#34;: \u0026#34;OBJECT\u0026#34; }, \u0026#34;usageHint\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;A usage hint for the base text style.\u0026#34;, \u0026#34;enum\u0026#34;: [ \u0026#34;h1\u0026#34;, \u0026#34;h2\u0026#34;, \u0026#34;h3\u0026#34;, \u0026#34;h4\u0026#34;, \u0026#34;h5\u0026#34;, \u0026#34;caption\u0026#34;, \u0026#34;body\u0026#34; ], \u0026#34;type\u0026#34;: \u0026#34;STRING\u0026#34; } }, \u0026#34;required\u0026#34;: [ \u0026#34;text\u0026#34; ], \u0026#34;type\u0026#34;: \u0026#34;OBJECT\u0026#34; } }, \u0026#34;type\u0026#34;: \u0026#34;OBJECT\u0026#34; }, \u0026#34;id\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;STRING\u0026#34; }, \u0026#34;weight\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;Optional layout weight for use in Row/Column children.\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;INTEGER\u0026#34; } }, \u0026#34;required\u0026#34;: [ \u0026#34;id\u0026#34;, \u0026#34;component\u0026#34; ], \u0026#34;type\u0026#34;: \u0026#34;OBJECT\u0026#34; }, \u0026#34;type\u0026#34;: \u0026#34;ARRAY\u0026#34; }, \u0026#34;surfaceId\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;The unique identifier for the UI surface to create or update. If you are adding a new surface this *must* be a new, unique identified that has never been used for any existing surfaces shown.\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;STRING\u0026#34; } }, \u0026#34;required\u0026#34;: [ \u0026#34;surfaceId\u0026#34;, \u0026#34;components\u0026#34; ], \u0026#34;type\u0026#34;: \u0026#34;OBJECT\u0026#34; } }, { \u0026#34;description\u0026#34;: \u0026#34;Signals the client to begin rendering a surface with a root component.\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;beginRendering\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;root\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;The ID of the root widget. This ID must correspond to the ID of one of the widgets in the `components` list.\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;STRING\u0026#34; }, \u0026#34;surfaceId\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;The unique identifier for the UI surface to render.\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;STRING\u0026#34; } }, \u0026#34;required\u0026#34;: [ \u0026#34;surfaceId\u0026#34;, \u0026#34;root\u0026#34; ], \u0026#34;type\u0026#34;: \u0026#34;OBJECT\u0026#34; } }, { \u0026#34;description\u0026#34;: \u0026#34;Returns the final output. Call this function when you are done with the current turn of the conversation. Do not call this if you need to use other tools first. You MUST call this tool when you are done.\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;provideFinalOutput\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;output\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;response\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;STRING\u0026#34; } }, \u0026#34;type\u0026#34;: \u0026#34;OBJECT\u0026#34; } }, \u0026#34;type\u0026#34;: \u0026#34;OBJECT\u0026#34; } } ] } ] } LLM 响应最终结果，包含我们自定义提供的Code组件：\n{ \u0026#34;candidates\u0026#34;: [ { \u0026#34;content\u0026#34;: { \u0026#34;parts\u0026#34;: [ { \u0026#34;functionCall\u0026#34;: { \u0026#34;args\u0026#34;: { \u0026#34;components\u0026#34;: [ { \u0026#34;component\u0026#34;: { \u0026#34;Text\u0026#34;: { \u0026#34;text\u0026#34;: { \u0026#34;literalString\u0026#34;: \u0026#34;Based on the information you provided, here is the CycBox configuration (config.yaml) and the Lua script (pms9103m_parser.lua) to parse the PMS9103M sensor data:\u0026#34; }, \u0026#34;usageHint\u0026#34;: \u0026#34;h3\u0026#34; } }, \u0026#34;id\u0026#34;: \u0026#34;config_intro\u0026#34; }, { \u0026#34;component\u0026#34;: { \u0026#34;Code\u0026#34;: { \u0026#34;code\u0026#34;: \u0026#34;version: \\\u0026#34;1.0\\\u0026#34;\\ngroups:\\n app:\\n app_transport: \\\u0026#34;serial\\\u0026#34;\\n app_codec: \\\u0026#34;frame_codec\\\u0026#34;\\n app_transformer: \\\u0026#34;disable\\\u0026#34;\\n app_lua_script_enabled: true\\n app_encoding: \\\u0026#34;UTF-8\\\u0026#34;\\n serial:\\n serial_requires_codec: true\\n serial_port: \\\u0026#34;/dev/ttyS0\\\u0026#34; # Update if your serial port is different\\n serial_baud_rate: 9600\\n serial_data_bits: 8\\n serial_parity: \\\u0026#34;none\\\u0026#34;\\n serial_stop_bits: \\\u0026#34;1\\\u0026#34;\\n serial_flow_control: \\\u0026#34;none\\\u0026#34;\\n frame_codec:\\n frame_codec_prefix: \\\u0026#34;42 4d\\\u0026#34;\\n frame_codec_header_size: 0\\n frame_codec_length_mode: \\\u0026#34;u16_be\\\u0026#34;\\n frame_codec_length_meaning: \\\u0026#34;payload_checksum\\\u0026#34; # Length value 0x1C (28) covers 26 bytes payload + 2 bytes checksum\\n frame_codec_checksum_algo: \\\u0026#34;sum16_be\\\u0026#34; # Assuming 16-bit big-endian sum, adjust if your datasheet specifies a different algorithm\\n frame_codec_checksum_scope: \\\u0026#34;prefix_header_length_payload\\\u0026#34;\\n frame_codec_tailer_length: 0\\n frame_codec_suffix: \\\u0026#34;\\\u0026#34;\u0026#34;, \u0026#34;filename\u0026#34;: \u0026#34;config.yaml\u0026#34;, \u0026#34;language\u0026#34;: \u0026#34;yaml\u0026#34; } }, \u0026#34;id\u0026#34;: \u0026#34;config_yaml_code\u0026#34; }, { \u0026#34;component\u0026#34;: { \u0026#34;Code\u0026#34;: { \u0026#34;code\u0026#34;: \u0026#34;-- PMS9103M Air Quality Sensor Protocol Parser\\n-- Protocol: 32-byte binary frame with 0x42 0x4D prefix, 2-byte length (0x001C), 26-byte payload, and 2-byte checksum.\\n-- Data format: Big-Endian.\\n\\nfunction on_receive()\\n local payload = message:get_payload()\\n\\n -- Validate payload length. The frame codec strips prefix, length field, and checksum,\\n -- so the Lua payload should be 26 bytes (bytes 4-29 from the raw frame).\\n if #payload ~= 26 then\\n log(\\\u0026#34;warn\\\u0026#34;, string.format(\\\u0026#34;PMS9103M: Expected 26 bytes payload, got %d\\\u0026#34;, #payload))\\n return false\\n end\\n\\n -- Parse Atmospheric PM values (1-indexed offsets relative to the Lua payload)\\n -- Raw frame bytes 10-11 -\u0026gt; Lua payload bytes 7-8\\n local pm1_0_atmospheric = read_u16_be(payload, 7)\\n -- Raw frame bytes 12-13 -\u0026gt; Lua payload bytes 9-10\\n local pm2_5_atmospheric = read_u16_be(payload, 9)\\n -- Raw frame bytes 14-15 -\u0026gt; Lua payload bytes 11-12\\n local pm10_atmospheric = read_u16_be(payload, 11)\\n\\n -- Add values for charting in the UI\\n message:add_int_value(\\\u0026#34;PM1.0 Atmospheric (μg/m³)\\\u0026#34;, pm1_0_atmospheric)\\n message:add_int_value(\\\u0026#34;PM2.5 Atmospheric (μg/m³)\\\u0026#34;, pm2_5_atmospheric)\\n message:add_int_value(\\\u0026#34;PM10 Atmospheric (μg/m³)\\\u0026#34;, pm10_atmospheric)\\n\\n -- Log the parsed values\\n log(\\\u0026#34;info\\\u0026#34;, string.format(\\\u0026#34;PMS9103M: PM1.0 Atmos: %d μg/m³, PM2.5 Atmos: %d μg/m³, PM10 Atmos: %d μg/m³\\\u0026#34;, \\n pm1_0_atmospheric, pm2_5_atmospheric, pm10_atmospheric))\\n\\n return true\\nend\u0026#34;, \u0026#34;filename\u0026#34;: \u0026#34;pms9103m_parser.lua\u0026#34;, \u0026#34;language\u0026#34;: \u0026#34;lua\u0026#34; } }, \u0026#34;id\u0026#34;: \u0026#34;lua_script_code\u0026#34; }, { \u0026#34;component\u0026#34;: { \u0026#34;Column\u0026#34;: { \u0026#34;children\u0026#34;: { \u0026#34;explicitList\u0026#34;: [ \u0026#34;config_intro\u0026#34;, \u0026#34;config_yaml_code\u0026#34;, \u0026#34;lua_script_code\u0026#34; ] } } }, \u0026#34;id\u0026#34;: \u0026#34;main_column\u0026#34; } ], \u0026#34;surfaceId\u0026#34;: \u0026#34;pms9103m_debug_config_script\u0026#34; }, \u0026#34;name\u0026#34;: \u0026#34;surfaceUpdate\u0026#34; }, \u0026#34;thoughtSignature\u0026#34;: \u0026#34;removed\u0026#34; }, { \u0026#34;functionCall\u0026#34;: { \u0026#34;args\u0026#34;: { \u0026#34;root\u0026#34;: \u0026#34;main_column\u0026#34;, \u0026#34;surfaceId\u0026#34;: \u0026#34;pms9103m_debug_config_script\u0026#34; }, \u0026#34;name\u0026#34;: \u0026#34;beginRendering\u0026#34; } } ], \u0026#34;role\u0026#34;: \u0026#34;model\u0026#34; }, \u0026#34;finishMessage\u0026#34;: \u0026#34;Model generated function call(s).\u0026#34;, \u0026#34;finishReason\u0026#34;: \u0026#34;STOP\u0026#34;, \u0026#34;index\u0026#34;: 0 } ], \u0026#34;modelVersion\u0026#34;: \u0026#34;gemini-2.5-flash\u0026#34;, \u0026#34;responseId\u0026#34;: \u0026#34;removed\u0026#34;, \u0026#34;usageMetadata\u0026#34;: { \u0026#34;candidatesTokenCount\u0026#34;: 1143, \u0026#34;promptTokenCount\u0026#34;: 6339, \u0026#34;promptTokensDetails\u0026#34;: [ { \u0026#34;modality\u0026#34;: \u0026#34;TEXT\u0026#34;, \u0026#34;tokenCount\u0026#34;: 6339 } ], \u0026#34;thoughtsTokenCount\u0026#34;: 2541, \u0026#34;totalTokenCount\u0026#34;: 10023 } } ","permalink":"https://yplam.com/posts/machinelearning/flutter-genui/","summary":"\u003cp\u003eFlutter 官方最近发布了 \u003ca href=\"https://docs.flutter.dev/ai/genui\"\u003eGenUI SDK for Flutter\u003c/a\u003e , 其理念就是通过 GenUI SDK 作为编排层，将用户与 AI Agent 间的交互从文本转变为丰富的交互式UI。\u003c/p\u003e","title":"Flutter GenUI 初探"},{"content":"最近买了个 LSM6DSR + LIS3MDLTR 模块准备玩玩九轴IMU，店家提供了个简单的库文件以及英飞凌的例程，因为他的库文件写得不怎么样，以及需要移植到 ESP32，所以决定试试让 AI 根据数据手册编以及官方范例写库文件以及测试例程。其中有个难点就是 LIS3MDLTR 是通过 LSM6DSR 的 Sensor Hub 功能接入。\n测试方法：使用统一的项目模板，统一的提示词，让 AI Agent 完成代码。如果出错则把错误信息反馈到 AI，让 AI 尝试修复。\n硬件 硬件比较简单，ESP32-C3 通过 SPI 连接 LSM6DSR，而模块上 LSM6DSR 通过 I2C 连接 LIS3MDLTR，运行在 SensorHub 模式。\nESP32-C3 \u0026lt;-\u0026gt; LSM6DSR (SPI2):\nSCLK: GPIO8 MISO (SDO): GPIO9 MOSI (SDA/SDI): GPIO10 CS: GPIO4 VDD / VDDIO: 3.3V GND: GND 项目模板 template 项目，包含几个从 idf sdk 拷贝的范例项目，ST 官方提供的 LSM6DSR 驱动库，以及预处理过的两个 Markdown 格式的数据手册。\n├── CMakeLists.txt ├── datasheet │ ├── LIS3MDLTR │ │ ├── 00_Introduction.md │ │ ├── 01_Features.md │ │ ├── 02_Applications.md │ │ ├── 03_Description.md │ │ ├── 04_Contents.md │ │ ├── 05_List_of_tables.md │ │ ├── 06_List_of_figures.md │ │ ├── 07_Block_diagram_and_pin_description.md │ │ ├── 08_Magnetic_and_electrical_specifications.md │ │ ├── 09_Terminology_and_functionality.md │ │ ├── 10_Application_hints.md │ │ ├── 11_Digital_interfaces.md │ │ ├── 12_Register_mapping.md │ │ ├── 13_Registers_description.md │ │ ├── 14_Package_information.md │ │ ├── 15_Revision_history.md │ │ ├── 16_Important_notice.md │ │ └── datasheet │ └── LSM6DSR │ ├── 00_Features.md │ ├── 00_Introduction.md │ ├── 01_Applications.md │ ├── 02_Description.md │ ├── 03_Contents.md │ ├── 04_List_of_tables.md │ ├── 05_List_of_figures.md │ ├── 06_Overview.md │ ├── 07_Embedded_low_power_features.md │ ├── 08_Pin_description.md │ ├── 09_Module_specifications.md │ ├── 10_Digital_interfaces.md │ ├── 11_Functionality.md │ ├── 12_Application_hints.md │ ├── 13_Register_mapping.md │ ├── 14_Register_description.md │ ├── 15_Embedded_functions_register_mapping.md │ ├── 16_Embedded_functions_register_description.md │ ├── 17_Embedded_advanced_features_pages.md │ ├── 18_Embedded_advanced_features_register_description.md │ └── datasheet ├── driver_example │ ├── CONTRIBUTING.md │ ├── LICENSE │ ├── lsm6dsr_reg.c │ ├── lsm6dsr_reg.h │ ├── README.md │ ├── Release_Notes.html │ └── Release_Notes.md ├── examples │ ├── get-started │ │ ├── blink │ │ ├── hello_world │ │ └── README.md │ └── peripherals │ ├── spi_master │ └── usb_serial_jtag └── main ├── CMakeLists.txt └── main.c 提示词 You are an expert embedded systems engineer specializing in sensor integration with the ESP-IDF framework. Your goal is to write a complete and robust driver library for the LSM6DSR IMU sensor for the ESP32-C3, using the ESP-IDF framework. The library must include both basic IMU functionality and the advanced sensor hub feature to read from an external LIS3MDLTR magnetometer. You will also create a comprehensive example application to demonstrate the library\u0026#39;s usage. Communication Interfaces \u0026amp; Pinout a) ESP32-C3 to LSM6DSR (SPI) The primary communication with the LSM6DSR will be via SPI on the HSPI (SPI2) host. * **SCLK:** `GPIO8` * **MISO (SDO):** `GPIO9` * **MOSI (SDA/SDI):** `GPIO10` * **CS (Chip Select):** `GPIO4` b) LSM6DSR to LIS3MDLTR (I2C) The LSM6DSR will act as an I2C master to communicate with the LIS3MDLTR in sensor hub mode. the example application should output sensor values using usb_serial_jtag, and you should disable the default log output of esp-idf. data output in the follow format with configurable frequency: acc_x_value acc_y_value acc_z_value,gyro_x_value gyro_y_value gyro_z_value,mag_x_value mag_y_value mag_z_value\\n ... I will provide you with a basic application template. You need to complete the missing parts. You can find datasheets in datasheet folder, some basic esp-idf examples in examples folder, and some basic driver code in driver_example folder. Claude Code - Sonnet Sonnet 4 能使用 esp-idf 组件的形式实现 lsm6dsr_driver 组件，并实现 esp32 相关的 SPI 接入代码。\nusb_serial_jtag 功能接入失败，后来改成 printf 输出；\nLSM6DSR 加速度，角速度功能能读到数据，初步校验应该正确；LIS3MDLTR 初始化失败，无法读到 ID。\nLIS3MDLTR 初始化失败问题经过多轮交互与调试依然不成功，最后通过提供商家的范例代码，成功定位到是 Sensor hub 寄存器初始化顺序问题，并成功修正。\nCodex - gpt-5-codex-high 能使用 esp-idf 组件的形式实现 lsm6dsr_driver 组件，并实现 esp32 相关的 SPI 接入代码。\nusb_serial_jtag 功能接入失败，后来改成 printf 输出；\nLSM6DSR 加速度，角速度功能能读到数据，但数据明显错误；LIS3MDLTR 初始化失败，无法读到 ID。\n提供商家的范例代码后依然无法读出正确数据，也无法读到 LIS3MDLTR ID。\nGemini - gemini-2.5-pro Claude Code 与 Codex 都是把官方驱动库拷贝到自己的组件内作为库文件，而 Gemini 通过 N 轮修改后，把官方驱动改为一个 driver_example 组件，并作为 lsm6dsr_driver 库的依赖。\nusb_serial_jtag 改成 printf 这个指令竟然都操作错误。\nspi 初始化多轮对话后依然失败。\n","permalink":"https://yplam.com/posts/machinelearning/ai-coding-for-embedded/","summary":"\u003cp\u003e最近买了个 LSM6DSR + LIS3MDLTR 模块准备玩玩九轴IMU，店家提供了个简单的库文件以及英飞凌的例程，因为他的库文件写得不怎么样，以及需要移植到 ESP32，所以决定试试让 AI 根据数据手册编以及官方范例写库文件以及测试例程。其中有个难点就是 LIS3MDLTR 是通过 LSM6DSR 的 Sensor Hub 功能接入。\u003c/p\u003e","title":"嵌入式 AI 编程测试：ESP32C3 LSM6DSR LIS3MDLTR"},{"content":"本文记录使用 musubi-tuner 与 RTX4090 训练 Flux Kontext 人物换脸 Lora 流程。与之前 Flux Lora 训练 不同， Flux Kontext Lora 需要增加多一张参考图片，训练脚本框架也从 sd-scripts 换成了 musubi-tuner。\n工具配置 因为是同一个作者，因此 musubi-tuner 的安装配置与 sd-scripts 类似，使用以下命令：\ngit clone https://github.com/kohya-ss/musubi-tuner.git cd musubi-tuner python3.10 -m venv venv source venv/bin/activate pip install -i https://mirrors.aliyun.com/pypi/simple --extra-index-url https://download.pytorch.org/whl/cu124 --default-timeout=100 -r requirements.txt 配置 accelerate\naccelerate config 启用 numa efficiency, 并且选择 bf16，生成的 ~/.cache/huggingface/accelerate/default_config.yaml 内容\ncompute_environment: LOCAL_MACHINE debug: false distributed_type: \u0026#39;NO\u0026#39; downcast_bf16: \u0026#39;no\u0026#39; enable_cpu_affinity: true gpu_ids: all machine_rank: 0 main_training_function: main mixed_precision: bf16 num_machines: 1 num_processes: 1 rdzv_backend: static same_network: true tpu_env: [] tpu_use_cluster: false tpu_use_sudo: false use_cpu: false 数据集准备 dataset.toml 与 Flux Lora 类似， 但由于 Flux Kontext 需要增加多一张参考图片，因此使用 metadata.jsonl 打 label。\n[general] resolution = [1024, 1024] batch_size = 1 enable_bucket = true bucket_no_upscale = false [[datasets]] image_jsonl_file = \u0026#34;/data/musubi-tuner/data/kontext_face_restoration/dataset_base/metadata.jsonl\u0026#34; cache_directory = \u0026#34;/data/musubi-tuner/data/kontext_face_restoration/cache/dataset_base\u0026#34; num_repeats = 2 flux_kontext_no_resize_control = false [[datasets]] image_jsonl_file = \u0026#34;/data/musubi-tuner/data/kontext_face_restoration/dataset_style/metadata.jsonl\u0026#34; cache_directory = \u0026#34;/data/musubi-tuner/data/kontext_face_restoration/cache/dataset_style\u0026#34; num_repeats = 2 flux_kontext_no_resize_control = false metadata.jsonl 内容如下：\n{\u0026#34;image_path\u0026#34;: \u0026#34;/data/musubi-tuner/data/kontext_face_restoration/dataset_base/14_end.png\u0026#34;, \u0026#34;control_path\u0026#34;: \u0026#34;/data/musubi-tuner/data/kontext_face_restoration/dataset_base/14_start.png\u0026#34;, \u0026#34;caption\u0026#34;: \u0026#34;face restoration\u0026#34;} 其中 image_path 为目标图片，即换脸后的图片，control_path 为参考图片，即换脸工作流的输入图片，caption 为图片描述。\n针对我们的换脸模型，control_path 就是把人脸 A 叠加在人物 B 上的图片，而 image_path 就是人物 A 的换脸后的自然图片。\n为了增加模型稳定性与泛化能力，可以增加不同风格间的换脸数据集，或者人脸朝向角度稍微不同的数据集。\n训练 musubi_tuner 增加了数据预处理过程。\npython src/musubi_tuner/flux_kontext_cache_latents.py --vae /data/models/FLUX.1-Kontext-dev/ae.safetensors --dataset_config /data/musubi-tuner/data/kontext_face_restoration/dataset.toml python src/musubi_tuner/flux_kontext_cache_text_encoder_outputs.py --text_encoder1 /data/models/flux_text_encoders/t5xxl_fp16.safetensors --text_encoder2 /data/models/flux_text_encoders/clip_l.safetensors --batch_size 2 --dataset_config /data/musubi-tuner/data/kontext_face_restoration/dataset.toml accelerate launch --mixed_precision bf16 --num_cpu_threads_per_process 4 src/musubi_tuner/flux_kontext_train_network.py --config_file /data/musubi-tuner/data/kontext_face_restoration/config.toml 在此使用的 config.toml 内容如下：\ndit = \u0026#34;/data/models/FLUX.1-Kontext-dev/flux1-kontext-dev.safetensors\u0026#34; vae = \u0026#34;/data/models/FLUX.1-Kontext-dev/ae.safetensors\u0026#34; text_encoder1 = \u0026#34;/data/models/flux_text_encoders/t5xxl_fp16.safetensors\u0026#34; text_encoder2 = \u0026#34;/data/models/flux_text_encoders/clip_l.safetensors\u0026#34; dataset_config = \u0026#34;/data/musubi-tuner/data/kontext_face_restoration/dataset.toml\u0026#34; output_dir = \u0026#34;/data/musubi-tuner/data/kontext_face_restoration/output\u0026#34; output_name = \u0026#34;face_restoration\u0026#34; save_model_as = \u0026#34;safetensors\u0026#34; sdpa = true mixed_precision = \u0026#34;bf16\u0026#34; save_precision = \u0026#34;bf16\u0026#34; timestep_sampling = \u0026#34;flux_shift\u0026#34; weighting_scheme = \u0026#34;none\u0026#34; optimizer_type = \u0026#34;adamw8bit\u0026#34; learning_rate = 0.0002 gradient_checkpointing = true max_data_loader_n_workers = 2 persistent_data_loader_workers = true network_module = \u0026#34;networks.lora_flux\u0026#34; network_dim = 64 network_alpha = 32 max_train_epochs = 100 save_every_n_epochs = 20 seed = 9527 fp8_base = true fp8_scaled = true ","permalink":"https://yplam.com/posts/machinelearning/flux-kontext-lora-training/","summary":"\u003cp\u003e本文记录使用 musubi-tuner 与 RTX4090 训练 Flux Kontext 人物换脸 Lora 流程。与之前 \u003ca href=\"/posts/machinelearning/flux-lora-training/\"\u003eFlux Lora 训练\u003c/a\u003e 不同， Flux Kontext Lora 需要增加多一张参考图片，训练脚本框架也从 sd-scripts 换成了 musubi-tuner。\u003c/p\u003e","title":"Flux Kontext Lora 训练笔记"},{"content":"在移动端跨平台开发领域，Flutter 凭借其优秀的渲染引擎和开发体验独树一帜。然而，当面临密集型计算、底层系统交互或需要复用现有的 C/C++ 库时，单纯依靠 Dart 往往力不从心。\nFlutter 虽然支持通过 MethodChannel 与原生平台（Android/iOS）通讯，但在处理跨平台通用业务逻辑时，我们更希望有一种“一次编写，到处运行”且性能强劲的方案。本文将介绍一种 Flutter + Rust + Cubit 的高性能应用开发模式：利用 Rust 统一业务逻辑与底层服务，利用 Cubit 桥接 UI 与数据状态。\n官方方案：Flutter + MethodChannel Flutter 官方提供的标准与原生代码交互的方式：MethodChannel。MethodChannel 是 Flutter 端（Dart）与宿主平台端之间的桥梁。 Dart 端发送一个异步消息调用，平台端接收并处理，然后返回结果。由于 Dart 对象与原生对象内存布局不同，数据传输需要经过序列化（Encode）和反序列化（Decode）。Flutter 使用 StandardMessageCodec 支持 JSON 等常见数据类型的转换。\n尽管 MethodChannel 功能强大，但在构建高性能应用时存在问题。同一套业务逻辑（如复杂的加密算法、本地数据库封装），需要分别为 Android 和 iOS 等编写多套代码。频繁的跨语言序列化与反序列化在大数据量传输时会成为性能瓶颈。\nFlutter + Rust + Cubit 为了解决上述问题，我们将架构演进为 Flutter + Rust + Cubit。\n2.1 核心思想 Rust：负责核心业务逻辑、网络请求、文件 IO、密集计算。利用 Rust 的内存安全和零成本抽象，实现真正的逻辑跨平台。 Flutter：只负责 UI 渲染和用户交互，保持轻量级。 Cubit：作为中间层，负责管理 UI 状态，调用 Rust 接口，并响应 Rust 推送的数据变化。 2.2 架构优势 高性能：Rust 编译为机器码，通过 FFI (Foreign Function Interface) 与 Dart 直接内存交互，配合 Rust 的异步模型，可以实现高性能。 代码复用：90% 的非 UI 代码只需用 Rust 编写一次，即可在 Android, iOS, Windows, Linux, macOS 上运行。 响应式流：结合 Dart 的 Stream 和 Rust 的 Channel，形成完美的数据驱动 UI 模式。 状态管理：为什么选择 Cubit？ 在 Flutter 生态中，flutter_bloc 是最流行的状态管理库。它包含两种模式：Bloc 和 Cubit。\nBloc vs Cubit\nBloc (Business Logic Component)：\n基于 Events (事件) 驱动。 流程：UI 添加 Event -\u0026gt; Bloc 处理 Event -\u0026gt; Bloc 发送 State 变更。 优点：可追溯性强，适合极其复杂的逻辑流。 缺点：样板代码多（需定义各种 Event 类），相对繁琐。 Cubit：\n基于 Functions (函数) 驱动。 流程：UI 调用 Cubit 方法 -\u0026gt; Cubit 执行逻辑 -\u0026gt; Cubit 发送 State 变更。 优点：代码简洁，直观，易于理解。 在 Flutter + Rust 模式下，Dart 端的逻辑主要是“转发”：UI 触发操作，Dart 转发给 Rust。Cubit 的函数式调用可以完美契合 FFI 的调用方式（Dart 直接调用 Rust 导出的 C ABI 函数）。我们不需要复杂的 Event 定义，因为真正的复杂逻辑已经被下沉到了 Rust 层。\n实现：FFI 与 Isolate 通讯机制 这是本模式的核心实现细节。UI 通过 Cubit 触发 Rust 操作，Rust 通过 Isolate Port 机制异步通知 UI 更新。\n初始化：Dart 在初始化 Rust 服务时，通过 FFI 传入一个 SendPort.nativePort (int64)。Rust 端将其转换为 Dart_Port 并保存。 UI 交互 (Dart -\u0026gt; Rust)：Cubit 调用 Rust 导出的 FFI 函数。这些函数通常是非阻塞的，或者在 Rust 内部的线程池中运行，仅返回一个简短的 Result（如 \u0026ldquo;RequestAccepted\u0026rdquo;）。 状态更新 (Rust -\u0026gt; Dart)：Rust 业务完成后（或有主动推送时），通过保存的 Port 发送序列化后的数据。 UI 渲染 (Dart Stream -\u0026gt; UI)：Dart 端的 ReceivePort 监听到消息，转换为应用状态，Cubit emit 新状态，UI 重绘。 与 MethodChannel 类似，状态更新也需要一次 Rust 序列化，Dart 反序列化的过程，然而与 MethodChannel 不同的是我们可以根据 State 结构选择更高性能的序列化方式，如 Flatbuffers，Protobuf，Simple SErialization（Flutter Rust Bridge）。更重要的是UI状态更新是一个相对低频的过程，因为就算业务逻辑与状态在高频变化，我们也可以在 Rust 端控制 State 更新频率在 120 fps 以下。\n","permalink":"https://yplam.com/posts/rust/flutter-rust-ffi-cubit/","summary":"\u003cp\u003e在移动端跨平台开发领域，Flutter 凭借其优秀的渲染引擎和开发体验独树一帜。然而，当面临密集型计算、底层系统交互或需要复用现有的 C/C++ 库时，单纯依靠 Dart 往往力不从心。\u003c/p\u003e\n\u003cp\u003eFlutter 虽然支持通过 MethodChannel 与原生平台（Android/iOS）通讯，但在处理跨平台通用业务逻辑时，我们更希望有一种“一次编写，到处运行”且性能强劲的方案。本文将介绍一种 \u003cstrong\u003eFlutter + Rust + Cubit\u003c/strong\u003e 的高性能应用开发模式：利用 Rust 统一业务逻辑与底层服务，利用 Cubit 桥接 UI 与数据状态。\u003c/p\u003e","title":"Flutter + Rust + Cubit：打造高性能跨平台应用"},{"content":"Cursor 是 AI 编程工具，可以自动生成代码，提高编程效率。与其他常用的 IDE 补全工具不同， Cursor 提供更加多样化的功能，同时也需要用户掌握相关使用技巧。\n.cursorrules 通过在 Cursor 中使用规则，你可以控制底层模型的行为。这些规则可以看作是对 LLM（大型语言模型）的指令或系统提示。\nCursor 提供了两种主要方式来自定义 AI 行为以满足你的需求：\n项目规则 项目规则提供了一个强大而灵活的系统，可以针对特定路径进行配置。项目规则存储在 .cursor/rules 目录中，可以对项目不同部分的 AI 行为进行精细控制。\n以下是项目规则的工作原理：\n语义描述：每条规则都可以包含何时应用该规则的描述 文件模式匹配：使用 glob 模式来指定规则适用的文件/文件夹 自动附加：当引用匹配的文件时，规则可以自动包含 引用文件：在项目规则中使用 @file 来包含它们作为规则应用时的上下文 你可以使用 @file 引用规则文件，允许你将多个规则链接在一起 你可以使用命令面板（Cmd + Shift + P \u0026gt; New Cursor Rule）创建新规则。使用项目规则的好处是它只是一个文件，因此可以进行版本控制。\n使用场景示例：\n特定文件类型的框架规则（例如，.tsx 文件的 SolidJS 偏好） 自动生成文件的特殊处理（例如，.proto 文件） 自定义 UI 开发模式 特定文件夹的代码风格和架构偏好 全局规则 全局规则可以通过修改 Cursor 设置 \u0026gt; 通用 \u0026gt; AI 规则部分来添加。如果你想指定在每个项目中都应该包含的规则（如输出语言、响应长度等），这将非常有用。\n可参考 https://cursor.directory/ 获取配置\nComposer Composer 是 Cursor 区别于其他 IDE 的最核心功能。它提供了三种不同的交互模式：\nAgent 模式 (⌘I) 这是默认模式，提供了工具和推理能力来处理复杂的任务。Agent 模式可以理解上下文并执行多步骤的操作。\nEdit 模式 专注于对代码进行精确和清晰的单次编辑。这种模式适合快速修改和重构代码。\nAsk 模式 (⌘L) 用于询问关于代码的问题，获取解释说明，以及探索代码库。这种模式非常适合学习和理解代码。\n这三种模式可以通过模式选择器进行切换，让你能够根据不同的需求选择最合适的交互方式。\n你可以用 @ 符号将文件、目录、代码片段作为上下文引用。也可以用来引用搜索等外部工具。\nCheckpoints 每次迭代都会创建一个检查点。你可以通过点击检查点旁边的 checkout 按钮返回到任何之前的版本。如果你不喜欢当前的更改并想恢复到之前的状态，这个功能会很有用。\n快捷键 ⌘I: 切换到 Agent 模式 ⌘L: 切换到 Ask 模式 ⌘K: 快速提示 完整列表 https://docs.cursor.com/kbd\nMCP 模型上下文协议（MCP）是一个开放协议，它标准化了应用程序如何向 LLM 提供上下文和工具。你可以将 MCP 理解为 Cursor 的插件系统 - 它允许你通过标准化接口将 Agent 连接到各种数据源和工具，从而扩展其功能。\n现时最多允许添加 40 个 tools。\n","permalink":"https://yplam.com/posts/machinelearning/cursor/","summary":"\u003cp\u003eCursor 是 AI 编程工具，可以自动生成代码，提高编程效率。与其他常用的 IDE 补全工具不同， Cursor 提供更加多样化的功能，同时也需要用户掌握相关使用技巧。\u003c/p\u003e","title":"Cursor 使用入门"},{"content":"现时 AI 编程助手可以说是程序员提升效率必备神器，选择一个优秀的编程助手，并且熟练使用，能大大提升开发效率。下面针对市面上评价较高，并且功能相对完善的 AI 编程助手进行评测。\n评测任务 实现一个 AI Chatbot，包括前端 ReactJS 界面与后端 Golang API，前端使用 OpenAI 兼容的接口，后端代理接口请求，根据不同模型调用不同 API 供应商。\n待评测软件 Cursor, Pro 订阅 Github copilot, Pro 订阅 Windsurf, 免费试用版 编程助手功能 代码补全，日常最常用功能，通过 Tab 自动补全代码 Agent 模式，通过对话以及上下文选择，实现项目内大范围的文件修改，命令行操作 基于代码上下文的 Chat，常用于代码REVIEW，代码分析，Bug 查找 代码编辑，选中一段代码，通过提示词进行修改。 下面主要针对 Agent 相关功能进行评测。\n结论 Cursor 效果最优。能在只提供提示词的情况下正确初始化一个可用的 Chatbot 项目。能根据错误提示修改代码，支持两个月前发布的 tailwind 4.0 版本。前端UI直接可用，并且针对对话时间等细节有适当的实现。后端代码结构合理，能使用适当的设计模式。较高的完成度，包括请求后端获取可用模型列表、流式对话输出、前后端合并打包到单个执行文件。\nWindsurf 通过大量错误信息反馈后能生成正确解决 tailwind 4.0 导致的错误，但无法使用 tailwind 4.0 实现正确UI，让其降级到 tailwind 3 后前端UI能正常运行。全局代码分析较差，需要用户正确添加需要修改的文件到上下文。代码质量相对 Cursor 明显较差，并且出现明显功能错误。\nCopilot 由于Agent功能为实验特性，出现多次请求限制。前端项目无法解决 tailwind 4.0 导致的错误。Chat 工具甚至无法正确分辨当前目录，导致命令执行出错。后端代码无法完整生成，大量空文件，为不可用状态。\n以下为各编辑器的测试详情记录\nCursor 评测 前端代码初始化，使用英文提示词，但由于 Cursor 开发环境选择中文，其输出也以中文为主\nInitialize a complete chatbot front-end project in the ui directory. The project is based on vite, reactjs, tailwind css and other popular front-end frameworks and components. Function list: 1. Chatbot uses openai compatible methods to connect to the backend API. 2. You can choose different models 3. Support new conversations and display the history conversation list in the sidebar. The history conversation records are stored locally in the browser 输出结果： 注意：以下完整长图均为 Cursor 操作与输出结果，开发者只进行确认操作，未编写代码\n首次运行出错，因为新版本 tailwind 等前端有非兼容性修改，将错误信息反馈到 Cursor\nCursor 能通过简单的用户操作与提示，生成完整的前端初始项目。开发者交互也很简单，只需要确认其代码修改与命令行执行。\n以上为完成后 UI 界面，可新建对话，记录对话历史。但选择模型与配置功能待完善。\n后端代码初始化，直接使用中文提示词：\n在 api 目录中初始化一个完整的后端 api 项目，项目使用 golang以及相关后端组件，实现与openai兼容的后端接口代理，功能列表： 1. 与openai兼容的后端代理接口 2. 可以根据前端选用不同的模型，将请求代理到不同的api供应商，支持 openai，deepseek，togertherai 3. 针对不同的api供应商请求，可选地配置 http 代理 4. 通过yaml文件配置 输出结果：\n按照提示，后端接口能直接编译运行：\ngo build -o agent-api ./agent-api --config config.yaml 前后端联调 跨域错误修正\n修改后端 config.yaml 以及前端 .env 配置文件，配置使用 openai 与 togetherai 接口，使用 http 代理，支持 gpt-4o， gpt-3.5-turbo， deepseek-ai/DeepSeek-V3 模型。运行，需要解决跨域错误：\n接着完善对话模型选择，流式对话模式，配置项缓存到 localStorage，前端 release 输出嵌入 golang embed fs，修复 release 打包错误， 修复301调整错误（详细对话流程可参考代码目录 .specstory/history/ 下文件），最终结果：\nCursor 总结\n能在只提供提示词的情况下正确初始化一个可用的 Chatbot 功能 能根据错误修正支持最新的前端框架特性 交互与代码逻辑稳定 可以直接在 chat 中执行命令，然后根据命令错误提示信息更新代码 细节：UI 界面针对对话时间的展示处理 细节：后端代码能使用合适的设计模式；包括 Interface 抽象、依赖注入，Factory，Registry Github Copilot 评测 针对 Github Copilot，使用与 Cursor 一致的提示词，使用最新 insider 版本 vs code.\n前端代码初始化，同样使用 Claude 3.7 Sonnet 模型，出现同样错误，但修复流程明显没有 Cursor 那么直接，进行多次交互后能定位到出错信息，但超出模型请求频率，只能暂停使用。\n交互过程如下：\n第二天，等待限制消除 再次将错误信息提交，但重复出现修复A导致B错误，修复B导致A错误的过程，无法成功生成能正确运行的前端项目。\n后端代码初始化，同样使用中文提示词，无法正确生成合理的go项目代码，为不可用状态。\nCopilot总结\nAgent 模式处于试验阶段，模型请求频率限制较大 上下文理解较差，甚至多次无法理解当前工作目录路径 Windsurf 评测 前端代码初始化，同样使用 Claude 3.7 Sonnet 模型，通过大量错误信息反馈后能生成正确运行的前端项目，但无法将 tailwind 4.0 正确配置。\n通过降级到 tailwind 3 后能正常运行UI，配置API，以及进行对话，但无法通过提示词使其正确支持或者切换 Stream 请求模式。\n后端代码初始化，同样使用中文提示词，可生成项目文件，但项目代码结构明显较差，代码啰嗦并且实现错误，未能达到可用标准。譬如：虽然有代理服务器的配置，但最终没有用到配置文件中的代理地址：\n// createClient creates an HTTP client with proxy configuration if provided func createClient(proxyURL string) (*http.Client, error) { client := \u0026amp;http.Client{} if proxyURL != \u0026#34;\u0026#34; { // Set up HTTP client with proxy proxyTransport, err := createProxyTransport(proxyURL) if err != nil { return nil, err } client.Transport = proxyTransport } return client, nil } // createProxyTransport creates a transport with proxy configuration func createProxyTransport(proxyURL string) (*http.Transport, error) { transport := \u0026amp;http.Transport{} if proxyURL != \u0026#34;\u0026#34; { proxyFunc, err := getProxyFunc(proxyURL) if err != nil { return nil, err } transport.Proxy = proxyFunc } return transport, nil } // getProxyFunc returns a proxy function for the given URL func getProxyFunc(proxyURL string) (func(*http.Request) (*http.URL, error), error) { proxy, err := http.ProxyFromEnvironment if err != nil { return nil, err } return proxy, nil } Windsurf 总结\n需要较精确地使用提示词以及选择上下文相关文件 生成的代码质量相对较差，甚至出现明显错误 开发者需要对项目代码功能有清晰理解才能使用 ","permalink":"https://yplam.com/posts/machinelearning/ai-pair-programmer/","summary":"\u003cp\u003e现时 AI 编程助手可以说是程序员提升效率必备神器，选择一个优秀的编程助手，并且熟练使用，能大大提升开发效率。下面针对市面上评价较高，并且功能相对完善的 AI 编程助手进行评测。\u003c/p\u003e","title":"AI 编程助手评测"},{"content":"本文记录使用 sd-scripts 与 RTX4090 训练 Flux Lora 流程。\n工具配置 使用著名的 sd-scripts 脚本进行训练，现时需要 sd3 分支支持，使用以下命令：\ngit clone https://github.com/kohya-ss/sd-scripts.git cd sd-scripts git checkout sd3 python3.10 -m venv venv source venv/bin/activate pip install -i https://mirrors.aliyun.com/pypi/simple --extra-index-url https://download.pytorch.org/whl/cu124 --default-timeout=100 -r requirements.txt # 未兼容新版 torch 2.6 pip install -i https://mirrors.aliyun.com/pypi/simple --extra-index-url https://download.pytorch.org/whl/cu124 --default-timeout=100 triton torch==2.4.0 torchvision==0.19.0 配置 accelerate\naccelerate config 启用 numa efficiency, 并且选择 bf16，生成的 ~/.cache/huggingface/accelerate/default_config.yaml 内容\ncompute_environment: LOCAL_MACHINE debug: false distributed_type: \u0026#39;NO\u0026#39; downcast_bf16: \u0026#39;no\u0026#39; enable_cpu_affinity: true gpu_ids: all machine_rank: 0 main_training_function: main mixed_precision: bf16 num_machines: 1 num_processes: 1 rdzv_backend: static same_network: true tpu_env: [] tpu_use_cluster: false tpu_use_sudo: false use_cpu: false 数据集准备 准备若干 jpg、png 图片，以及同名但后缀为 .txt 的图片内容描述文件，建议使用脚本通过 ChatGPT 4o api 生成，然后配置 dataset.toml\n[[datasets]] enable_bucket = false resolution = [320, 320] bucket_reso_steps = 64 max_bucket_reso = 320 min_bucket_reso = 128 bucket_no_upscale = true batch_size = 1 random_crop = false shuffle_caption = false [[datasets.subsets]] image_dir = \u0026#34;/home/yplam/AI/sd-scripts/data/dataset\u0026#34; num_repeats = 1 caption_extension = \u0026#34;.txt\u0026#34; 训练 需要注意的是训练前需下载对应的模型权重、clip、ae 等，通常如果有用 ComfyUI 等工具则在 models 下可以找到。\n以下参数针对 RTX4090 显卡训练 fp8 lora，显示 VRAM 占用为16GB多\naccelerate launch --mixed_precision bf16 --num_cpu_threads_per_process 1 flux_train_network.py \\ --pretrained_model_name_or_path /home/yplam/AI/sd-scripts/flux1-dev2pro.safetensors \\ --clip_l /home/yplam/AI/ComfyUI-Docker/models/clip/clip_l.safetensors \\ --ae /home/yplam/AI/ComfyUI-Docker/models/vae/ae.safetensors \\ --t5xxl /home/yplam/AI/ComfyUI-Docker/models/clip/t5xxl_fp16.safetensors \\ --dataset_config /home/yplam/AI/sd-scripts/data/dataset.toml \\ --cache_latents_to_disk \\ --save_model_as safetensors \\ --sdpa \\ --persistent_data_loader_workers \\ --max_data_loader_n_workers 2 \\ --seed 42 \\ --gradient_checkpointing \\ --mixed_precision bf16 \\ --save_precision bf16 \\ --network_module networks.lora_flux \\ --network_dim 16 \\ --network_alpha 8 \\ --optimizer_type adamw8bit \\ --learning_rate 5e-5 \\ --lr_scheduler constant_with_warmup \\ --lr_warmup_steps 20 \\ --cache_text_encoder_outputs \\ --cache_text_encoder_outputs_to_disk \\ --fp8_base \\ --max_train_epochs 100 \\ --save_every_n_epochs 10 \\ --output_dir /home/yplam/AI/sd-scripts/data/output \\ --output_name mylora \\ --timestep_sampling shift \\ --discrete_flow_shift 3.1582 \\ --model_prediction_type raw \\ --guidance_scale 1.0 ","permalink":"https://yplam.com/posts/machinelearning/flux-lora-training/","summary":"\u003cp\u003e本文记录使用 sd-scripts 与 RTX4090 训练 Flux Lora 流程。\u003c/p\u003e","title":"Flux Lora 训练笔记"},{"content":"针对常规的网络应用型APP，Flutter + Go 可以很好的兼顾性能与开发效率，而对于某些需要极致控制内存占用，需要与C库进行高效交互的程序，Flutter + Rust 则是另一个可选项。\nFlutter + Rust 最直接的方式可能是使用 Flutter Favorite 的库 flutter_rust_bridge，基于代码模板以及提供多个工具简化整个对接流程。然而，对于一些只需要导出少量 rust 接口的功能，使用 flutter_rust_bridge 未免引入了过多复杂性，而直接使用 dart ffi 反而是一个相对精简的实现。\nRust \u0026lt;-\u0026gt; C 配置 Cargo.toml 输出 C 库\n[package] name = \u0026#34;xxx\u0026#34; version = \u0026#34;0.1.0\u0026#34; edition = \u0026#34;2024\u0026#34; [lib] name = \u0026#34;xxx\u0026#34; crate-type = [\u0026#34;cdylib\u0026#34;, \u0026#34;rlib\u0026#34;] 基于 cbindgen 导出 .h 头文件，创建 cbindgen.toml:\nlanguage = \u0026#34;C\u0026#34; header = \u0026#34;/* Auto-generated by cbindgen */\u0026#34; include_version = true braces = \u0026#34;SameLine\u0026#34; line_length = 100 tab_width = 4 documentation = true documentation_style = \u0026#34;doxy\u0026#34; [export] include = [\u0026#34;xxx\u0026#34;] exclude = [] [fn] rename_args = \u0026#34;GeckoCase\u0026#34; args = \u0026#34;auto\u0026#34; sort_by = \u0026#34;Name\u0026#34; [struct] rename_fields = \u0026#34;ScreamingSnakeCase\u0026#34; must_use = \u0026#34;/*must_use*/\u0026#34; derive_const_casts = true derive_mut_casts = true [enum] rename_variants = \u0026#34;ScreamingSnakeCase\u0026#34; must_use = \u0026#34;/*must_use*/\u0026#34; [const] allow_static_const = true allow_constexpr = false [macro_expansion] bitflags = true 然后更新 build.rs 编译脚本\nuse std::env; use std::path::PathBuf; fn main() { let crate_dir = env::var(\u0026#34;CARGO_MANIFEST_DIR\u0026#34;).unwrap(); let output_dir = PathBuf::from(\u0026amp;crate_dir); // Generate the header file cbindgen::Builder::new() .with_crate(crate_dir.clone()) .with_language(cbindgen::Language::C) .generate() .expect(\u0026#34;Unable to generate bindings\u0026#34;) .write_to_file(output_dir.join(\u0026#34;bindings.h\u0026#34;)); // Rerun if any of these change println!(\u0026#34;cargo:rerun-if-changed=src/dart\u0026#34;); println!(\u0026#34;cargo:rerun-if-changed=cbindgen.toml\u0026#34;); } 需要导出的Rust函数添加 #[unsafe(no_mangle)] 与 extern \u0026quot;C\u0026quot;，譬如，需要与 dart 对接必须要实现以下函数，接收 api_data 然后调用 Dart_InitializeApiDL 初始化，另外，Rust 到 Dart 的异步通讯可通过 dart_port 的方式实现：\n#[unsafe(no_mangle)] pub extern \u0026#34;C\u0026#34; fn initialize_dart_api(api_data: *mut ::core::ffi::c_void, dart_port: i64, is_debug: bool) { println!(\u0026#34;Initializing Dart API\u0026#34;); unsafe { if Dart_InitializeApiDL(api_data) != 0 { panic!(\u0026#34;failed to initialize Dart DL C API: version mismatch. must update include/ to match Dart SDK version\u0026#34;); } } // Store the dart port globally if let Ok(mut port) = DART_PORT.lock() { *port = Some(dart_port); } // Try to initialize logger, but don\u0026#39;t panic if it\u0026#39;s already initialized let log_level = if is_debug { \u0026#34;debug\u0026#34; } else { \u0026#34;info\u0026#34; }; let _ = env_logger::try_init_from_env(Env::default().default_filter_or(log_level)); info!(\u0026#34;Dart API initialized with port: {}\u0026#34;, dart_port); } 这样打包Rust动态库的同时就会输出对应的头文件，譬如以上函数的定义：\nvoid initialize_dart_api(void *api_data, int64_t dart_port, bool is_debug); dart \u0026lt;-\u0026gt; C dart 根据 C 头文件与动态库，通过 ffi 的形式交互\ndart run ffigen --config ffigen.yaml 其中 ffigen.yaml:\n# Run with `dart run ffigen --config ffigen.yaml`. name: XXXBindings description: | Bindings for `bindings.h`. Regenerate bindings with `dart run ffigen --config ffigen.yaml`. output: \u0026#39;lib/generated/xxx_bindings_generated.dart\u0026#39; headers: entry-points: - \u0026#39;../core/bindings.h\u0026#39; include-directives: - \u0026#39;../core/bindings.h\u0026#39; compiler-opts: - \u0026#39;-I/usr/lib/clang/20/include/\u0026#39; - \u0026#39;-I/usr/lib/clang/19/include/\u0026#39; preamble: | // ignore_for_file: always_specify_types // ignore_for_file: camel_case_types // ignore_for_file: non_constant_identifier_names comments: style: any length: full 运行后输出 xxx_bindings_generated.dart 为 dart 下的绑定，如下：\nvoid initialize_dart_api( ffi.Pointer\u0026lt;ffi.Void\u0026gt; api_data, int dart_port, bool is_debug, ) { return _initialize_dart_api(api_data, dart_port, is_debug); } late final _initialize_dart_apiPtr = _lookup\u0026lt; ffi.NativeFunction\u0026lt; ffi.Void Function(ffi.Pointer\u0026lt;ffi.Void\u0026gt;, ffi.Int64, ffi.Bool) \u0026gt; \u0026gt;(\u0026#39;initialize_dart_api\u0026#39;); late final _initialize_dart_api = _initialize_dart_apiPtr .asFunction\u0026lt;void Function(ffi.Pointer\u0026lt;ffi.Void\u0026gt;, int, bool)\u0026gt;(); 使用时需要增加动态库加载功能，并且最好是增加一个wapper类封装，类似 Rust 常用的 unsafe 机制。\n动态库加载：\nfinal dartffi.DynamicLibrary _dylib = () { if (Platform.isMacOS || Platform.isIOS) { return dartffi.DynamicLibrary.open(\u0026#39;$_libName.framework/$_libName\u0026#39;); } if (Platform.isAndroid || Platform.isLinux) { return dartffi.DynamicLibrary.open(\u0026#39;lib$_libName.so\u0026#39;); } if (Platform.isWindows) { return dartffi.DynamicLibrary.open(\u0026#39;$_libName.dll\u0026#39;); } throw UnsupportedError(\u0026#39;Unknown platform: ${Platform.operatingSystem}\u0026#39;); }(); wapper类实例化时必须先调用 initialize_dart_api 函数，譬如一个简单的实现, 启动时传入 _receivePort.sendPort.nativePort，然后通过监听 _receivePort 将 Rust 的异步消息以Stream的方式广播出去。\nfinal XXXBindings _xxxBindings = XXXBindings(_dylib); StreamController\u0026lt;Message\u0026gt;? _messageController; static XXXService get instance { _instance ??= XXXService._internal(); return _instance!; } XXXService._internal() { _receivePort = ReceivePort(); _messageController = StreamController\u0026lt;Message\u0026gt;.broadcast(); _engineStartedController!.add(false); // Initialize the Dart API in the native library _xxxBindings.initialize_dart_api( dartffi .NativeApi .initializeApiDLData, // API data - pass null from Dart side _receivePort.sendPort.nativePort, // Native port ID kDebugMode, // Debug mode flag ); // Start listening to the receive port _startListening(); } void _startListening() { _receivePort.listen( (rawMessage) { if (_disposed || _messageController == null) return; try { if (rawMessage is Uint8List) { final fbMessage = fb.Message(rawMessage); final message = Message.fromFlatBuffer(fbMessage); // logInfo(\u0026#39;Received message\u0026#39;); _messageController!.add(message); } else { logWarning( \u0026#39;Received unexpected message type: ${rawMessage.runtimeType}\u0026#39;, ); } } catch (e, stackTrace) { logWarning(\u0026#39;Error processing message: $e\u0026#39;); logWarning(\u0026#39;Stack trace: $stackTrace\u0026#39;); // Add error to stream instead of silently ignoring _messageController!.addError(e, stackTrace); } }, onError: (error, stackTrace) { logWarning(\u0026#39;ReceivePort error: $error\u0026#39;); logWarning(\u0026#39;Stack trace: $stackTrace\u0026#39;); _messageController?.addError(error, stackTrace); }, onDone: () { logInfo(\u0026#39;ReceivePort closed\u0026#39;); _messageController?.close(); }, ); } 内存管理 需要注意的是 Rust 下面申请的内存只能 Rust 下释放，Dart 亦同理。\n譬如，如果Rust以如下方式返回 CString：\nCString::new(xxx_string) .map(|c_string| c_string.into_raw()) .unwrap_or(std::ptr::null_mut()) 则需要提供一个接口到 dart，使该字符串使用后能释放：\n#[unsafe(no_mangle)] pub extern \u0026#34;C\u0026#34; fn free_string(ptr: *mut c_char) { if !ptr.is_null() { unsafe { let _ = CString::from_raw(ptr); } } } 对于 dart 申请的内存，也可以使用类似的机制 ：\nfinal dataPtr = malloc.allocate\u0026lt;dartffi.Uint8\u0026gt;(...) try { // ... } finally { malloc.free(dataPtr); } ","permalink":"https://yplam.com/posts/rust/flutter-rust/","summary":"\u003cp\u003e针对常规的网络应用型APP，Flutter + Go 可以很好的兼顾性能与开发效率，而对于某些需要极致控制内存占用，需要与C库进行高效交互的程序，Flutter + Rust 则是另一个可选项。\u003c/p\u003e","title":"Flutter + Rust 跨平台应用开发"},{"content":"现时推荐系统可以说是内容类网站的基础组件之一，而得益于最近大模型等机器学习领域的快速发展，带动相关技术应用的普及，今天可以利用相关技术实现一个具备基础功能的推荐系统。\n推荐系统的关键技术和方法：\n基于内容的推荐，基于内容的推荐系统通过分析项目的特征来进行推荐。例如，在电影推荐中，系统可能会根据电影的类型、导演、演员等信息进行推荐。 协同过滤，包括用户-用户协同过滤，物品-物品协同过滤 基于模型的推荐，使用机器学习模型（如矩阵分解、深度学习）来进行推荐。这些模型通过训练数据学习用户和物品的潜在特征。 在生成推荐的过程中，主要包括以下步骤：\n选择，选择合适的推荐策略和算法。根据用户需求和业务场景，选择不同的推荐方法（如协同过滤、基于内容的推荐、混合推荐等）。 召回，从大规模的物品集合中初步筛选出一批可能感兴趣的物品。召回阶段的目标是提高效率，确保不遗漏用户可能感兴趣的内容。 过滤，对召回的物品进行进一步过滤，去除不符合条件的物品。这一步通常用于应用业务规则或个性化约束。 排序，对经过过滤的物品进行排序，以确定最终推荐的优先级。排序阶段的目标是优化推荐的相关性和用户满意度。 推荐系统还涉及冷启动，业务规则等。\n小型推荐系统相关技术 Transformers，自然语言处理的基础库 ONNX，方便模型跨平台部署 PGVector，PostgreSQL 扩展，用于高效存储和检索向量数据 Matrix Factorization，常用于实现协同过滤的推荐算法 文本内容相关推荐 相对于 Word2Vec，具有注意力机制的 BERT 能更好地理解内容上下文信息，从而实现更精准的基于内容的相关推荐\n使用 BERT 模型获取文本向量 向量存储到 PGVector 根据向量距离排序，得到内容相关文章 相似图片推荐 使用 ViT 或者 DEIT 模型获取图片向量 向量存储到 PGVector 根据向量距离排序，得到相似图片 用户感兴趣内容推荐 基于协同过滤 使用 Matrix Factorization 分解稀疏矩阵 算出用户特征与物品特征，存储到 PGVector 根据用户-用户距离，物品-物品距离，用户-物品距离获取推荐 ","permalink":"https://yplam.com/posts/machinelearning/recommender-system/","summary":"\u003cp\u003e现时推荐系统可以说是内容类网站的基础组件之一，而得益于最近大模型等机器学习领域的快速发展，带动相关技术应用的普及，今天可以利用相关技术实现一个具备基础功能的推荐系统。\u003c/p\u003e","title":"推荐系统的简易实现"},{"content":"JLink 软件包提供 JLinkRemoteServer，通过监听 19020 端口，为其他调试客户端提供网络远程调试功能，同时官方提供 tunnel 服务，实现跨局域网调试。如果自己有外网服务器，也可以非常简单地通过 FRP 自建 JLink 中转服务。\nJLink Docker 镜像 根据运行 Jlink的环境不同，从官方网站下载对应 deb 安装包，譬如 JLink_Linux_V698e_arm64.deb， JLink_Linux_V698e_x86_64.deb，然后在同一目录编写 Dockerfile ：\nFROM debian:bookworm-slim COPY JLink_Linux_V698e_x86_64.deb /tmp RUN dpkg -i /tmp/JLink_Linux_V698e_x86_64.deb \\ \u0026amp;\u0026amp; rm /tmp/JLink_Linux_V698e_x86_64.deb EXPOSE 19020 CMD [\u0026#34;/usr/bin/JLinkRemoteServer\u0026#34;] 打包 Docker 镜像 ，建议直接在连接 JLink 的机器上打包。\ndocker build -t jlink . FRP 服务器配置 外网 Linux 服务器创建文件 frp/frps.toml\nbindAddr = \u0026#34;0.0.0.0\u0026#34; bindPort = 7000 tls.force = false auth.method = \u0026#34;token\u0026#34; auth.token = \u0026#34;N8pUECXOSrXXxS54dRUkXo4KEfjzyluFZzHLwCzq8wU33eM5UdJKwlVD75C6rm78\u0026#34; 然后 Docker 运行\ndocker run --network host -d -v ./frp:/etc/frp --restart=always snowdreamtech/frps:0.52.3 远程 JLink Linux 机器配置 远程 JLink 通常运行在一些小型的 Linux 主机上，USB 外接 JLink 设备。创建 compose.yaml\nservices: jlink: image: jlink:latest ports: - \u0026#34;19020:19020\u0026#34; privileged: true devices: - /dev/bus/usb:/dev/bus/usb frpc: image: snowdreamtech/frpc:0.52.3 volumes: - ./frp:/etc/frp 创建 frp/frpc.toml\nserverAddr = \u0026#34;x.x.x.x\u0026#34; serverPort = 7000 loginFailExit = true auth.method = \u0026#34;token\u0026#34; auth.token = \u0026#34;N8pUECXOSrXXxS54dRUkXo4KEfjzyluFZzHLwCzq8wU33eM5UdJKwlVD75C6rm78\u0026#34; transport.tls.enable = false [[proxies]] name = \u0026#34;jlink\u0026#34; type = \u0026#34;tcp\u0026#34; localIP = \u0026#34;jlink\u0026#34; localPort = 19020 remotePort = 19020 然后使用docker compose运行\ndocker compose up 远程调试 本地 JLinkExe 通过 FRP 服务器连接远程 JLink 进行调试：\nJLinkExe -if SWD -device EFR32MG21AXXXF768 -speed 1000 -autoconnect 1 -ip x.x.x.x:19020 ","permalink":"https://yplam.com/posts/embedded/jlink-remote-frp/","summary":"\u003cp\u003eJLink 软件包提供 JLinkRemoteServer，通过监听 19020 端口，为其他调试客户端提供网络远程调试功能，同时官方提供 tunnel 服务，实现跨局域网调试。如果自己有外网服务器，也可以非常简单地通过 FRP 自建 JLink 中转服务。\u003c/p\u003e","title":"基于 FRP 实现远程 JLink 调试"},{"content":"Flutter 是由 Google 开发的开源 UI 软件开发工具包，用于构建跨平台的高性能应用程序。通过一套代码库，开发者可以同时为 iOS、Android、Web 和桌面平台创建原生应用。通常情况下，Dart 代码会通过 MethodChannel 的方式与各平台原生代码进行交互，而原生代码通常也是根据不同平台由 Java，Swift，C++ 等语言编写。除此以外，一些与平台相关性不大，但使用 Dart 语言实现困难的跨平台代码，则适合使用 Rust 或者 Go 等编程语言实现，本文章记录 Flutter + Go 实现跨平台应用开发。\n可以通过以下命令创建一个支持多平台的插件：\nflutter create --org com.yplam --platforms=android,ios,linux,windows,macos -a java flutter_abc -t plugin Flutter 插件模板默认会生成 getPlatformVersion 方法，可以在编辑器中全局搜索该方法名查看各平台的接入方式，并且在此基础上修改。\n编写 Go 代码，代码的组织与通常的 Go 项目区别不大，个人经验是项目根目录只包含跨平台可用的导出函数，或者针对每个平台编写对应的导出文件。\n譬如针对桌面平台导出 C 静态库，则编写独立的 main.go，使用 export 导出函数:\npackage main import \u0026#34;C\u0026#34; //export Run func Run(fn *C.char) int32 { return 0 } //export Stop func Stop() { } func main() {} 然后使用以下命令生成静态库与对应头文件:\nGOOS=linux GOARCH=amd64 CGO_ENABLED=1 go build -buildmode=c-archive -o ./libs/linux_amd64/libabc.a ./cmd/libs/main.go GOOS=windows GOARCH=amd64 CGO_ENABLED=1 CXX=x86_64-w64-mingw32-g++ CC=x86_64-w64-mingw32-gcc go build -buildmode=c-archive -o ./libs/windows_amd64/libabc.a ./cmd/libs/main.go 然后更改插件的 linux/CMakeLists.txt 或者 windows/CMakeLists.txt, 把 C 库加到项目\nset(ABC_LIB_DIR \u0026#34;${CMAKE_CURRENT_SOURCE_DIR}/lib\u0026#34;) link_directories(${ABC_LIB_DIR}) target_link_libraries(${PLUGIN_NAME} PRIVATE ${ABC_LIB_DIR}/libabc.a) 然后即可在 xxx_plugin.cc 中 include 头文件，以及调用相关函数。\nAndroid 与 iOS 可直接使用 gomobile 生成对应的库：\n# go install golang.org/x/mobile/cmd/gomobile@latest # gomobile init gomobile bind -v -target android -o ./libs/android/libabc.aar -ldflags=\u0026#34;-w -s\u0026#34; ./ # ios 需要在Xcode环境打包 gomobile bind -v -target ios -o ./libs/ios/Libabc.xcframework -ldflags=\u0026#34;-w -s\u0026#34; ./ 针对 ios，需要将 xcframework 添加到项目（未详细测试，请参考网上文档）。\n","permalink":"https://yplam.com/posts/go/flutter-go-mobile/","summary":"\u003cp\u003eFlutter 是由 Google 开发的开源 UI 软件开发工具包，用于构建跨平台的高性能应用程序。通过一套代码库，开发者可以同时为 iOS、Android、Web 和桌面平台创建原生应用。通常情况下，Dart 代码会通过 MethodChannel 的方式与各平台原生代码进行交互，而原生代码通常也是根据不同平台由 Java，Swift，C++ 等语言编写。除此以外，一些与平台相关性不大，但使用 Dart 语言实现困难的跨平台代码，则适合使用 Rust 或者 Go 等编程语言实现，本文章记录 Flutter + Go 实现跨平台应用开发。\u003c/p\u003e","title":"Flutter + Go 跨平台应用开发"},{"content":"本文章总结Go语言编程中常用的插件系统设计。\nGo 语言自带 plugin package Go 1.8 开始自带 plugin 模块，通过 go build -buildmode=plugin 将代码打包成动态链接库； 然后在主应用程序中通过 plugin.Open，plugin.Lookup 获取插件实例。\n基于 package init 的编译型插件 Go 语言有个特别的特性就是当 import 某个 package 时，会立刻执行该 package 的 init 函数；这个特性通常不推荐使用，因为会导致代码执行逻辑难以阅读；但该特性十分适合用于实现编译型的插件，譬如 sql 库的各种驱动可以通过 init 函数注册：\nfunc init() { sql.Register(\u0026#34;mysql\u0026#34;, \u0026amp;MySQLDriver{}) } 又譬如 Caddy 扩展:\nfunc init() { caddy.RegisterModule(Gizmo{}) } 使用 init 函数的优点是只有用到的插件才会编译，并且插件会编译到主程序执行文件中，符合 go 易于部署的特点。\n基于 gRPC 的独立运行插件 由于 go 语言网络相关的组件非常丰富，因此实现一个基于网络的插件系统也非常简单，譬如 gRPC。https://github.com/hashicorp/go-plugin 项目是一个开源的基于gRPC的插件系统；与前面介绍的两种不同，基于gRPC的插件系统的优势是插件可以用多种编程语言编写，并且可以将插件对主程序的调用限定在公开接口上，并且可以通过 Docker 限制插件对系统资源的占用，避免某个插件把系统搞崩溃。\n","permalink":"https://yplam.com/posts/go/go-plugin/","summary":"\u003cp\u003e本文章总结Go语言编程中常用的插件系统设计。\u003c/p\u003e","title":"Go语言插件系统应用"},{"content":"本文目的为通过了解 Stable Diffusion 基本概念，学习如何根据需求选择模型、参数、工作流生成图片，探索 Stable Diffusion 技术的应用场景。\n学习资料 零基础读懂Stable Diffusion Stable Diffusion 基础知识系列文章 工具 Stable Diffusion web UI：直观而且容易上手，插件丰富 ComfyUI：功能强大、配置灵活，建议对 Stable Diffusion 有一定了解后转用 sd-scripts：训练相关工具脚本 ","permalink":"https://yplam.com/posts/machinelearning/stable-diffusion/","summary":"\u003cp\u003e本文目的为通过了解 Stable Diffusion 基本概念，学习如何根据需求选择模型、参数、工作流生成图片，探索 Stable Diffusion 技术的应用场景。\u003c/p\u003e","title":"Stable Diffusion 笔记"},{"content":"本文记录双 RTX4080 显卡运行 Yi-34B-Chat-4bits 模型过程与排错。\n基于 Ubuntu Server 20.04.6 LTS，并具有基础的科学上网条件。\n由于 CUDA 已绑定对应显卡驱动，因此直接到官网按提示下载安装即可，譬如我选择安装 12.1 版本：\nhttps://developer.nvidia.com/cuda-12-1-0-download-archive\nwget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin sudo mv cuda-ubuntu2004.pin /etc/apt/preferences.d/cuda-repository-pin-600 wget https://developer.download.nvidia.com/compute/cuda/12.1.0/local_installers/cuda-repo-ubuntu2004-12-1-local_12.1.0-530.30.02-1_amd64.deb sudo dpkg -i cuda-repo-ubuntu2004-12-1-local_12.1.0-530.30.02-1_amd64.deb sudo cp /var/cuda-repo-ubuntu2004-12-1-local/cuda-*-keyring.gpg /usr/share/keyrings/ sudo apt-get update sudo apt-get -y install cuda 安装 Docker\nfor pkg in docker.io docker-doc docker-compose docker-compose-v2 podman-docker containerd runc; do sudo apt-get remove $pkg; done # Add Docker\u0026#39;s official GPG key: sudo apt-get update sudo apt-get install ca-certificates curl gnupg sudo install -m 0755 -d /etc/apt/keyrings curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg sudo chmod a+r /etc/apt/keyrings/docker.gpg # Add the repository to Apt sources: echo \\ \u0026#34;deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\ $(. /etc/os-release \u0026amp;\u0026amp; echo \u0026#34;$VERSION_CODENAME\u0026#34;) stable\u0026#34; | \\ sudo tee /etc/apt/sources.list.d/docker.list \u0026gt; /dev/null sudo apt-get update sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin 如果上面有出错信息，则大概率是访问 docker 服务器间的网络不顺畅。。。\n安装 NVIDIA Container Toolkit\ncurl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \\ \u0026amp;\u0026amp; curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \\ sed \u0026#39;s#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g\u0026#39; | \\ sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list \\ \u0026amp;\u0026amp; \\ sudo apt-get update sudo apt-get install -y nvidia-container-toolkit sudo nvidia-ctk runtime configure --runtime=docker sudo systemctl restart docker Dockerfile 与 compose.yaml\n此 Dockerfile 同时加入 chatglm-cpp 的支持（貌似默认无法支持多卡，需要修改代码？）\nFROM nvidia/cuda:12.1.1-cudnn8-devel-ubuntu20.04 ARG TIMEZONE=Asia/Shanghai ARG UID=1000 ARG GID=1000 ENV DEBIAN_FRONTEND=noninteractive RUN \\ sed -e \u0026#34;s/archive.ubuntu.com/mirrors.tuna.tsinghua.edu.cn/g\u0026#34; \\ -e \u0026#34;s/security.ubuntu.com/mirrors.tuna.tsinghua.edu.cn/g\u0026#34; -i /etc/apt/sources.list # Set timezone RUN ln -snf /usr/share/zoneinfo/${TIMEZONE} /etc/localtime \u0026amp;\u0026amp; echo ${TIMEZONE} \u0026gt; /etc/timezone \\ \u0026amp;\u0026amp; \u0026#34;date\u0026#34; RUN apt-get update \u0026amp;\u0026amp; apt-get install -y \\ curl \\ apt-utils \\ wget \\ build-essential \\ libssl-dev \\ zlib1g-dev \\ libncurses5-dev \\ libncursesw5-dev \\ libreadline-dev \\ libsqlite3-dev \\ libgdbm-dev \\ libdb5.3-dev \\ libbz2-dev \\ libexpat1-dev \\ liblzma-dev \\ git \\ vim \\ libffi-dev \\ libgdbm-compat-dev \\ ffmpeg libsm6 libxext6 RUN wget https://www.python.org/ftp/python/3.10.12/Python-3.10.12.tar.xz -O /tmp/Python-3.10.12.tar.xz \\ \u0026amp;\u0026amp; tar xvf /tmp/Python-3.10.12.tar.xz -C /tmp \\ \u0026amp;\u0026amp; cd /tmp/Python-3.10.12 \\ \u0026amp;\u0026amp; ./configure --enable-optimizations --with-ensurepip=install \\ \u0026amp;\u0026amp; make -j $(nproc) \\ \u0026amp;\u0026amp; make altinstall \\ \u0026amp;\u0026amp; update-alternatives --install /usr/bin/python python /usr/local/bin/python3.10 1 \\ \u0026amp;\u0026amp; update-alternatives --install /usr/bin/pip pip /usr/local/bin/pip3.10 1 \\ \u0026amp;\u0026amp; rm -rf /tmp/Python-3.10.12.tar.xz /tmp/Python-3.10.12 RUN export LD_LIBRARY_PATH=/lib/x86_64-linux-gnu:$LD_LIBRARY_PATH RUN pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121 RUN pip install xformers --index-url https://download.pytorch.org/whl/cu118 RUN pip install wheel streamlit transformers_stream_generator cpm_kernels astunparse accelerate tiktoken einops scipy peft auto-gptq optimum RUN CMAKE_ARGS=\u0026#34;-DGGML_CUBLAS=ON\u0026#34; pip install -U \u0026#39;chatglm-cpp[api]\u0026#39; RUN pip install autoawq xformers RUN groupadd -g $GID -o chatglm RUN useradd -m -u $UID -g $GID -o -s /bin/bash chatglm USER chatglm WORKDIR /home/chatglm/work ENTRYPOINT [\u0026#34;tail\u0026#34;, \u0026#34;-f\u0026#34;, \u0026#34;/dev/null\u0026#34;] compose.yaml\nservices: chatglm: build: context: ./docker network: host container_name: chatglm restart: always # entrypoint: [\u0026#34;uvicorn\u0026#34;, \u0026#34;chatglm_cpp.openai_api:app\u0026#34;, \u0026#34;--host\u0026#34;, \u0026#34;0.0.0.0\u0026#34;] dns: - 119.29.29.29 volumes: - ./:/home/chatglm/work/ - ./data/cache:/home/chatglm/.cache - ./data/config:/home/chatglm/.config - ./data/triton:/home/chatglm/.triton - /usr/local/nvidia:/usr/local/nvidia ports: - 8000:8000 deploy: resources: reservations: devices: - driver: nvidia capabilities: [gpu] docker compose up -d \u0026ndash;build , 运行，devel镜像较大，可能需要较长时间。\n运行后先进入容器查看是否显卡已正常挂载，nvidia-smi 。\ngit clone https://huggingface.co/01-ai/Yi-34B-Chat-4bits 下载模型，需要先安装 lfs 插件。\n进入容器，按官方资料编写并执行脚本，由于 AutoModelForCausalLM 已支持多 GPU，通常不需要更改代码。\n错误排查 对于多 GPU 的环境，需要先保证 GPU 间数据能正常通讯：\nimport torch x = torch.tensor([1.0, 2.0], device=0) x.to(1) x.to(\u0026#39;cpu\u0026#39;).to(1) 需要测试 x.to(1) 后的值是否正常，如果为 [0, 0] 则代表 GPU 间数据传递失败，可能存在两种原因：\nIOMMU，可以通过 bios 配置关闭，参考 https://docs.nvidia.com/deeplearning/nccl/user-guide/docs/troubleshooting.html#pci-access-control-services-acs\n显卡驱动问题，建议寻找合适的驱动版本。譬如 CUDA 12.1 对应的驱动版本无法 GPU 间传递数据，升级到 12.2 后正常（容器依然基于 12.1，经测试依然可用）\n","permalink":"https://yplam.com/posts/machinelearning/pytorch-multiple-gpus-error/","summary":"\u003cp\u003e本文记录双 RTX4080 显卡运行 Yi-34B-Chat-4bits 模型过程与排错。\u003c/p\u003e","title":"PyTorch 多显卡推理与问题排查"},{"content":"本文探讨物联网平台后端组件选择，架构设计与性能验证。\n组件 EMQX 集群 MQTT 设备接入，通常设备均通过类似 \u0026lt;设备型号\u0026gt;/\u0026lt;设备ID\u0026gt; 的预定义主题前缀收发消息 MQTT 协议接入层，根据 \u0026lt;设备型号\u0026gt; 前缀消费 EMQX 消息，并且根据对应的物模型规则将 MQTT 消息转换为系统物模型消息，然后转发到消息上行 Kafka 消息队列；同时通过消费 Kafka 中的下行物模型指令，根据设备型号对应的物模型规则转换为 MQTT 消息，并发送到 EMQX 集群 Kafka 设备上行消息由规则引擎消费，先保存到时序数据库 InfluxDB，更新 PostgreSQL 中设备状态存储，发送到实时状态 Kafka 消息队列（供API层订阅），然后根据场景规则的触发器判断并触发场景任务，场景任务执行通过 Asynq + Redis 支持 组件性能验证 EMQX 性能测试 EMQX 性能测试对测试客户端性能要求较高，并且由于客户端端口分配问题，每个网卡支持的客户端数量不能大于可分配端口数，因此使用阿里云ECS增加虚拟网卡的方式进行测试，在此使用 4 网卡，每网卡 50000 客户端连接的方式模拟。\nsysctl -w net.ipv4.ip_local_port_range=\u0026#39;10000 60999\u0026#39; ./bin/emqtt_bench pub -t t -h 172.18.93.253 -s 16 -q 0 -c 50000 --ifaddr 172.18.93.254 -i 5 ./bin/emqtt_bench pub -t t -h 172.18.93.253 -s 16 -q 0 -c 50000 --ifaddr 172.18.93.255 -i 5 ./bin/emqtt_bench pub -t t -h 172.18.93.253 -s 16 -q 0 -c 50000 --ifaddr 172.18.94.1 -i 5 ./bin/emqtt_bench pub -t t -h 172.18.93.253 -s 16 -q 0 -c 50000 --ifaddr 172.18.94.0 -i 5 初步测试在单机可支持 15 万连接，15 万 qos0 消息，超过后出现 connack_timeout 报错。考虑到 EMQX 与 MQTT 接入层的横向扩展较容易，评估成为性能瓶颈的可能性较低。\nKafka 性能测试 通常 Kafka 的性能瓶颈为磁盘 IO，docker-compose.yml 中对 Kafka 配置对标阿里云 4 核 8G，5 万 iops 实例类型:\nblkio_config: device_read_iops: - path: /dev/nvme0n1 rate: 50000 device_write_iops: - path: /dev/nvme0n1 rate: 50000 device_write_bps: - path: /dev/nvme0n1 rate: \u0026#39;300m\u0026#39; device_read_bps: - path: /dev/nvme0n1 rate: \u0026#39;300m\u0026#39; deploy: resources: limits: cpus: \u0026#34;4\u0026#34; memory: 8G 创建测试主题，并验证\n./kafka-topics.sh --create --bootstrap-server localhost:29092 --topic ptest --partitions 6 --replication-factor 2 ./kafka-console-producer.sh --broker-list localhost:29092 --topic ptest ./kafka-console-consumer.sh --bootstrap-server localhost:29092 --topic ptest 分别测试不限制吞吐量以及限制百万吞吐量下的性能数据：\n./kafka-producer-perf-test.sh --producer-props bootstrap.servers=localhost:29092 acks=1 --topic ptest --throughput -1 --record-size 100 --num-records 50000000 # 50000000 records sent, 2288643.749714 records/sec (218.26 MB/sec), 6.51 ms avg latency, 303.00 ms max latency, 0 ms 50th, 7 ms 95th, 194 ms 99th, 257 ms 99.9th. ./kafka-producer-perf-test.sh --producer-props bootstrap.servers=localhost:29092 acks=1 --topic ptest --throughput 1000000 --record-size 100 --num-records 50000000 # 50000000 records sent, 999900.009999 records/sec (95.36 MB/sec), 0.72 ms avg latency, 597.00 ms max latency, 0 ms 50th, 1 ms 95th, 4 ms 99th, 43 ms 99.9th. 最大吞吐量超过200万每秒，在百万消息每秒的情况下，延时能满足业务需求。\n测试消费性能：\n./kafka-consumer-perf-test.sh --broker-list localhost:29092 --topic ptest --messages 50000000 # data.consumed.in.MB, MB.sec, data.consumed.in.nMsg, nMsg.sec, rebalance.time.ms, fetch.time.ms, fetch.MB.sec, fetch.nMsg.sec # 4768.4112, 518.9260, 50000417, 5441333.8775, 3176, 6013, 793.0170, 8315386.1633 ","permalink":"https://yplam.com/posts/iot/million-throughput-iot-architecture-design/","summary":"\u003cp\u003e本文探讨物联网平台后端组件选择，架构设计与性能验证。\u003c/p\u003e\n\u003ch2 id=\"组件\"\u003e组件\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eEMQX 集群 MQTT 设备接入，通常设备均通过类似 \u0026lt;设备型号\u0026gt;/\u0026lt;设备ID\u0026gt; 的预定义主题前缀收发消息\u003c/li\u003e\n\u003cli\u003eMQTT 协议接入层，根据 \u0026lt;设备型号\u0026gt; 前缀消费 EMQX 消息，并且根据对应的物模型规则将 MQTT 消息转换为系统物模型消息，然后转发到消息上行 Kafka 消息队列；同时通过消费 Kafka 中的下行物模型指令，根据设备型号对应的物模型规则转换为 MQTT 消息，并发送到 EMQX 集群\u003c/li\u003e\n\u003cli\u003eKafka 设备上行消息由规则引擎消费，先保存到时序数据库 InfluxDB，更新 PostgreSQL 中设备状态存储，发送到实时状态 Kafka 消息队列（供API层订阅），然后根据场景规则的触发器判断并触发场景任务，场景任务执行通过 Asynq + Redis 支持\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"组件性能验证\"\u003e组件性能验证\u003c/h2\u003e\n\u003ch3 id=\"emqx-性能测试\"\u003eEMQX 性能测试\u003c/h3\u003e\n\u003cp\u003eEMQX 性能测试对测试客户端性能要求较高，并且由于客户端端口分配问题，每个网卡支持的客户端数量不能大于可分配端口数，因此使用阿里云ECS增加虚拟网卡的方式进行测试，在此使用 4 网卡，每网卡 50000 客户端连接的方式模拟。\u003c/p\u003e","title":"物联网平台后端架构设计与性能验证"},{"content":"记录关于 RV1106 烧录、开发环境配置、SDK与Rust绑定相关内容。\n最后更新：2024-07-27\nCLion 配置 Cmake options 添加\n-DCOMPILE_FOR_RV1106_IPC:BOOL=ON -DRKIPC_CROSS_COMPILE=arm-rockchip830-linux-uclibcgnueabihf Rust 绑定 由于 RV1106 官方 SDK 基于 uclibc，因此 Rust 编译器环境需要基于官方 SDK 手动打包\nexport PATH=/home/xxx/xxx/tools/linux/toolchain/arm-rockchip830-linux-uclibcgnueabihf/bin:$PATH git clone https://github.com/rust-lang/rust.git cd rust git checkout 1.72.1 git submodule update --init --recursive # ./x setup --target=armv7-unknown-linux-uclibceabihf ./x check --target=armv7-unknown-linux-uclibceabihf ./x build library --target=armv7-unknown-linux-uclibceabihf ./x build --stage 2 --target=armv7-unknown-linux-uclibceabihf mv build/host/stage2 rust-1.72.1-rv1106 tar -cvJf rust-1.72.1-rv1106.tar.xz rust-1.72.1-rv1106 config.toml\nchangelog-seen = 2 [build] target = [\u0026#34;armv7-unknown-linux-uclibceabihf\u0026#34;] build-stage = 2 test-stage = 2 doc-stage = 2 extended = true [llvm] download-ci-llvm = false [rust] channel = \u0026#34;nightly\u0026#34; download-rustc = false [dist] compression-profile = \u0026#34;balanced\u0026#34; [target.armv7-unknown-linux-uclibceabihf] linker = \u0026#34;arm-rockchip830-linux-uclibcgnueabihf-gcc\u0026#34; cc = \u0026#34;arm-rockchip830-linux-uclibcgnueabihf-gcc\u0026#34; 打包好的工具链可访问github下载： https://github.com/yplam/rv1106-rs/releases/tag/v0.2.0 ,下载后可通过\nrustup toolchain link rv1106 path-to/rust-1.72.1-rv1106 https://github.com/yplam/rv1106-rs 项目实现了对 RV1106 SDK 的 Rust 基础功能绑定，方便基于 Rust 开发应用，暂时只实现了 rv1106-sys 关于 rockit， rknpu2 的功能绑定。\n使用 glibc 基于 uclibc 打包的 Rust 工具链只能处于基本可用状态，由于大量库缺乏对 uclibc 的支持（譬如基于 ring、tls 相关的库），因此如果只把 rv1106 作为通用 linux 环境使用的情况下，可以基于 glibc 的工具链打包，缺点是缺乏 media 相关包的支持。\n","permalink":"https://yplam.com/posts/embedded/rv1106-dev/","summary":"\u003cp\u003e记录关于 RV1106 烧录、开发环境配置、SDK与Rust绑定相关内容。\u003c/p\u003e","title":"RV1106 开发笔记"},{"content":"基于 Docker 环境实现 EFR32MG21 官方 Bootloader， Zigbee 协调器与 Matter 固件编译打包与烧录。\n最后更新：2024-07-13\n打包与烧录均可以基于 Docker 完成\ndocker run --rm -it \\ --user builder \\ -v /dev/bus/usb:/dev/bus/usb \\ -v $(pwd)/build:/build \\ --privileged \\ ghcr.io/darkxst/silabs-firmware-builder:4.4.2 进入 Docker 容器，基于模板生成项目源码，编译。\nslc generate \\ --with=\u0026#34;EFR32MG21A020F768IM32\u0026#34; \\ --project-file=\u0026#34;/gecko_sdk/platform/bootloader/sample-apps/Series-2/bootloader-uart-xmodem/bootloader-uart-xmodem.slcp\u0026#34; \\ --export-destination=bootloader-uart-xmodem \\ --copy-proj-sources --new-project --force \\ --configuration=\u0026#34;\u0026#34; cd bootloader-uart-xmodem # 修改引脚配置 make -f bootloader-uart-xmodem.Makefile release cd .. slc generate \\ --with=\u0026#34;EFR32MG21A020F768IM32\u0026#34; \\ --project-file=\u0026#34;/gecko_sdk/protocol/zigbee/app/ncp/sample-app/ncp-uart-hw/ncp-uart-hw.slcp\u0026#34; \\ --export-destination=ncp-uart-hw \\ --copy-proj-sources --new-project --force \\ --configuration=\u0026#34;\u0026#34; cd ncp-uart-hw # 修改引脚配置 sl_iostream_usart_vcom_config.h make -f ncp-uart-hw.Makefile release # 部分模块需要先解锁 commander device recover -d EFR32MG21A020F768 ","permalink":"https://yplam.com/posts/embedded/efr32mg21-firmware/","summary":"\u003cp\u003e基于 Docker 环境实现 EFR32MG21 官方 Bootloader， Zigbee 协调器与 Matter 固件编译打包与烧录。\u003c/p\u003e","title":"基于 Docker 的 EFR32MG21 Zigbee/Matter 固件打包"},{"content":"家里虽然部署了一台 Gen8 Micro 用作 NAS，但最近想针对一些重要内容增加一份本地备份，于是咸鱼上找一下矿渣，找到这台金色比特米。\nU 盘烧录 Armbian_23.08.0_amlogic_s905x_bullseye_5.15.120_server_2023.07.08.img.gz\n接上鼠标键盘（USB口可能供电不足，无法同时支持多个设备接入，建议使用可外接供电的 USB hub），HDMI开机，发现可进入 Android 系统，点击配置图标，可进入标准的 Android 设置页，点击几下版本号，可打开开发者模式\n配置好IP，网线连上电脑，adb connect 192.168.x.x 然后选择允许即可 adb shell 接入\n重命名 切换卡载系统V1.1.20180808.apk 到 20180808.apk，然后通过 adb 安装与启用：\nadb install 20180808.apk adb shell monkey -p cn.edu.tit.reboot -c android.intent.category.LAUNCHER 1 在弹出界面选择第一次安装/启用，接上U盘，重启可进入 armbian\narmbian 常规设置后，可远程 root ssh 登录\n挂载sd卡，先备份整个 mmc，并校验（注意：如果使用fat32可能无法完整备份）：\ndd if=/dev/mmcblk2 of=/mnt/data/p212_mmc_backup.img bs=4M status=progress sha256sum /dev/mmcblk2 分析旧 mmc 分区，其中 /dev/mmcblk2p2 包含分区表与结构\nhexdump -C -n 10240 /dev/mmcblk2p2 00000000 4d 50 54 00 30 31 2e 30 30 2e 30 30 00 00 00 00 |MPT.01.00.00\u0026hellip;.| 00000010 0f 00 00 00 fd c1 03 b8 62 6f 6f 74 6c 6f 61 64 |\u0026hellip;\u0026hellip;..bootload| 00000020 65 72 00 00 00 00 00 00 00 00 40 00 00 00 00 00 |er\u0026hellip;\u0026hellip;..@\u0026hellip;..| 00000030 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;.| 00000040 72 65 73 65 72 76 65 64 00 00 00 00 00 00 00 00 |reserved\u0026hellip;\u0026hellip;..| 00000050 00 00 00 04 00 00 00 00 00 00 40 02 00 00 00 00 |\u0026hellip;\u0026hellip;\u0026hellip;.@\u0026hellip;..| 00000060 00 00 00 00 00 00 00 00 63 61 63 68 65 00 00 00 |\u0026hellip;\u0026hellip;..cache\u0026hellip;| 00000070 00 00 00 00 00 00 00 00 00 00 00 20 00 00 00 00 |\u0026hellip;\u0026hellip;\u0026hellip;.. \u0026hellip;.| 00000080 00 00 c0 06 00 00 00 00 02 00 00 00 00 00 00 00 |\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;.| 00000090 65 6e 76 00 00 00 00 00 00 00 00 00 00 00 00 00 |env\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;.| 000000a0 00 00 80 00 00 00 00 00 00 00 40 27 00 00 00 00 |\u0026hellip;\u0026hellip;\u0026hellip;.@\u0026rsquo;\u0026hellip;.| 000000b0 00 00 00 00 00 00 00 00 6c 6f 67 6f 00 00 00 00 |\u0026hellip;\u0026hellip;..logo\u0026hellip;.| 000000c0 00 00 00 00 00 00 00 00 00 00 00 02 00 00 00 00 |\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;.| 000000d0 00 00 40 28 00 00 00 00 01 00 00 00 00 00 00 00 |..@(\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;| 000000e0 72 65 63 6f 76 65 72 79 00 00 00 00 00 00 00 00 |recovery\u0026hellip;\u0026hellip;..| 000000f0 00 00 00 02 00 00 00 00 00 00 c0 2a 00 00 00 00 |\u0026hellip;\u0026hellip;\u0026hellip;..*\u0026hellip;.| 00000100 01 00 00 00 00 00 00 00 72 73 76 00 00 00 00 00 |\u0026hellip;\u0026hellip;..rsv\u0026hellip;..| 00000110 00 00 00 00 00 00 00 00 00 00 80 00 00 00 00 00 |\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;.| 00000120 00 00 40 2d 00 00 00 00 01 00 00 00 00 00 00 00 |..@-\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;| 00000130 74 65 65 00 00 00 00 00 00 00 00 00 00 00 00 00 |tee\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;.| 00000140 00 00 80 00 00 00 00 00 00 00 40 2e 00 00 00 00 |\u0026hellip;\u0026hellip;\u0026hellip;.@\u0026hellip;..| 00000150 01 00 00 00 00 00 00 00 63 72 79 70 74 00 00 00 |\u0026hellip;\u0026hellip;..crypt\u0026hellip;| 00000160 00 00 00 00 00 00 00 00 00 00 00 02 00 00 00 00 |\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;.| 00000170 00 00 40 2f 00 00 00 00 01 00 00 00 00 00 00 00 |..@/\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;| 00000180 6d 69 73 63 00 00 00 00 00 00 00 00 00 00 00 00 |misc\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;| 00000190 00 00 00 02 00 00 00 00 00 00 c0 31 00 00 00 00 |\u0026hellip;\u0026hellip;\u0026hellip;..1\u0026hellip;.| 000001a0 01 00 00 00 00 00 00 00 69 6e 73 74 61 62 6f 6f |\u0026hellip;\u0026hellip;..instaboo| 000001b0 74 00 00 00 00 00 00 00 00 00 00 20 00 00 00 00 |t\u0026hellip;\u0026hellip;\u0026hellip;. \u0026hellip;.| 000001c0 00 00 40 34 00 00 00 00 01 00 00 00 00 00 00 00 |..@4\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;| 000001d0 62 6f 6f 74 00 00 00 00 00 00 00 00 00 00 00 00 |boot\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;| 000001e0 00 00 00 02 00 00 00 00 00 00 c0 54 00 00 00 00 |\u0026hellip;\u0026hellip;\u0026hellip;..T\u0026hellip;.| 000001f0 01 00 00 00 00 00 00 00 73 79 73 74 65 6d 00 00 |\u0026hellip;\u0026hellip;..system..| 00000200 00 00 00 00 00 00 00 00 00 00 00 40 00 00 00 00 |\u0026hellip;\u0026hellip;\u0026hellip;..@\u0026hellip;.| 00000210 00 00 40 57 00 00 00 00 01 00 00 00 00 00 00 00 |..@W\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;| 00000220 63 68 61 6f 6d 69 00 00 00 00 00 00 00 00 00 00 |chaomi\u0026hellip;\u0026hellip;\u0026hellip;.| 00000230 00 00 00 60 00 00 00 00 00 00 c0 97 00 00 00 00 |\u0026hellip;`\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;| 00000240 01 00 00 00 00 00 00 00 64 61 74 61 00 00 00 00 |\u0026hellip;\u0026hellip;..data\u0026hellip;.| 00000250 00 00 00 00 00 00 00 00 00 00 c0 d9 00 00 00 00 |\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;.| 00000260 00 00 40 f8 00 00 00 00 04 00 00 00 00 00 00 00 |..@\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;.| 00000270 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;.| * 00002800\n猜测 /dev/mmcblk2p13 为内核，在 00000800 offset 找到 1f8b0808 magic\n寻找 dtb：\n通过 binwalk -R \u0026lsquo;\\xd0\\x0d\\xfe\\xed\u0026rsquo; p212_mmc_backup.img 查找 dtb 特征\nbinwalk -R \u0026#39;\\xd0\\x0d\\xfe\\xed\u0026#39; p212_mmc_backup.img DECIMAL HEXADECIMAL DESCRIPTION -------------------------------------------------------------------------------- 41945088 0x2800800 Raw signature (\\xd0\\x0d\\xfe\\xed) 41986048 0x280A800 Raw signature (\\xd0\\x0d\\xfe\\xed) 42207232 0x2840800 Raw signature (\\xd0\\x0d\\xfe\\xed) 42248192 0x284A800 Raw signature (\\xd0\\x0d\\xfe\\xed) 728629248 0x2B6E0000 Raw signature (\\xd0\\x0d\\xfe\\xed) 728670208 0x2B6EA000 Raw signature (\\xd0\\x0d\\xfe\\xed) 1430345728 0x55415800 Raw signature (\\xd0\\x0d\\xfe\\xed) 1430386688 0x5541F800 Raw signature (\\xd0\\x0d\\xfe\\xed) 然后\ndd if=../p212_mmc_backup.img of=./dtb.dtb bs=1 skip=$((0x2800800)) count=$((1024*1024)) dtc -I dtb -O dts -o dtb.dts dtb.dtb 安装 armbian：\numount 所有分区 dd if=/dev/zero of=/dev/mmcblk2 bs=512 count=1 conv=fsync 清空分区表 运行 armbian-install，选择设备ID 105，等待 ","permalink":"https://yplam.com/posts/linux/p212/","summary":"\u003cp\u003e家里虽然部署了一台 Gen8 Micro 用作 NAS，但最近想针对一些重要内容增加一份本地备份，于是咸鱼上找一下矿渣，找到这台金色比特米。\u003c/p\u003e","title":"比特米刷机记录"},{"content":"本笔记记录 FFmpeg HLS Fragmented Mp4 封装过程，主要关注点为 Fragmented Mp4 容器格式。\n测试对应的 ffmpeg 命令为:\n./ffmpeg -i 2023-06-07-07-40-44.mp4 -c:v copy -c:a copy -hls_segment_type fmp4 -hls_list_size 10 \\ -hls_flags delete_segments+append_list -hls_playlist_type event -bsf:a aac_adtstoasc -brand isom \\ -loglevel debug -v verbose /tmp/index.m3u8 功能上不涉及编解码，只是将 mp4 文件重新封装为 hls m3u8，其中分片格式使用 fmp4，主要涉及代码为 libavformat 的 hlsenc.c，基础数据结构如下：\nconst FFOutputFormat ff_hls_muxer = { .p.name = \u0026#34;hls\u0026#34;, .p.long_name = NULL_IF_CONFIG_SMALL(\u0026#34;Apple HTTP Live Streaming\u0026#34;), .p.extensions = \u0026#34;m3u8\u0026#34;, .p.audio_codec = AV_CODEC_ID_AAC, .p.video_codec = AV_CODEC_ID_H264, .p.subtitle_codec = AV_CODEC_ID_WEBVTT, .p.flags = AVFMT_NOFILE | AVFMT_GLOBALHEADER | AVFMT_ALLOW_FLUSH | AVFMT_NODIMENSIONS, .p.priv_class = \u0026amp;hls_class, .priv_data_size = sizeof(HLSContext), .init = hls_init, .write_header = hls_write_header, .write_packet = hls_write_packet, .write_trailer = hls_write_trailer, .deinit = hls_deinit, }; typedef struct HLSContext { const AVClass *class; // Class for private options. int64_t start_sequence; uint32_t start_sequence_source_type; // enum StartSequenceSourceType int64_t time; // Set by a private option. int64_t init_time; // Set by a private option. int max_nb_segments; // Set by a private option. int hls_delete_threshold; // Set by a private option. uint32_t flags; // enum HLSFlags uint32_t pl_type; // enum PlaylistType char *segment_filename; char *fmp4_init_filename; int segment_type; int resend_init_file; ///\u0026lt; resend init file into disk after refresh m3u8 int use_localtime; ///\u0026lt; flag to expand filename with localtime int use_localtime_mkdir;///\u0026lt; flag to mkdir dirname in timebased filename int allowcache; int64_t recording_time; int64_t max_seg_size; // every segment file max size char *baseurl; char *vtt_format_options_str; char *subtitle_filename; AVDictionary *format_options; int encrypt; char *key; char *key_url; char *iv; char *key_basename; int encrypt_started; char *key_info_file; char key_file[LINE_BUFFER_SIZE + 1]; char key_uri[LINE_BUFFER_SIZE + 1]; char key_string[KEYSIZE*2 + 1]; char iv_string[KEYSIZE*2 + 1]; AVDictionary *vtt_format_options; char *method; char *user_agent; VariantStream *var_streams; unsigned int nb_varstreams; ClosedCaptionsStream *cc_streams; unsigned int nb_ccstreams; int master_m3u8_created; /* status of master play-list creation */ char *master_m3u8_url; /* URL of the master m3u8 file */ int version; /* HLS version */ char *var_stream_map; /* user specified variant stream map string */ char *cc_stream_map; /* user specified closed caption streams map string */ char *master_pl_name; unsigned int master_publish_rate; int http_persistent; AVIOContext *m3u8_out; AVIOContext *sub_m3u8_out; AVIOContext *http_delete; int64_t timeout; int ignore_io_errors; char *headers; int has_default_key; /* has DEFAULT field of var_stream_map */ int has_video_m3u8; /* has video stream m3u8 list */ } HLSContext; #define OFFSET(x) offsetof(HLSContext, x) #define E AV_OPT_FLAG_ENCODING_PARAM static const AVOption options[] = { {\u0026#34;start_number\u0026#34;, \u0026#34;set first number in the sequence\u0026#34;, OFFSET(start_sequence),AV_OPT_TYPE_INT64, {.i64 = 0}, 0, INT64_MAX, E}, {\u0026#34;hls_time\u0026#34;, \u0026#34;set segment length\u0026#34;, OFFSET(time), AV_OPT_TYPE_DURATION, {.i64 = 2000000}, 0, INT64_MAX, E}, {\u0026#34;hls_init_time\u0026#34;, \u0026#34;set segment length at init list\u0026#34;, OFFSET(init_time), AV_OPT_TYPE_DURATION, {.i64 = 0}, 0, INT64_MAX, E}, {\u0026#34;hls_list_size\u0026#34;, \u0026#34;set maximum number of playlist entries\u0026#34;, OFFSET(max_nb_segments), AV_OPT_TYPE_INT, {.i64 = 5}, 0, INT_MAX, E}, {\u0026#34;hls_delete_threshold\u0026#34;, \u0026#34;set number of unreferenced segments to keep before deleting\u0026#34;, OFFSET(hls_delete_threshold), AV_OPT_TYPE_INT, {.i64 = 1}, 1, INT_MAX, E}, {\u0026#34;hls_vtt_options\u0026#34;,\u0026#34;set hls vtt list of options for the container format used for hls\u0026#34;, OFFSET(vtt_format_options_str), AV_OPT_TYPE_STRING, {.str = NULL}, 0, 0, E}, {\u0026#34;hls_allow_cache\u0026#34;, \u0026#34;explicitly set whether the client MAY (1) or MUST NOT (0) cache media segments\u0026#34;, OFFSET(allowcache), AV_OPT_TYPE_INT, {.i64 = -1}, INT_MIN, INT_MAX, E}, {\u0026#34;hls_base_url\u0026#34;, \u0026#34;url to prepend to each playlist entry\u0026#34;, OFFSET(baseurl), AV_OPT_TYPE_STRING, {.str = NULL}, 0, 0, E}, {\u0026#34;hls_segment_filename\u0026#34;, \u0026#34;filename template for segment files\u0026#34;, OFFSET(segment_filename), AV_OPT_TYPE_STRING, {.str = NULL}, 0, 0, E}, {\u0026#34;hls_segment_options\u0026#34;,\u0026#34;set segments files format options of hls\u0026#34;, OFFSET(format_options), AV_OPT_TYPE_DICT, {.str = NULL}, 0, 0, E}, {\u0026#34;hls_segment_size\u0026#34;, \u0026#34;maximum size per segment file, (in bytes)\u0026#34;, OFFSET(max_seg_size), AV_OPT_TYPE_INT, {.i64 = 0}, 0, INT_MAX, E}, {\u0026#34;hls_key_info_file\u0026#34;, \u0026#34;file with key URI and key file path\u0026#34;, OFFSET(key_info_file), AV_OPT_TYPE_STRING, {.str = NULL}, 0, 0, E}, {\u0026#34;hls_enc\u0026#34;, \u0026#34;enable AES128 encryption support\u0026#34;, OFFSET(encrypt), AV_OPT_TYPE_BOOL, {.i64 = 0}, 0, 1, E}, {\u0026#34;hls_enc_key\u0026#34;, \u0026#34;hex-coded 16 byte key to encrypt the segments\u0026#34;, OFFSET(key), AV_OPT_TYPE_STRING, .flags = E}, {\u0026#34;hls_enc_key_url\u0026#34;, \u0026#34;url to access the key to decrypt the segments\u0026#34;, OFFSET(key_url), AV_OPT_TYPE_STRING, {.str = NULL}, 0, 0, E}, {\u0026#34;hls_enc_iv\u0026#34;, \u0026#34;hex-coded 16 byte initialization vector\u0026#34;, OFFSET(iv), AV_OPT_TYPE_STRING, .flags = E}, {\u0026#34;hls_subtitle_path\u0026#34;, \u0026#34;set path of hls subtitles\u0026#34;, OFFSET(subtitle_filename), AV_OPT_TYPE_STRING, {.str = NULL}, 0, 0, E}, {\u0026#34;hls_segment_type\u0026#34;, \u0026#34;set hls segment files type\u0026#34;, OFFSET(segment_type), AV_OPT_TYPE_INT, {.i64 = SEGMENT_TYPE_MPEGTS }, 0, SEGMENT_TYPE_FMP4, E, \u0026#34;segment_type\u0026#34;}, {\u0026#34;mpegts\u0026#34;, \u0026#34;make segment file to mpegts files in m3u8\u0026#34;, 0, AV_OPT_TYPE_CONST, {.i64 = SEGMENT_TYPE_MPEGTS }, 0, UINT_MAX, E, \u0026#34;segment_type\u0026#34;}, {\u0026#34;fmp4\u0026#34;, \u0026#34;make segment file to fragment mp4 files in m3u8\u0026#34;, 0, AV_OPT_TYPE_CONST, {.i64 = SEGMENT_TYPE_FMP4 }, 0, UINT_MAX, E, \u0026#34;segment_type\u0026#34;}, {\u0026#34;hls_fmp4_init_filename\u0026#34;, \u0026#34;set fragment mp4 file init filename\u0026#34;, OFFSET(fmp4_init_filename), AV_OPT_TYPE_STRING, {.str = \u0026#34;init.mp4\u0026#34;}, 0, 0, E}, {\u0026#34;hls_RtspServerfmp4_init_resend\u0026#34;, \u0026#34;resend fragment mp4 init file after refresh m3u8 every time\u0026#34;, OFFSET(resend_init_file), AV_OPT_TYPE_BOOL, {.i64 = 0 }, 0, 1, E }, {\u0026#34;hls_flags\u0026#34;, \u0026#34;set flags affecting HLS playlist and media file generation\u0026#34;, OFFSET(flags), AV_OPT_TYPE_FLAGS, {.i64 = 0 }, 0, UINT_MAX, E, \u0026#34;flags\u0026#34;}, {\u0026#34;single_file\u0026#34;, \u0026#34;generate a single media file indexed with byte ranges\u0026#34;, 0, AV_OPT_TYPE_CONST, {.i64 = HLS_SINGLE_FILE }, 0, UINT_MAX, E, \u0026#34;flags\u0026#34;}, {\u0026#34;temp_file\u0026#34;, \u0026#34;write segment and playlist to temporary file and rename when complete\u0026#34;, 0, AV_OPT_TYPE_CONST, {.i64 = HLS_TEMP_FILE }, 0, UINT_MAX, E, \u0026#34;flags\u0026#34;}, {\u0026#34;delete_segments\u0026#34;, \u0026#34;delete segment files that are no longer part of the playlist\u0026#34;, 0, AV_OPT_TYPE_CONST, {.i64 = HLS_DELETE_SEGMENTS }, 0, UINT_MAX, E, \u0026#34;flags\u0026#34;}, {\u0026#34;round_durations\u0026#34;, \u0026#34;round durations in m3u8 to whole numbers\u0026#34;, 0, AV_OPT_TYPE_CONST, {.i64 = HLS_ROUND_DURATIONS }, 0, UINT_MAX, E, \u0026#34;flags\u0026#34;}, {\u0026#34;discont_start\u0026#34;, \u0026#34;start the playlist with a discontinuity tag\u0026#34;, 0, AV_OPT_TYPE_CONST, {.i64 = HLS_DISCONT_START }, 0, UINT_MAX, E, \u0026#34;flags\u0026#34;}, {\u0026#34;omit_endlist\u0026#34;, \u0026#34;Do not append an endlist when ending stream\u0026#34;, 0, AV_OPT_TYPE_CONST, {.i64 = HLS_OMIT_ENDLIST }, 0, UINT_MAX, E, \u0026#34;flags\u0026#34;}, {\u0026#34;split_by_time\u0026#34;, \u0026#34;split the hls segment by time which user set by hls_time\u0026#34;, 0, AV_OPT_TYPE_CONST, {.i64 = HLS_SPLIT_BY_TIME }, 0, UINT_MAX, E, \u0026#34;flags\u0026#34;}, {\u0026#34;append_list\u0026#34;, \u0026#34;append the new segments into old hls segment list\u0026#34;, 0, AV_OPT_TYPE_CONST, {.i64 = HLS_APPEND_LIST }, 0, UINT_MAX, E, \u0026#34;flags\u0026#34;}, {\u0026#34;program_date_time\u0026#34;, \u0026#34;add EXT-X-PROGRAM-DATE-TIME\u0026#34;, 0, AV_OPT_TYPE_CONST, {.i64 = HLS_PROGRAM_DATE_TIME }, 0, UINT_MAX, E, \u0026#34;flags\u0026#34;}, {\u0026#34;second_level_segment_index\u0026#34;, \u0026#34;include segment index in segment filenames when use_localtime\u0026#34;, 0, AV_OPT_TYPE_CONST, {.i64 = HLS_SECOND_LEVEL_SEGMENT_INDEX }, 0, UINT_MAX, E, \u0026#34;flags\u0026#34;}, {\u0026#34;second_level_segment_duration\u0026#34;, \u0026#34;include segment duration in segment filenames when use_localtime\u0026#34;, 0, AV_OPT_TYPE_CONST, {.i64 = HLS_SECOND_LEVEL_SEGMENT_DURATION }, 0, UINT_MAX, E, \u0026#34;flags\u0026#34;}, {\u0026#34;second_level_segment_size\u0026#34;, \u0026#34;include segment size in segment filenames when use_localtime\u0026#34;, 0, AV_OPT_TYPE_CONST, {.i64 = HLS_SECOND_LEVEL_SEGMENT_SIZE }, 0, UINT_MAX, E, \u0026#34;flags\u0026#34;}, {\u0026#34;periodic_rekey\u0026#34;, \u0026#34;reload keyinfo file periodically for re-keying\u0026#34;, 0, AV_OPT_TYPE_CONST, {.i64 = HLS_PERIODIC_REKEY }, 0, UINT_MAX, E, \u0026#34;flags\u0026#34;}, {\u0026#34;independent_segments\u0026#34;, \u0026#34;add EXT-X-INDEPENDENT-SEGMENTS, whenever applicable\u0026#34;, 0, AV_OPT_TYPE_CONST, { .i64 = HLS_INDEPENDENT_SEGMENTS }, 0, UINT_MAX, E, \u0026#34;flags\u0026#34;}, {\u0026#34;iframes_only\u0026#34;, \u0026#34;add EXT-X-I-FRAMES-ONLY, whenever applicable\u0026#34;, 0, AV_OPT_TYPE_CONST, { .i64 = HLS_I_FRAMES_ONLY }, 0, UINT_MAX, E, \u0026#34;flags\u0026#34;}, {\u0026#34;strftime\u0026#34;, \u0026#34;set filename expansion with strftime at segment creation\u0026#34;, OFFSET(use_localtime), AV_OPT_TYPE_BOOL, {.i64 = 0 }, 0, 1, E }, {\u0026#34;strftime_mkdir\u0026#34;, \u0026#34;create last directory component in strftime-generated filename\u0026#34;, OFFSET(use_localtime_mkdir), AV_OPT_TYPE_BOOL, {.i64 = 0 }, 0, 1, E }, {\u0026#34;hls_playlist_type\u0026#34;, \u0026#34;set the HLS playlist type\u0026#34;, OFFSET(pl_type), AV_OPT_TYPE_INT, {.i64 = PLAYLIST_TYPE_NONE }, 0, PLAYLIST_TYPE_NB-1, E, \u0026#34;pl_type\u0026#34; }, {\u0026#34;event\u0026#34;, \u0026#34;EVENT playlist\u0026#34;, 0, AV_OPT_TYPE_CONST, {.i64 = PLAYLIST_TYPE_EVENT }, INT_MIN, INT_MAX, E, \u0026#34;pl_type\u0026#34; }, {\u0026#34;vod\u0026#34;, \u0026#34;VOD playlist\u0026#34;, 0, AV_OPT_TYPE_CONST, {.i64 = PLAYLIST_TYPE_VOD }, INT_MIN, INT_MAX, E, \u0026#34;pl_type\u0026#34; }, {\u0026#34;method\u0026#34;, \u0026#34;set the HTTP method(default: PUT)\u0026#34;, OFFSET(method), AV_OPT_TYPE_STRING, {.str = NULL}, 0, 0, E}, {\u0026#34;hls_start_number_source\u0026#34;, \u0026#34;set source of first number in sequence\u0026#34;, OFFSET(start_sequence_source_type), AV_OPT_TYPE_INT, {.i64 = HLS_START_SEQUENCE_AS_START_NUMBER }, 0, HLS_START_SEQUENCE_LAST-1, E, \u0026#34;start_sequence_source_type\u0026#34; }, {\u0026#34;generic\u0026#34;, \u0026#34;start_number value (default)\u0026#34;, 0, AV_OPT_TYPE_CONST, {.i64 = HLS_START_SEQUENCE_AS_START_NUMBER }, INT_MIN, INT_MAX, E, \u0026#34;start_sequence_source_type\u0026#34; }, {\u0026#34;epoch\u0026#34;, \u0026#34;seconds since epoch\u0026#34;, 0, AV_OPT_TYPE_CONST, {.i64 = HLS_START_SEQUENCE_AS_SECONDS_SINCE_EPOCH }, INT_MIN, INT_MAX, E, \u0026#34;start_sequence_source_type\u0026#34; }, {\u0026#34;epoch_us\u0026#34;, \u0026#34;microseconds since epoch\u0026#34;, 0, AV_OPT_TYPE_CONST, {.i64 = HLS_START_SEQUENCE_AS_MICROSECONDS_SINCE_EPOCH }, INT_MIN, INT_MAX, E, \u0026#34;start_sequence_source_type\u0026#34; }, {\u0026#34;datetime\u0026#34;, \u0026#34;current datetime as YYYYMMDDhhmmss\u0026#34;, 0, AV_OPT_TYPE_CONST, {.i64 = HLS_START_SEQUENCE_AS_FORMATTED_DATETIME }, INT_MIN, INT_MAX, E, \u0026#34;start_sequence_source_type\u0026#34; }, {\u0026#34;http_user_agent\u0026#34;, \u0026#34;override User-Agent field in HTTP header\u0026#34;, OFFSET(user_agent), AV_OPT_TYPE_STRING, {.str = NULL}, 0, 0, E}, {\u0026#34;var_stream_map\u0026#34;, \u0026#34;Variant stream map string\u0026#34;, OFFSET(var_stream_map), AV_OPT_TYPE_STRING, {.str = NULL}, 0, 0, E}, {\u0026#34;cc_stream_map\u0026#34;, \u0026#34;Closed captions stream map string\u0026#34;, OFFSET(cc_stream_map), AV_OPT_TYPE_STRING, {.str = NULL}, 0, 0, E}, {\u0026#34;master_pl_name\u0026#34;, \u0026#34;Create HLS master playlist with this name\u0026#34;, OFFSET(master_pl_name), AV_OPT_TYPE_STRING, {.str = NULL}, 0, 0, E}, {\u0026#34;master_pl_publish_rate\u0026#34;, \u0026#34;Publish master play list every after this many segment intervals\u0026#34;, OFFSET(master_publish_rate), AV_OPT_TYPE_INT, {.i64 = 0}, 0, UINT_MAX, E}, {\u0026#34;http_persistent\u0026#34;, \u0026#34;Use persistent HTTP connections\u0026#34;, OFFSET(http_persistent), AV_OPT_TYPE_BOOL, {.i64 = 0 }, 0, 1, E }, {\u0026#34;timeout\u0026#34;, \u0026#34;set timeout for socket I/O operations\u0026#34;, OFFSET(timeout), AV_OPT_TYPE_DURATION, { .i64 = -1 }, -1, INT_MAX, .flags = E }, {\u0026#34;ignore_io_errors\u0026#34;, \u0026#34;Ignore IO errors for stable long-duration runs with network output\u0026#34;, OFFSET(ignore_io_errors), AV_OPT_TYPE_BOOL, { .i64 = 0 }, 0, 1, E }, {\u0026#34;headers\u0026#34;, \u0026#34;set custom HTTP headers, can override built in default headers\u0026#34;, OFFSET(headers), AV_OPT_TYPE_STRING, { .str = NULL }, 0, 0, E }, { NULL }, }; static const AVClass hls_class = { .class_name = \u0026#34;hls muxer\u0026#34;, .item_name = av_default_item_name, .option = options, .version = LIBAVUTIL_VERSION_INT, }; ff_hls_muxer 调用的生命周期如下:\nh l s _ i n i t h l s _ w r i t e _ h e a d e r h l s _ w r i t e _ p a c k e t h l s _ w r i t e _ t r a i l e r h l s _ d e i n i t 其中重点关注 hls_write_packet 函数，其调用流程如下：\nmain 函数调用 ffmpeg_parse_options，通过 of_open 申请内存，初始化 Muxer，并放入全局 output_files 数组 of_open 中较关键为 avformat_alloc_output_context2 ，根据输出格式申请 AVFormatContext ffmpeg_mux.c 初始化后启动 muxer_thread，唯一参数为 Muxer， muxer_thread 轮询 mux-\u0026gt;tq 读取帧信息 AVPacket ffmpeg_mux.c write_packet 修正时间相关数据 mux.c write_packets_common, 如果该 bitstream 没有 filter 则通过 write_packet_common 处理 mux.c write_packet_common 处理帧时长，注意此时参数 AVFormatContext 为 mux-\u0026gt;fc，即 hls mux.c write_packet 修正相关数据 hlsenc.c hls_write_packet hls_write_packet 函数实现的功能如下：\n找出 AVPacket 对应的 VariantStream 与 AVFormatContext 修正 end_pts 与 start_pts 时间参数 检查是否需要切分新 Fragment，譬如是否设置 split_by_time 参数，当前帧是否为关键帧 处理 ref_pkt （暂时未知作用） 如果通过 split_by_time 参数指定分割时间，并且为I帧，则进行分割操作, 通过 av_write_frame 写入 NULL pkt，触发 movenc.c mov_write_packet 函数调用 mov_flush_fragment 完成 如果不需要分片，则将 AVPacket 发送到 ff_write_chained 处理，注意此时的 AVFormatContext 已经转换为 s-\u0026gt;priv_data-\u0026gt;var_streams[i]-\u0026gt;avf，即 mp4 ff_write_chained 修正 pts 后发送到 av_write_frame 重新进入 mux.c write_packets_common，只不过此时 pkt 为 mp4 格式，会发送到 movenc.c 的 mov_write_packet 函数进行处理 mov_write_packet 为 Mp4 帧封装函数，实现的功能如下：\n如果接收到空 AVPacket，则调用 mov_flush_fragment 进行 Fragmented Mp4 封装，否则调用 mov_write_single_packet（不考虑与我们场景不相干分支） mov_write_single_packet 先修正 AVPacket 数据，获取 mov 与 trk 相关参数，判断是否需要 mov_auto_flush_fragment，然后调用 ff_mov_write_packet； ff_mov_write_packet 写入 mdat，然后将帧数据 MOVIentry 添加到 trk-\u0026gt;cluster，后续写入 fMp4 相关数据 Box 时会大量依赖 trk-\u0026gt;cluster mov_flush_fragment 为 Fragmented Mp4 文件封装函数，实现功能如下：\n计算、修正 track 的时长与 end_pts 写 moov box 写 moof box ","permalink":"https://yplam.com/posts/av/ffmpeg-hls-fmp4/","summary":"\u003cp\u003e本笔记记录 FFmpeg HLS Fragmented Mp4  封装过程，主要关注点为 Fragmented Mp4 容器格式。\u003c/p\u003e","title":"FFmpeg HLS Fragmented Mp4 封装过程分析"},{"content":"最近在一个 mips 架构的嵌入式 Linux 上用到 ring 与 rustls，由于 ring 0.16.20 对 mips 的支持较差，而 0.17 又迟迟不发布，只能魔改一堆包。\n其中重点是 rustls，并且不同上层包对 rustls 版本依赖还不一样，幸好 cargo patch.crates-io 机制可以比较容易兼容项目中同时 patch 多个版本。\n修改 Cargo.toml\n[patch.crates-io] rustls = { version = \u0026#34;0.19\u0026#34;, path = \u0026#34;./third_party/rustls-0.19.1\u0026#34; } rustls1 = { version = \u0026#34;0.21\u0026#34;, package = \u0026#34;rustls\u0026#34;, path = \u0026#34;./third_party/rustls-0.21.1\u0026#34; } ","permalink":"https://yplam.com/posts/rust/patch-crates-io-multipile-version/","summary":"\u003cp\u003e最近在一个 mips 架构的嵌入式 Linux 上用到 ring 与 rustls，由于 ring 0.16.20 对 mips 的支持较差，而 0.17 又迟迟不发布，只能魔改一堆包。\u003c/p\u003e","title":"Rust patch.crates-io 同一 package 多版本支持"},{"content":"最近需要为一个 IPC 项目实现 RTSP 功能，记录一下 Live555 实现 ISP 获取 H265 帧实现 RTSP 服务端的过程。\nLive555 代码结构相对比较清晰：\nR F t r s a p m S e e d r S v o e u r r c e M F e r d a i m a e S d e S s o s u i r o c n e M R e T d P i S a i S n u k b S e s s i o n 其中 FramedSource 可以通过多层嵌套的方式实现 filter 功能。\n官方提供大量测试代码以及若干范例，然而大多视频源来自文件，因此需要针对 ISP 视频流的应用场景做修改。要点如下：\n实现 FramedSource 子类，可以参考 DeviceSource 的实现，但测试中发现没有必要实现新帧到达事件触发的过程，因为 rtsp 连接后会调用 FramedSource 的 doGetNextFrame 方法，在此方法中如果调用 FramedSource::afterGetting(this) 则会继续触发 doGetNextFrame 的调用，因此只需要考虑缓冲区无数据的情况下通过 envir().taskScheduler().scheduleDelayedTask() 操作延时触发即可。\n需要注意的是，请勿阻塞的形式等待缓冲区数据到来，因为 live555 是单线程运行，阻塞会影响其他功能的正确执行。\n实现 OnDemandServerMediaSubsession 子类，实现 createNewStreamSource 与 createNewRTPSink 方法，针对 ISP 帧的形式，需要设置 reuseFirstSource 为 True\n需要注意 ISP 获取的视频帧信息是否带有 00000001 等帧头信息，根据实际情况使用 H265VideoStreamFramer 或 H265VideoStreamDiscreteFramer 等。\n","permalink":"https://yplam.com/posts/av/live555-rtsp-stream/","summary":"\u003cp\u003e最近需要为一个 IPC 项目实现 RTSP 功能，记录一下 Live555 实现 ISP 获取 H265 帧实现 RTSP 服务端的过程。\u003c/p\u003e","title":"Live555 RTSP 视频流服务端开发笔记"},{"content":"最近发现 ESP32 相对于其他品牌单片机而言对 Rust 的支持还算完善，特别是对 std 的支持，使得很多对嵌入式而言相对高阶的库可以非常简单地使用。\n譬如 chrono + clokwerk 这两个库的组合就可以很容易地实现一个相对完善的定时任务功能；更不用说像 json、mqtt、http 等基础网络功能的支持。并且与嵌入式 C 对比，由于其内容安全特性，可以避免很多 C 程序员喜欢用的提前分配静态内存的技巧，使得其在功能复杂的情况下内存占用甚至比C更低。\n最近基于 Rust + ESP32 实现了一个简单的 CO2 传感器数据上报项目，通过 mqtt 接入 HomeAssistant 项目地址 https://github.com/yplam/esp-rust-mqtt-sensor\n","permalink":"https://yplam.com/posts/embedded/esp32-rust-mqtt-homeassistant/","summary":"\u003cp\u003e最近发现 ESP32 相对于其他品牌单片机而言对 Rust 的支持还算完善，特别是对 std 的支持，使得很多对嵌入式而言相对高阶的库可以非常简单地使用。\u003c/p\u003e","title":"基于 Rust 实现 ESP32 HomeAssistant MQTT CO2 传感器"},{"content":"手上有几台闲置的几台斐讯 N1 刚好达到安装 Kubernetes 的最低硬件要求，于是趁着五一假期在家捣弄个“高可用”斐讯 N1 K8S 集群，用于运行 HomeAssistant\n硬件准备 1 台树莓派 CM4+256G SSD，5 台 N1+5 个 32G 迷你 U 盘，两个 cc2652p zigbee dongle， 一个 8 口千兆交换机，明纬 12V5A 电源，1 分 5DC 电源线，短网线若干，厚双面胶。\n一顿操作下来，刚好整整齐齐的粘成一块：\nArmbian 准备 得益于 N1 折腾生态比较完善，比较容易找到系统打包脚本，https://github.com/yunsur/phicomm-n1\n通过修改 config/boards/arm-64.conf 把不需要的包删除，尽量让操作系统保持简洁\n-------------------------- config/boards/arm-64.conf -------------------------- index 9d24069..0a1d99a 100644 @@ -25,5 +25,5 @@ EXTRAWIFI=\u0026#34;no\u0026#34; WIREGUARD=\u0026#34;yes\u0026#34; INSTALL_HEADERS=\u0026#34;yes\u0026#34; INSTALL_DOCKER=\u0026#34;yes\u0026#34; -PACKAGE_LIST_BOARD=\u0026#34;bluez bluez-tools bluetooth libubootenv-tool\u0026#34; -PACKAGE_LIST_FAMILY=\u0026#34;autojump avahi-daemon samba samba-common-bin samba-vfs-modules smbclient tcpdump ntpdate python3 python3-pip docker-ce docker-compose\u0026#34; +PACKAGE_LIST_BOARD=\u0026#34;\u0026#34; +PACKAGE_LIST_FAMILY=\u0026#34;avahi-daemon lvm2\u0026#34; ------------------ config/kernel/linux-arm-64-current.config ------------------ index fa4d782..5829e3e 100644 @@ -1783,7 +1783,7 @@ CONFIG_NET_9P=m CONFIG_NET_9P_VIRTIO=m # CONFIG_NET_9P_DEBUG is not set # CONFIG_CAIF is not set -CONFIG_CEPH_LIB=m +CONFIG_CEPH_LIB=y # CONFIG_CEPH_LIB_PRETTYDEBUG is not set # CONFIG_CEPH_LIB_USE_DNS_RESOLVER is not set CONFIG_NFC=m @@ -2238,7 +2238,7 @@ CONFIG_ZRAM_WRITEBACK=y CONFIG_BLK_DEV_LOOP=y CONFIG_BLK_DEV_LOOP_MIN_COUNT=8 CONFIG_BLK_DEV_CRYPTOLOOP=m -CONFIG_BLK_DEV_DRBD=m +CONFIG_BLK_DEV_DRBD=y # CONFIG_DRBD_FAULT_INJECTION is not set CONFIG_BLK_DEV_NBD=m # CONFIG_BLK_DEV_SX8 is not set @@ -2248,7 +2248,7 @@ CONFIG_BLK_DEV_RAM_SIZE=4096 # CONFIG_CDROM_PKTCDVD is not set CONFIG_ATA_OVER_ETH=m CONFIG_VIRTIO_BLK=m -# CONFIG_BLK_DEV_RBD is not set +CONFIG_BLK_DEV_RBD=y # CONFIG_BLK_DEV_RSXX is not set # @@ -8152,7 +8152,7 @@ CONFIG_SUNRPC_SWAP=y CONFIG_RPCSEC_GSS_KRB5=m # CONFIG_SUNRPC_DISABLE_INSECURE_ENCTYPES is not set # CONFIG_SUNRPC_DEBUG is not set -# CONFIG_CEPH_FS is not set +CONFIG_CEPH_FS=y CONFIG_CIFS=y CONFIG_CIFS_STATS2=y CONFIG_CIFS_ALLOW_INSECURE_LEGACY=y 集群部署 因为是以实验为目标，集群使用 3 master + 3 worker ，ETCD stacked，keepalived + haproxy 实现 apiserver 的高可用\n其中 master[0] 为 raspberry pi 4，其他 5 台为 N1\nvip 192.168.2.230 node1 ansible_host=192.168.2.2 node2 ansible_host=192.168.2.231 node3 ansible_host=192.168.2.232 node4 ansible_host=192.168.2.233 node5 ansible_host=192.168.2.234 node6 ansible_host=192.168.2.235 部署脚本基于 ansible，直接 clone 以下项目：https://github.com/TimeBye/kubeadm-ha，然后根据需要修改配置即可，譬如关掉系统资源检查\n注意 1：N1 为 arm64 架构，某些较旧的镜像可能不支持（譬如一些过旧的 nginx），因此适当时候要 \u0026lsquo;kubectl get pods -A\u0026rsquo; 查看一下， 如果是 CrashLoopBackOff 状态可优先排查一下用到的镜像版本是否支持 arm64\n注意 2: armbian 启动默认会开启 swap，需要通过 /etc/default/armbian-zram-config 配置\n部署 lb + ingress 使用 metallb 作为二层负载均衡，nginx ingress\nhelm repo add metallb https://metallb.github.io/metallb helm upgrade --install metallb metallb/metallb --namespace metallb-system --create-namespace -f metallb.yaml helm upgrade --install ingress-nginx ingress-nginx/ingress-nginx --namespace ingress-nginx --create-namespace -f ingress.yaml 部署 nfs 尝试了一通 ceph，发现 N1 的渣资源根本跑不起来，于是决定把数据存在局域网一台 zfs 的 nas 上\nhelm repo add nfs-subdir-external-provisioner https://kubernetes-sigs.github.io/nfs-subdir-external-provisioner/ helm install nfs-subdir-external-provisioner nfs-subdir-external-provisioner/nfs-subdir-external-provisioner --set nfs.server=xxx --set nfs.path=/data/k8s --set storageClass.provisionerName=k8s-sigs.io/nfs-subdir-external-provisioner --set image.repository=xxx 部署 homeassistant 暂时只想将一些 zigbee 传感器接入，于是部署了以下三个服务：\nkubectl apply -f pvc.yaml helm install mosquitto k8s-at-home/mosquitto -f mosquitto.yaml helm install home-assistant k8s-at-home/home-assistant -f homeassistant.yaml helm install zigbee2mqtt k8s-at-home/zigbee2mqtt -f zigbee2mqtt.yaml 其中 config 文件通过 nfs pvc 配置，zigbee2mqtt 绑定到 zigbee dongle 所在的 node\ndocker 配置代理 整个过程最麻烦的反而是镜像下载被墙问题，如果你使用 docker，需要通过修改 systemd 配置\nsudo mkdir -p /etc/systemd/system/docker.service.d sudo touch /etc/systemd/system/docker.service.d/proxy.conf [Service] Environment=\u0026#34;HTTP_PROXY=http://proxy.example.com:8080/\u0026#34; Environment=\u0026#34;HTTPS_PROXY=http://proxy.example.com:8080/\u0026#34; Environment=\u0026#34;NO_PROXY=localhost,127.0.0.1,.example.com\u0026#34; ","permalink":"https://yplam.com/posts/k8s/k8s-n1/","summary":"\u003cp\u003e手上有几台闲置的几台斐讯 N1 刚好达到安装 Kubernetes 的最低硬件要求，于是趁着五一假期在家捣弄个“高可用”斐讯 N1 K8S 集群，用于运行 HomeAssistant\u003c/p\u003e","title":"斐讯 N1 搭建私有 Kubernetes 集群运行 HomeAssistant"},{"content":"本笔记并不是一个完整的关于 OpenWRT 移植的笔记，只作为个人备忘用。同时亦分享出来给需要的朋友作为参考。水平有限，如果有出错地方请反馈 yplam(at)yplam.com\n嵌入式 Linux 三大件：uboot，kernel，rootfs；uboot 暂时不打算动，kernel 之前已编译测试过可启动，所以剩下只需要将 OpenWRT 的 rootfs 构建出来，那么 OpenWRT 运行起来应该也不是很难的事。\n资料搜集 可能比较少人在 OpenWRT 上用 imx6ull，能搜集的资料并不多，不过够用\ni.mx6ul 移植Openwrt https://blog.csdn.net/wind0419/article/details/78036522 i.mx6ul开发板移植openwrt系统 https://blog.csdn.net/qq_40614144/article/details/105538483 一个托管在git上面的 imx6ull openwrt 移植项目 https://github.com/iuncuim/openwrt-imx6ull 增加 target imx6ull 参考上面的 git 项目，在 OpenWRT 源码 target/linux 下添加一个 imx6ull 目录，然后将我们之前内核编译的 .config 文件拷贝到 target/linux/imx6ull/config-4.14 。\n由于我们用的是官方内核，所以 patch 相关的可以忽略掉。\n最小配置的 imx6ull 目录如下：\n. ├── base-files │ └── etc │ └── inittab ├── config-4.14 ├── image │ └── Makefile ├── Makefile └── profiles └── 100-generic.mk Makefile:\n# # Copyright (C) 2013-2014 OpenWrt.org # # This is free software, licensed under the GNU General Public License v2. # See /LICENSE for more information. # include $(TOPDIR)/rules.mk ARCH:=arm BOARD:=imx6ull BOARDNAME:=Freescale i.MX 6 ULL FEATURES:=audio display fpu gpio rtc usb usbgadget squashfs ext4 targz nand ubifs CPU_TYPE:=cortex-a7 CPU_SUBTYPE:=neon-vfpv4 KERNEL_PATCHVER:=4.14 include $(INCLUDE_DIR)/target.mk KERNELNAME:=zImage DEFAULT_PACKAGES += uboot-envtools $(eval $(call BuildTarget)) profiles/100-generic.mk\n# # Copyright (C) 2013 OpenWrt.org # # This is free software, licensed under the GNU General Public License v2. # See /LICENSE for more information. # define Profile/Generic PRIORITY:=1 NAME:=Generic (default) endef define Profile/Generic/Description Package set compatible with most Freescale i.MX 6 ull based boards. endef $(eval $(call Profile,Generic)) image/Makefile\n# # Copyright (C) 2013 OpenWrt.org # # This is free software, licensed under the GNU General Public License v2. # See /LICENSE for more information. # include $(TOPDIR)/rules.mk include $(INCLUDE_DIR)/image.mk KERNEL_LOADADDR:=0x80800000 define Device/Default PROFILES := Generic FILESYSTEMS := squashfs ext4 KERNEL_INSTALL := 1 KERNEL_SUFFIX := -uImage KERNEL_NAME := zImage KERNEL_PREFIX := $$(IMAGE_PREFIX) endef $(eval $(call BuildImage)) base-files/etc/inittab\n::sysinit:/etc/init.d/rcS S boot ::shutdown:/etc/init.d/rcS K shutdown ::askconsole:/usr/libexec/login.sh tty1::askfirst:/usr/libexec/login.sh 以上配置基于个人猜测以及参考以下文档：\nhttps://openwrt.org/docs/techref/image.makefile https://openwrt.org/docs/techref/process.boot https://openwrt.org/docs/guide-user/additional-software/imagebuilder#addingmodifying_profiles 编译 ROOTFS 编译过程与常规类似，主要区别是选择我们自己的内核目录，以及工具链使用 glibc 而不是默认的 musl（推测原因是我们的内核并没有打 musl 相关的 patch）。\n选好 Target System， Target Profile，编译。如无意外会生成我们想要的 rootfs：bin/targets/imx6ull/generic-glibc/openwrt-imx6ull-generic-rootfs.tar.gz\n将 rootfs 解压到 SD 卡分区，启动开发板，更改 uboot 的内核启动相关配置到我们的内核与rootfs，启动\n","permalink":"https://yplam.com/posts/embedded/imx6ull-openwrt/","summary":"\u003cp\u003e本笔记并不是一个完整的关于 OpenWRT 移植的笔记，只作为个人备忘用。同时亦分享出来给需要的朋友作为参考。水平有限，如果有出错地方请反馈 yplam(at)yplam.com\u003c/p\u003e","title":"iMX6ULL 运行 OpenWRT"},{"content":"鉴于之前玩的 MT7688A 已经停产并且模块断货，最近把目光投向一款新芯片：iMX6ULL，因为其起点价格在接受范围，最低配置的核心板价格在百元以内，128M+128M 足够跑我的OpenThread网关，通用芯片该有的功能都有，按功能来算的话比 MT7688A 性价比还高。\n拿到开发板，目标是跑 OpenWRT + OpenThread 网关，MQTT/MQTT-SN 或者 LWM2M 服务，把手上一堆传感器、控制器接上，不依赖外部服务运行。\n原装系统运行在 nand 上，不方便折腾，于是准备用 SD 卡启动的方式，修改起来很简单，热风枪把一个配置电阻换个位置。\n由于还不熟悉此板卡 uboot，内核的编译，暂时先用着随板带的固件。\n写入uboot uboot 固件使用 uboot-myimx6ek140-6y-256m-nand.imx，imx 文件格式在这里有个比较详细的介绍：https://www.cnblogs.com/Lioker/p/13219519.html。芯片启动时内部 ROM 程序会按 imx 文件格式从 SD 卡的 0x400 地址加载相关配置，并且启动。\n所以我们要以以下命令将 uboot 写入sd卡：\nsudo dd if=uboot-myimx6ek140-6y-256m-nand.imx of=/dev/sdx bs=1k seek=1 conv=fsync 上面的命令含义是以 1k 的块大小写入，并且跳过第一个块（第一个块一般为分区表）；详细解说可以参考 i.MX_Linux_User\u0026rsquo;s_Guide.pdf 4.3 章节以及上面关于 imx 格式的文章。\n顺便吐槽一下国内某些卖开发板的，文档就只是一堆关于软件使用，脚本运行，却完全不涉及这么操作的原理\nSD卡分区，烧写文件 如果平时用的是 Linux 系统，SD 卡的分区就简单一点，分两个区，一个 fat32 格式用来放内核文件以及设备树（不确定为何要 fat32，看自带的 uboot 是已经支持 ext4 ），一个选一个你喜欢的格式，用来放根目录；可以按官方推荐的分区方式：\n前面 10MB 空出来，因为要留给 uboot 10MB 开始，分 500MB 格式化成 FAT32 用来存放内核与设备树文件 后面一个 ext3/ext4 用来做根文件 通过 fdisk 与 mkfs 指令完成，参考官方文档（需要注意sdx需要与你sd卡对应）：\n$ sudo fdisk /dev/sdx Type the following parameters (each followed by \u0026lt;ENTER\u0026gt;): p [lists the current partitions] d [to delete existing partitions. Repeat this until no unnecessary partitions are reported by the \u0026#39;p\u0026#39; command to start fresh.] n [create a new partition] p [create a primary partition - use for both partitions] 1 [the first partition] 20480 [starting at offset sector] 1024000 [size for the first partition to be used for the boot images] p [to check the partitions] np2 1228800 [starting at offset sector, which leaves enough space for the kernel, the bootloader and its configuration data] \u0026lt;enter\u0026gt; [using the default value will create a partition that extends to the last sector of the media] p [to check the partitions] w [this writes the partition table to the media and fdisk exits] 格式化：\nsudo mkfs.fat -F32 -v -n \u0026#34;BOOT\u0026#34; /dev/sdx1 sudo mkfs.ext4 -F -L \u0026#34;rootfs\u0026#34; /dev/sdx2 然后将内核文件、dtb、rootfs分别拷贝过去。\nuboot 启动 将 SD 卡换过去，加电，如无以外 uboot 应该是可以起来，内核起不来（如果内核也能起来的话可以uboot启动的时候按一下键盘暂停内核启动）\n在 uboot 终端运行 printenv 命令，查看厂家预定义的一些参数根据自己的需要进行修改。\n譬如在我的开发板上运行下面的指令就可以从 SD 卡启动：\nfatload mmc 0:1 ${kernel_addr_r} zimage-myimx6a7 fatload mmc 0:1 ${fdt_addr_r} myimx6ek140-6y-256m-nand.dtb setenv bootargs console=${console},${baudrate} root=/dev/mmcblk0p2 bootz ${kernel_addr_r} - ${fdt_addr_r} 上面指令依次从 SD 卡的第一个分区加载 zimage-myimx6a7 内核文件到内核启动的内存地址，myimx6ek140-6y-256m-nand.dtb 设备树文件到设备树内存地址，然后设置 bootargs （传递给内核的启动参数），然后启动。\n参数化一下：\nsetenv my_load_ker fatload mmc 0:1 ${kernel_addr_r} zimage-myimx6a7 setenv my_load_dtb fatload mmc 0:1 ${fdt_addr_r} myimx6ek140-6y-256m-nand.dtb setenv my_bootz bootz ${kernel_addr_r} - ${fdt_addr_r} setenv bootargs console=${console},${baudrate} root=/dev/mmcblk0p2 saveenv 然后就可以用此单行指令启动：\nrun my_load_ker; run my_load_dtb; run my_bootz 更进一步：\nsetenv bootcmd_my \u0026#34;run my_load_ker; run my_load_dtb; run my_bootz\u0026#34; setenv my_env_flag set saveenv 或者直接改掉原开发板的 bootcmd\nsetenv bootcmd \u0026#34;run my_load_ker; run my_load_dtb; run my_bootz\u0026#34; saveenv 重启，可以直接从SD卡启动\n参考：\nhttps://blog.csdn.net/wofeile880_jian/article/details/64444029 i.MX_Linux_User\u0026rsquo;s_Guide.pdf ","permalink":"https://yplam.com/posts/embedded/imx6ull-boot-sd-card/","summary":"\u003cp\u003e鉴于之前玩的 MT7688A 已经停产并且模块断货，最近把目光投向一款新芯片：iMX6ULL，因为其起点价格在接受范围，最低配置的核心板价格在百元以内，128M+128M 足够跑我的OpenThread网关，通用芯片该有的功能都有，按功能来算的话比 MT7688A 性价比还高。\u003c/p\u003e","title":"iMX6ULL SD卡系统制作与启动"},{"content":"最近想在 iMX6ULL 上运行 OpenWRT，第一步准备将内核版本升到 4.14，按着官方说明操作一通，顺便在此记录一下\n源码下载：\ngit clone https://source.codeaurora.org/external/imx/linux-imx git remote show origin git branch -a git checkout -b imx_4.14.98_2.0.0_ga 编译：\ncd linux-imx/ export ARCH=arm export CROSS_COMPILE=/src/gcc-linaro-7.5/bin/arm-linux-gnueabihf- cp arch/arm/configs/imx_v6_v7_defconfig ./.config make menuconfig make V=99 -j8 如无意外会在 arch/arm/boot 下生成 zImage，拷贝到开发板覆盖原内核，启动。\n如果是一些还不是很稳定的分支的话可能会有各种问题，一般看报错信息、修改相关代码，以及 Google 都能解决。实在不行，换一个分支再跑一遍。\nPS：如果你的开发板供应商有提供内核源码，而你又不清楚自己编译的源码能不能兼容的话；可以通过一个简单方式验证，就是从 imx 官方 git 下载最接近的分支版本下来，然后 diff -r 比对一下；大多数情况下 99% 以上的代码是一致的，区别只是官方开发板的 dts，以及部分外设驱动的修改。\n","permalink":"https://yplam.com/posts/embedded/imx6ull-kernel-compile/","summary":"\u003cp\u003e最近想在 iMX6ULL 上运行 OpenWRT，第一步准备将内核版本升到 4.14，按着官方说明操作一通，顺便在此记录一下\u003c/p\u003e","title":"iMX6ULL 内核编译"},{"content":"OpenThread 边界路由器的作用是作为 Thread 网络与其他基于IP的网络（如WIFI、以太网）的桥梁。有了边界路由器的存在才让 Thread 网络中的设备成了跟手机、电脑等对等的一员（是的，基于IP就是那么自信）。\nOpenThread 官方提供 Docker、 BeagleBone Black、Raspberry Pi 3B 的支持（代码中 OpenWRT 也是有支持的，只是可能还未正式稳定）。本文将尽量详细地记录 Raspberry Pi 3B 配置成边界路由器的过程。\n树莓派基础配置 第一步当然是下载镜像，并且写入到SD卡。官网地址：https://www.raspberrypi.org/downloads/raspberry-pi-os/ 。Linux系统下可以直接用以下命令写入镜像:\n# 注意：请根据真实情况选择磁盘，不然可能会导致你的数据丢失 sudo dd bs=4M if=2020-08-20-raspios-buster-armhf-lite.img of=/dev/mmcblk0 conv=fsync 启用wifi与ssh 使用headless的配置方式，不需要显示器与外接键盘。在SD卡的 boot 分区中创建一个空的 ssh 文件：\ncd /run/media/yplam/boot touch ssh 在刚刚那个 boot 分区新建一个 wpa_supplicant.conf 文件，输入 WIFI 网络信息：\ncountry=CN ctrl_interface=DIR=/var/run/wpa_supplicant GROUP=netdev update_config=1 network={ ssid=\u0026#34;NETWORK-NAME\u0026#34; psk=\u0026#34;NETWORK-PASSWORD\u0026#34; } 插入SD卡上电启动，如果有mdns的话直接 ：\nping raspberrypi.local 获取IP，如果没有则登录路由器把它找出来，然后ssh登录，用户名pi，密码 raspberry 。\n基础软件安装 sudo apt install git OTBR编译安装 git clone https://github.com/openthread/ot-br-posix cd ot-br-posix ./script/bootstrap ./script/setup 注意，可能需要改改 script/_dns64 中关于 dns 服务器的配置（国内无法访问）\nRCP 配置 编译 RCP 固件，如 NRF52840 可以使用以下编译选项：\ncd /src/openthread/ ./bootstrap make -f examples/Makefile-nrf52840 BORDER_AGENT=1 BORDER_ROUTER=1 COMMISSIONER=1 UDP_FORWARD=1 USB=1 LINK_RAW=1 BOOTLOADER=USB cd /src/openthread/output/nrf52840/bin arm-none-eabi-objcopy -O ihex ot-rcp ot-rcp.hex 插入 RCP 到树莓派 USB 口，查看：\nls /dev/tty* 名称为 /dev/ttyACM* 的设备即为 RCP；修改配置文件 /etc/default/otbr-agent\nOTBR_AGENT_OPTS=\u0026#34;-I wpan0 spinel+hdlc+uart:///dev/ttyACM0\u0026#34; 修改配置后重启系统，运行以下命令：\nsudo systemctl status 如果安装正常，则可以看到相关服务正常运行：\navahi-daemon.service otbr-agent.service otbr-web.service 而运行下面命令可以看到OpenThread网络为 disabled 状态\nsudo ot-ctl state AP模式配置 树莓派可以配置运行在 AP 模式，其他设备可以接入树莓派提供的网络来管理 OpenThread 网络。\n安装以下软件：\nsudo apt-get install hostapd dnsmasq tayga hostapd — 允许使用树莓派的WIFI允许在AP模式 dnsmasq — 提供 DHCP 与 DNS 服务 tayga — NAT64服务，提供外网 IPV4 地址到 IPV6 地址的转换 修改文件 /etc/dhcpcd.conf，末尾增加一行\ndenyinterfaces wlan0 新建文件 /etc/network/interfaces.d/wlan0\nallow-hotplug wlan0 iface wlan0 inet static address 192.168.1.2 netmask 255.255.255.0 network 192.168.1.0 broadcast 192.168.1.255 配置 /etc/hostapd/hostapd.conf，因为使用的是 PI3B+，支持5G网络，配置有所不同\n# The Wi-Fi interface configured for static IPv4 addresses interface=wlan0 # Use the 802.11 Netlink interface driver driver=nl80211 # The user-defined name of the network ssid=BorderRouter-AP # Use the 5GHz band hw_mode=a # Use channel 6 channel=40 # Enable 802.11n ieee80211n=1 # Enable WMM wmm_enabled=1 require_ht=1 ht_capab=[HT40-][DSSS_CCK-40] # Accept all MAC addresses macaddr_acl=0 # Use WPA authentication auth_algs=1 # Require clients to know the network name ignore_broadcast_ssid=0 # Use WPA2 wpa=2 # Use a pre-shared key wpa_key_mgmt=WPA-PSK # The network passphrase wpa_passphrase=12345678 # Use AES, instead of TKIP rsn_pairwise=CCMP 修改 /etc/default/hostapd\nDAEMON_CONF=\u0026#34;/etc/hostapd/hostapd.conf\u0026#34; sudo systemctl unmask hostapd sudo systemctl start hostapd 修改 /etc/systemd/system/hostapd.service\n[Unit] Description=Hostapd IEEE 802.11 Access Point After=sys-subsystem-net-devices-wlan0.device BindsTo=sys-subsystem-net-devices-wlan0.device [Service] Type=forking PIDFile=/var/run/hostapd.pid ExecStart=/usr/sbin/hostapd -B /etc/hostapd/hostapd.conf -P /var/run/hostapd.pid [Install] WantedBy=multi-user.target 在 /etc/rc.local 的 exit 0 之前添加\nsudo service hostapd start 重启树莓派，可以看到多了一个名叫 BorderRouter-AP 的 wifi 网络可以加入。\n配置 dnsmasq 修改 /etc/dnsmasq.conf\n# The Wi-Fi interface configured for static IPv4 addresses interface=wlan0 # Explicitly specify the address to listen on listen-address=192.168.1.2 # Bind to the interface to make sure we aren\u0026#39;t sending things elsewhere bind-interfaces # Forward DNS requests to the Google DNS server=119.29.29.29 # Don\u0026#39;t forward short names domain-needed # Never forward addresses in non-routed address spaces bogus-priv # Assign IP addresses between 192.168.1.50 and 192.168.1.150 with a 12 hour lease time dhcp-range=192.168.1.50,192.168.1.150,12h 修正 /lib/systemd/system/bind9.service 与 dnsmasq 的冲突\nAfter=network.target dnsmasq.service 配置 tayga 修改 /etc/tayga.conf 关于以下配置项\nprefix 64:ff9b::/96 dynamic-pool 192.168.255.0/24 ipv6-addr 2001:db8:1::1 ipv4-addr 192.168.255.1 启用 tayga\nsudo systemctl enable tayga 使能网络转发\nsudo sh -c \u0026#34;echo 1 \u0026gt; /proc/sys/net/ipv4/ip_forward\u0026#34; sudo sh -c \u0026#34;echo 1 \u0026gt; /proc/sys/net/ipv6/conf/all/forwarding\u0026#34; 为了重启后能生效，修改配置文件 /etc/sysctl.conf，更改对应项配置\n使能 NAT44\nsudo iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE 使能 wlan0 与 eth0 之间的转发\nsudo iptables -A FORWARD -i eth0 -o wlan0 -m state --state RELATED,ESTABLISHED -j ACCEPT sudo iptables -A FORWARD -i wlan0 -o eth0 -j ACCEPT 保存iptables配置\nsudo sh -c \u0026#34;iptables-save \u0026gt; /etc/iptables.ipv4.nat\u0026#34; 在 /etc/rc.local 的 exit 前增加\niptables-restore \u0026lt; /etc/iptables.ipv4.nat 重启系统，查看各服务是否正常启动，譬如 ping -6 一个外网 IP\nping -6 64:ff9b::*** 创建 OpenThread 网络 sudo ot-ctl panid 0xc80b sudo ot-ctl extpanid f37fcf5bc5cbe195 sudo ot-ctl masterkey e35efdce91b5d2ad6ee96350c31e56d3 sudo ot-ctl pskc 7beafb2ea25f3f8ce244b1e92a79a623 sudo ot-ctl networkname MyOT sudo ot-ctl channel 11 sudo ot-ctl ifconfig up sudo ot-ctl thread start sudo ot-ctl state sudo ot-ctl prefix add fd11:22::/64 pasor sudo ot-ctl netdata register 需要注意的是后面两行如果不运行，OpenThread网络中的设备将无法访问外网。\n至此，OpenThread网络配置完成，可以通过 ping 外网 ip 进行测试（通过nat64）。\n","permalink":"https://yplam.com/posts/embedded/raspberry-pi-openthread/","summary":"\u003cp\u003eOpenThread 边界路由器的作用是作为 Thread 网络与其他基于IP的网络（如WIFI、以太网）的桥梁。有了边界路由器的存在才让 Thread 网络中的设备成了跟手机、电脑等对等的一员（是的，基于IP就是那么自信）。\u003c/p\u003e","title":"树莓派 OpenThread 边界路由器配置"},{"content":"最近经常要到一些没有有线网络的地方，虽然手机可以共享WIFI出来，但总不能24小时开着，刚好手上空闲着一块 EC20 4G 模块， 于是淘宝弄了块最便宜的 MT7688 4G 路由板回来，DIY 自己的 4G WIFI共享路由器。\nMT7688 路由板为 5V 供电，核心板 8MB Flash，64MB RAM（怪不得这么便宜，低配中的底配），MPS 两路 DCDC 供电， SIM 卡连 ESD 器件都省了；\n硬件不需要太多改动，只是加了个金升阳的12V转5V DCDC 模块，找个外壳装起来，热融胶固定，钻空加电源座、天线座；完工。\n国内网上资料多是基于 Openwrt 15 的版本，使用官方驱动，不过实在是有点旧了，并且查了一下开源的 MT76 WIFI 驱动感觉也足够稳定，于是决定使用最新的 19.07 版本。\n新版有个好处就是内核比较新，已经自带 EC20 驱动，并且提供 qmi 网卡支持。\n使用 mwan3 实现有线与4G网络的切换。\n项目相关代码脚本位于 https://github.com/yplam/openwrt-mt7688-4g\n编译 编译环境基于 docker 与 docker-compose；\n下载代码\ngit clone https://github.com/yplam/openwrt-mt7688-4g.git cd openwrt-mt7688-4g git submodule update --init 或者手动下载 openwrt 源码到 /src/openwrt 目录（只在 openwrt 19.07 下测试过）\n本机安装好docker与docker-compose, 运行\ndocker-compose up --build 启动编译环境。\n然后运行：\ndocker-compose exec -u docker compiler /bin/bash 进入编译环境；\n因为OpenWRT并不支持我们的核心板，需要对设备树进行修改，为了方便直接基于 LINKIT7688 进行小改；\n修改 openwrt/target/linux/ramips/dts/LINKIT7688.dts，包括内存大小，Flash大小，console 串口\nchosen { bootargs = \u0026#34;console=ttyS0,57600\u0026#34;; }; memory@0 { device_type = \u0026#34;memory\u0026#34;; reg = \u0026lt;0x0 0x4000000\u0026gt;; }; partition@50000 { compatible = \u0026#34;denx,uimage\u0026#34;; label = \u0026#34;firmware\u0026#34;; reg = \u0026lt;0x50000 0x7b0000\u0026gt;; }; 为了提升代码下载速度，需要本机的 8123 端口提供 http 代理，如果没有，请修改 docker-compose.yml，删除运行环境相关代码，并且重启 docker-compose;\n运行：\ncd /src/openwrt ./scripts/feeds update -a ./scripts/feeds install -a make menuconfig 选择\nMediaTek Ralink MIPS\nMT76x8 based boards\nMediaTek LinkIt Smart 7688\nNetwork -\u0026gt; mt7688-4g\n可以用 make download 下载各包的代码（因为如果网络不通，可能会多次失败）\n运行编译：\nmake V=99 如无意外，编译成功后会生成\nopenwrt-mt7688-4g/src/openwrt/bin/targets/ramips/mt76x8/openwrt-ramips-mt76x8-LinkIt7688-squashfs-sysupgrade.bin 文件；可以选择在原固件的管理界面直接上传升级，或者通过 uboot 使用 tftp 升级（需要配置tftp服务器，以及配置主机IP）\n完成！\n编译出来的路由器固件相关信息：\n路由器默认IP为 192.16.0.1 WIFI SSID 为 ot4g 密码 12345678 默认 root 用户密码为空，请登录后设置 有线网卡默认为dhcp client的方式获取IP 如果同时接入有线网与4G，将优先使用有线网，如果有线网断开，将切换到4G MT7688 问题与解决 网口切换到GPIO模式 MT7688 官方提供 mt7688_pinmux 工具来查看与配置 GPIO 模式，然而对于网口1-4却不起作用，表现出来是电压为 1.6V 左右， 无法通过 gpioset 与 gpioget 命令读写。\n解决方案参考数据手册 P59，通过配置 1000003C AGPIO_CFG 寄存器的 20:17 位设置为 1 来将该 4 个网口设置成数字引脚。\ndevmem 0x1000003c 32 # 0x00E001FF devmem 0x1000003c 32 0x00FE01FF 然后就可以用 gpioset/gpioget 进行配置：\ngpioget 0 14 # 1 gpioset 0 14=0 watchdog 功能怎么用 使用以下命令查看 watchdog 状态\nubus call system watchdog 输出\n{ \u0026#34;status\u0026#34;: \u0026#34;running\u0026#34;, \u0026#34;timeout\u0026#34;: 30, \u0026#34;frequency\u0026#34;: 5, \u0026#34;magicclose\u0026#34;: false } 使用以下命令关闭喂狗，强制看门狗超时：\nubus call system watchdog \u0026#39;{\u0026#34;stop\u0026#34;: true}\u0026#39; *********************** Watchdog Reset Occurred *********************** ","permalink":"https://yplam.com/posts/embedded/openwrt-mt7688-4g/","summary":"\u003cp\u003e最近经常要到一些没有有线网络的地方，虽然手机可以共享WIFI出来，但总不能24小时开着，刚好手上空闲着一块 EC20 4G 模块，\n于是淘宝弄了块最便宜的 MT7688 4G 路由板回来，DIY 自己的 4G WIFI共享路由器。\u003c/p\u003e","title":"基于 OpenWRT 与 MT7688 DIY 4G WIFI 路由器"},{"content":"Symfony 5 已经发布了一段时间，Symfony 4 也出了 4.4 LTS 版本，于是准备把手上一个历史遗留项目升级到 4.4，然而一动手就遇到麻烦，因为现在官方已经不推荐使用之前那种传统的大 bundle，而是倾向于更通用的组件（作为一个从 Symfony 2 过来的用户，不得不说挺支持官方的做法，因为经常会因为有 bundle 不及时更新而导致 composer 冲突）。\n本文章将尝试从头开始创建一个 Symfony 4 基础应用。\n搭建 Docker 开发环境 Docker 在持续集成与环境部署方面提供不少便利性，因此此项目用 Docker 作为开发环境，发布环境还是使用之前比较熟悉的 deployer。\n习惯上 docker-compose.yml 放根目录，项目源码放 src 下，各个镜像基本上是按官方配置，然后适当修改一下\nversion: \u0026#39;3.7\u0026#39; services: nginx: build: context: ./docker/nginx ports: [\u0026#34;80:80\u0026#34;] volumes: - ./.:/www - ./docker/nginx/nginx-sites.conf:/etc/nginx/conf.d/site.conf - ./docker/nginx/nginx.conf:/etc/nginx/nginx.conf - ./data/log/nginx:/var/log/nginx links: - php73fpm php73fpm: build: context: ./docker/php73fpm args: TIMEZONE: Asia/Shanghai links: - mysql volumes: - ./.:/www - ./data/composer:/var/www/.composer entrypoint: - /bin/sh - -c - ip -4 route list match 0/0 | awk \u0026#39;{print $$3\u0026#34; host.docker.internal\u0026#34;}\u0026#39; \u0026gt;\u0026gt; /etc/hosts \u0026amp;\u0026amp; php-fpm mysql: image: percona:5.7 ports: [\u0026#39;3306:3306\u0026#39;] environment: - MYSQL_ROOT_PASSWORD=root - MYSQL_DATABASE=symfony - MYSQL_USER=symfony - MYSQL_PASSWORD=123456 volumes: - ./data/mysql_data:/var/lib/mysql - ./docker/mysql/mysql-docker.cnf:/etc/mysql/conf.d/docker.cnf 创建应用 官方提供两种方式创建 Symfony 应用，个人更倾向于 composer\ncomposer create-project symfony/website-skeleton:4.4.* . 开始之前也可以先配置一下 composer 国内镜像：\ncomposer config -g repo.packagist composer https://mirrors.aliyun.com/composer/ 用户登录 以前 fosuserbundle 可以说是第一个必装的 bundle，因为太方便了，配置两下就可以具备完整的用户注册、登录、召回密码等功能，然而因为用户管理可以说是一个网站的基石功能，用上了 fosuserbundle 反而会影响到系统的灵活性，并且 fosuserbundle 为了通用与兼容性，会带来一下不太想要的复杂性。\n可能官方已经注意到这个情况，所以提供了一个 maker 命令生成模板。\n先创建用户：\nbin/console make:user 按需求选择各选项。因为我们要兼容旧版的密码加密方式，所以需要手动加上 salt 等字段：\nbin/console make:entity User 系统会自动生成User Entity并且配置使用：\ncreated: src/Entity/User.php created: src/Repository/UserRepository.php updated: src/Entity/User.php updated: config/packages/security.yaml 新版本的 Symfony 的用户密码加密方式有所改变，为了兼容旧版，并且为了后续的灵活性，这里需要创建一个 App 的 UserProvider。关于密码加密方式兼容相关的信息可以参考： https://symfony.com/doc/4.4/security/password_migration.html\nuse HWI\\Bundle\\OAuthBundle\\Connect\\AccountConnectorInterface; use HWI\\Bundle\\OAuthBundle\\Form\\RegistrationFormHandlerInterface; use HWI\\Bundle\\OAuthBundle\\Security\\Core\\User\\OAuthAwareUserProviderInterface; use Symfony\\Component\\Security\\Core\\User\\PasswordUpgraderInterface; use Symfony\\Component\\Security\\Core\\User\\UserInterface; use Symfony\\Component\\Security\\Core\\User\\UserProviderInterface; class UserProvider implements UserProviderInterface, PasswordUpgraderInterface, OAuthAwareUserProviderInterface, AccountConnectorInterface, RegistrationFormHandlerInterface 这里的 UserProvider 除了实现基本功能外，还增加了对 HWIOAuthBundle 的支持。\n","permalink":"https://yplam.com/posts/symfony/symfony-the-new-way/","summary":"\u003cp\u003eSymfony 5 已经发布了一段时间，Symfony 4 也出了 4.4 LTS 版本，于是准备把手上一个历史遗留项目升级到 4.4，然而一动手就遇到麻烦，因为现在官方已经不推荐使用之前那种传统的大 bundle，而是倾向于更通用的组件（作为一个从 Symfony 2 过来的用户，不得不说挺支持官方的做法，因为经常会因为有 bundle 不及时更新而导致 composer 冲突）。\u003c/p\u003e\n\u003cp\u003e本文章将尝试从头开始创建一个 Symfony 4 基础应用。\u003c/p\u003e","title":"Symfony 4 the new way"},{"content":"两年多前曾经在服务器上部署了个 Tensorflow 模型，由于 Tensorflow serving 刚公布不久，并且还没阅读相关文档，所以当时就粗暴的用 Flask 写了个接口就放到线上跑了两年。\n最近又需要在服务器上部署些模型，决定用回比较官方的方式，研究一下 Tensorflow serving。\n安装 使用 docker compose 安装，需要注意的是，由于 Tensorflow 的接口不断在变化，Tensorflow serving 的版本需要与模型训练、模型导出的版本一致，否则可能会出现某些操作符不存在的错误。\ndocker-compose.yml\nversion: \u0026#39;3.7\u0026#39; services: tensorflow_serving: build: context: ./bin/TensorflowServing ports: [\u0026#34;127.0.0.1:8501:8501\u0026#34;] volumes: - ./models:/models environment: - MODEL_NAME=nsfw bin/TensorflowServing/Dockerfile，虽然是默认镜像，但习惯加个 Dockerfile\nFROM tensorflow/serving:1.12.0 测试 在此测试的是 tensorflow-open_nsfw 模型，此模型提供模型导出以及数据请求格式生成相关的脚本，适合用来快速测试。\n用 virtualenv 安装 tensorflow 1.12 版本，以及 numpy==1.16.1 ，然后运行下面命令导出模型：\npython tools/export_savedmodel.py -i base64_jpeg -v 1 -m data/open_nsfw-weights.npy nsfw 使用以下命令查看模型输入输出格式：\nsaved_model_cli show --dir nsfw/1 --all 结果如下，输入是一个 base64 encode 的 jpeg 图片字符串：\nMetaGraphDef with tag-set: \u0026#39;serve\u0026#39; contains the following SignatureDefs: signature_def[\u0026#39;serving_default\u0026#39;]: The given SavedModel SignatureDef contains the following input(s): inputs[\u0026#39;inputs\u0026#39;] tensor_info: dtype: DT_STRING shape: (-1) name: input:0 The given SavedModel SignatureDef contains the following output(s): outputs[\u0026#39;outputs\u0026#39;] tensor_info: dtype: DT_FLOAT shape: (-1, 2) name: predictions:0 Method name is: tensorflow/serving/predict 将导出的模型放到 docker compose 工作目录下的 models 下，然后启动 docker ：\ndocker-compose up --build 拿一张需要测试的jpeg图片，运行下面命令：\npython tools/create_predict_request.py -i base64_jpeg -l tensorflow -t tf-serving test.jpg \u0026gt; test.txt test.txt 中会生成用于请求 Tensorflow serving 的格式，大概如下：\n{\u0026#34;instances\u0026#34;: [\u0026#34;_9j_4AAQSkZ......UUCP__Z\u0026#34;]} 需要注意的是这里的base64 encode图片需要为urlsafe格式，如果客户端为PHP的话需要对encode的字符串做替换处理。\n然后测试一下：\ncurl -d \u0026#39;@test.txt\u0026#39; -X POST http://localhost:8501/v1/models/nsfw:predict 会返回类似下面结果：\n{ \u0026#34;predictions\u0026#34;: [[0.337196, 0.662804] ] } 结果中第一个代表 sfw，第二个代表 nsfw，因此模型判断此图片包含不良内容。\n","permalink":"https://yplam.com/posts/machinelearning/tensorflow-serving-nsfw/","summary":"\u003cp\u003e两年多前曾经在服务器上部署了个 Tensorflow 模型，由于 Tensorflow serving 刚公布不久，并且还没阅读相关文档，所以当时就粗暴的用 Flask 写了个接口就放到线上跑了两年。\u003c/p\u003e\n\u003cp\u003e最近又需要在服务器上部署些模型，决定用回比较官方的方式，研究一下 Tensorflow serving。\u003c/p\u003e","title":"Tensorflow Serving Nsfw"},{"content":"偶尔有收到用户关于 \u0026ldquo;Could not decode image: ***\u0026rdquo; 的反馈，并且最近频率有增加的趋势，解开 Theme 文件除了图片有点大以外看不出其他问题，所以决定花点时间跟踪一下 Chromium 源码。\n本来以为是一个非常简单的问题，只需要找到报错信息，然后打印 backtrace，再断点跟踪一下。然而由于 Chromium 多线程的特性，以及 crx 文件的安装是在 sandbox 中进行的，断点到出错信息，得到的是下面 的 backtrace：\n#0 0x0000555557b3e373 in extensions::SandboxedUnpacker::ImageSanitizationDone(std::__Cr::unique_ptr\u0026lt;base::DictionaryValue, std::__Cr::default_delete\u0026lt;base::DictionaryValue\u0026gt; \u0026gt;, extensions::ImageSanitizer::Status, base::FilePath const\u0026amp;) (this=0x2f1d9794c020, manifest=..., status=extensions::ImageSanitizer::Status::kDecodingError, file_path_for_error=...) at ../../extensions/browser/sandboxed_unpacker.cc:548 #1 0x0000555557b430f9 in base::internal::FunctorTraits\u0026lt;void (extensions::SandboxedUnpacker::*)(std::__Cr::unique_ptr\u0026lt;base::DictionaryValue, std::__Cr::default_delete\u0026lt;base::DictionaryValue\u0026gt; \u0026gt;, extensions::ImageSanitizer::Status, base::FilePath const\u0026amp;), void\u0026gt;::Invoke\u0026lt;void (extensions::SandboxedUnpacker::*)(std::__Cr::unique_ptr\u0026lt;base::DictionaryValue, std::__Cr::default_delete\u0026lt;base::DictionaryValue\u0026gt; \u0026gt;, extensions::ImageSanitizer::Status, base::FilePath const\u0026amp;), scoped_refptr\u0026lt;extensions::SandboxedUnpacker\u0026gt;, std::__Cr::unique_ptr\u0026lt;base::DictionaryValue, std::__Cr::default_delete\u0026lt;base::DictionaryValue\u0026gt; \u0026gt;, extensions::ImageSanitizer::Status, base::FilePath const\u0026amp;\u0026gt;(void (extensions::SandboxedUnpacker::*)(std::__Cr::unique_ptr\u0026lt;base::DictionaryValue, std::__Cr::default_delete\u0026lt;base::DictionaryValue\u0026gt; \u0026gt;, extensions::ImageSanitizer::Status, base::FilePath const\u0026amp;), scoped_refptr\u0026lt;extensions::SandboxedUnpacker\u0026gt;\u0026amp;\u0026amp;, std::__Cr::unique_ptr\u0026lt;base::DictionaryValue, std::__Cr::default_delete\u0026lt;base::DictionaryValue\u0026gt; \u0026gt;\u0026amp;\u0026amp;, extensions::ImageSanitizer::Status\u0026amp;\u0026amp;, base::FilePath const\u0026amp;) (method= (void (extensions::SandboxedUnpacker::*)(extensions::SandboxedUnpacker * const, std::__Cr::unique_ptr\u0026lt;base::DictionaryValue, std::__Cr::default_delete\u0026lt;base::DictionaryValue\u0026gt; \u0026gt;, extensions::ImageSanitizer::Status, const base::FilePath \u0026amp;)) 0x555557b3e340 \u0026lt;extensions::SandboxedUnpacker::ImageSanitizationDone(std::__Cr::unique_ptr\u0026lt;base::DictionaryValue, std::__Cr::default_delete\u0026lt;base::DictionaryValue\u0026gt; \u0026gt;, extensions::ImageSanitizer::Status, base::FilePath const\u0026amp;)\u0026gt;, receiver_ptr=..., args=..., args=@0x7fffbb8afb14: extensions::ImageSanitizer::Status::kDecodingError, args=...) at ../../base/bind_internal.h:499 #2 0x0000555557b43020 in base::internal::InvokeHelper\u0026lt;false, void\u0026gt;::MakeItSo\u0026lt;void (extensions::SandboxedUnpacker::*)(std::__Cr::unique_ptr\u0026lt;base::DictionaryValue, std::__Cr::default_delete\u0026lt;base::DictionaryValue\u0026gt; \u0026gt;, extensions::ImageSanitizer::Status, base::FilePath const\u0026amp;), scoped_refptr\u0026lt;extensions::SandboxedUnpacker\u0026gt;, std::__Cr::unique_ptr\u0026lt;base::DictionaryValue, std::__Cr::default_delete\u0026lt;base::DictionaryValue\u0026gt; \u0026gt;, extensions::ImageSanitizer::Status, base::FilePath const\u0026amp;\u0026gt;(void (extensions::SandboxedUnpacker::*\u0026amp;\u0026amp;)(std::__Cr::unique_ptr\u0026lt;base::DictionaryValue, std::__Cr::default_delete\u0026lt;base::DictionaryValue\u0026gt; \u0026gt;, extensions::ImageSanitizer::Status, base::FilePath const\u0026amp;), scoped_refptr\u0026lt;extensions::SandboxedUnpacker\u0026gt;\u0026amp;\u0026amp;, std::__Cr::unique_ptr\u0026lt;base::DictionaryValue, std::__Cr::default_delete\u0026lt;base::DictionaryValue\u0026gt; \u0026gt;\u0026amp;\u0026amp;, extensions::ImageSanitizer::Status\u0026amp;\u0026amp;, base::FilePath const\u0026amp;) (functor= @0x2f1d9880ebc0: (void (extensions::SandboxedUnpacker::*)(extensions::SandboxedUnpacker * const, std::__Cr::unique_ptr\u0026lt;base::DictionaryValue, std::__Cr::default_delete\u0026lt;base::DictionaryValue\u0026gt; \u0026gt;, extensions::ImageSanitizer::Status, const base::FilePath \u0026amp;)) 0x555557b3e340 \u0026lt;extensions::SandboxedUnpacker::ImageSanitizationDone(std::__Cr::unique_ptr\u0026lt;base::DictionaryValue, std::__Cr::default_delete\u0026lt;base::DictionaryValue\u0026gt; \u0026gt;, extensions::ImageSanitizer::Status, base::FilePath const\u0026amp;)\u0026gt;, args=..., args=..., args=@0x7fffbb8afb14: extensions::ImageSanitizer::Status::kDecodingError, args=...) at ../../base/bind_internal.h:599 #3 0x0000555557b42f7d in base::internal::Invoker\u0026lt;base::internal::BindState\u0026lt;void (extensions::SandboxedUnpacker::*)(std::__Cr::unique_ptr\u0026lt;base::DictionaryValue, std::__Cr::default_delete\u0026lt;base::DictionaryValue\u0026gt; \u0026gt;, extensions::ImageSanitizer::Status, base::FilePath const\u0026amp;), scoped_refptr\u0026lt;extensions::SandboxedUnpacker\u0026gt;, std::__Cr::unique_ptr\u0026lt;base::DictionaryValue, std::__Cr::default_delete\u0026lt;base::DictionaryValue\u0026gt; \u0026gt; \u0026gt;, void (extensions::ImageSanitizer::Status, base::FilePath const\u0026amp;)\u0026gt;::RunImpl\u0026lt;void (extensions::SandboxedUnpacker::*)(std::__Cr::unique_ptr\u0026lt;base::DictionaryValue, std::__Cr::default_delete\u0026lt;base::DictionaryValue\u0026gt; \u0026gt;, extensions::ImageSanitizer::Status, base::FilePath const\u0026amp;), std::__Cr::tuple\u0026lt;scoped_refptr\u0026lt;extensions::SandboxedUnpacker\u0026gt;, std::__Cr::unique_ptr\u0026lt;base::DictionaryValue, std::__Cr::default_delete\u0026lt;base::DictionaryValue\u0026gt; \u0026gt; \u0026gt;, 0ul, 1ul\u0026gt;(void (extensions::SandboxedUnpacker::*\u0026amp;\u0026amp;)(std::__Cr::unique_ptr\u0026lt;base::DictionaryValue, std::__Cr::default_delete\u0026lt;base::DictionaryValue\u0026gt; \u0026gt;, extensions::ImageSanitizer::Status, base::FilePath const\u0026amp;), std::__Cr::tuple\u0026lt;scoped_refptr\u0026lt;extensions::SandboxedUnpacker\u0026gt;, std::__Cr::unique_ptr\u0026lt;base::DictionaryValue, std::__Cr::default_delete\u0026lt;base::DictionaryValue\u0026gt; \u0026gt; \u0026gt;\u0026amp;\u0026amp;, std::__Cr::integer_sequence\u0026lt;unsigned long, 0ul, 1ul\u0026gt;, extensions::ImageSanitizer::Status\u0026amp;\u0026amp;, base::FilePath const\u0026amp;) (functor= @0x2f1d9880ebc0: (void (extensions::SandboxedUnpacker::*)(extensions::SandboxedUnpacker * const, std::__Cr::unique_ptr\u0026lt;base::DictionaryValue, std::__Cr::default_delete\u0026lt;base::DictionaryValue\u0026gt; \u0026gt;, extensions::ImageSanitizer::Status, const base::FilePath \u0026amp;)) 0x555557b3e340 \u0026lt;extensions::SandboxedUnpacker::ImageSanitizationDone(std::__Cr::unique_ptr\u0026lt;base::DictionaryValue, std::__Cr::default_delete\u0026lt;base::DictionaryValue\u0026gt; \u0026gt;, extensions::ImageSanitizer::Status, base::FilePath const\u0026amp;)\u0026gt;, bound=..., unbound_args=@0x7fffbb8afb14: extensions::ImageSanitizer::Status::kDecodingError, unbound_args=...) at ../../base/bind_internal.h:672 #4 0x0000555557b42e5d in base::internal::Invoker\u0026lt;base::internal::BindState\u0026lt;void (extensions::SandboxedUnpacker::*)(std::__Cr::unique_ptr\u0026lt;base::DictionaryValue, std::__Cr::default_delete\u0026lt;base::DictionaryValue\u0026gt; \u0026gt;, extensions::ImageSanitizer::Status, base::FilePath const\u0026amp;), scoped_refptr\u0026lt;extensions::SandboxedUnpacker\u0026gt;, std::__Cr::unique_ptr\u0026lt;base::DictionaryValue, std::__Cr::default_delete\u0026lt;base::DictionaryValue\u0026gt; \u0026gt; \u0026gt;, void (extensions::ImageSanitizer::Status, base::FilePath const\u0026amp;)\u0026gt;::RunOnce(base::internal::BindStateBase*, extensions::ImageSanitizer::Status, base::FilePath const\u0026amp;) (base=0x2f1d9880eba0, unbound_args=extensions::ImageSanitizer::Status::kDecodingError, unbound_args=...) at ../../base/bind_internal.h:641 #5 0x0000555557345787 in base::OnceCallback\u0026lt;void (unsigned int, std::__Cr::basic_string\u0026lt;char, std::__Cr::char_traits\u0026lt;char\u0026gt;, std::__Cr::allocator\u0026lt;char\u0026gt; \u0026gt; const\u0026amp;)\u0026gt;::Run(unsigned int, std::__Cr::basic_string\u0026lt;char, std::__Cr::char_traits\u0026lt;char\u0026gt;, std::__Cr::allocator\u0026lt;char\u0026gt; \u0026gt; const\u0026amp;) \u0026amp;\u0026amp; (this=0x2f1d982f0418, args=4, args=...) at ../../base/callback.h:97 #6 0x0000555557b11de2 in extensions::ImageSanitizer::ReportError(extensions::ImageSanitizer::Status, base::FilePath const\u0026amp;) (this=0x2f1d982f03e0, status=extensions::ImageSanitizer::Status::kDecodingError, path=...) at ../../extensions/browser/image_sanitizer.cc:219 #7 0x0000555557b1203a in extensions::ImageSanitizer::ImageDecoded(base::FilePath const\u0026amp;, SkBitmap const\u0026amp;) (this=0x2f1d982f03e0, image_path=..., decoded_image=...) at ../../extensions/browser/image_sanitizer.cc:157 #8 0x0000555557326b0c in base::internal::FunctorTraits\u0026lt;void (OAuth2TokenService::RequestImpl::*)(GoogleServiceAuthError const\u0026amp;, OAuth2AccessTokenConsumer::TokenResponse const\u0026amp;), void\u0026gt;::Invoke\u0026lt;void (OAuth2TokenService::RequestImpl::*)(GoogleServiceAuthError const\u0026amp;, OAuth2AccessTokenConsumer::TokenResponse const\u0026amp;), base::WeakPtr\u0026lt;OAuth2TokenService::RequestImpl\u0026gt;, GoogleServiceAuthError, OAuth2AccessTokenConsumer::TokenResponse\u0026gt;(void (OAuth2TokenService::RequestImpl::*)(GoogleServiceAuthError const\u0026amp;, OAuth2AccessTokenConsumer::TokenResponse const\u0026amp;), base::WeakPtr\u0026lt;OAuth2TokenService::RequestImpl\u0026gt;\u0026amp;\u0026amp;, GoogleServiceAuthError\u0026amp;\u0026amp;, OAuth2AccessTokenConsumer::TokenResponse\u0026amp;\u0026amp;) (method= (void (OAuth2TokenService::RequestImpl::*)(OAuth2TokenService::RequestImpl * const, const GoogleServiceAuthError \u0026amp;, const OAuth2AccessTokenConsumer::TokenResponse \u0026amp;)) 0x555557b11fe0 \u0026lt;extensions::ImageSanitizer::ImageDecoded(base::FilePath const\u0026amp;, SkBitmap const\u0026amp;)\u0026gt;, receiver_ptr=..., args=..., args=...) at ../../base/bind_internal.h:499 除了知道报错是在 extensions::SandboxedUnpacker::ImageSanitizationDone 以外，其他都是一些 复杂的函数指针。\n参考 Chromium 关于线程与任务 ，回调 的文档。扩展安装属于发送到线程上的序列化任务，底层通过偏函数，并且由于使用 mojo，使得对调用流程的跟踪 异常麻烦。\n最终只能通过阅读源码 + dump 的方式反推整个流程如下：\nDownloadItemImpl::OnDownloadCompleting 下载完成 DownloadFileImpl::RenameAndAnnotate 重命名，然后回调 DownloadItemImpl::OnDownloadRenamedToFinalName 下载完成并且完成重命名 ChromeDownloadManagerDelegate::ShouldOpenDownload 检查到是 crx download_crx_util::OpenChromeExtension 打开 crx CrxInstaller::InstallCrx 安装 crx extensions::CrxInstaller::InstallCrxFile SandboxedUnpacker::StartWithCrx SandboxedUnpacker::Unzip SandboxedUnpacker::Unpack SandboxedUnpacker::ReadManifestDone ImageSanitizer::CreateAndStart ImageSanitizer::Start ImageSanitizer::ImageFileRead data_decoder::ImageDecoderImpl::DecodeImage 结果：\n由于 extensions/browser/image_sanitizer.cc 中定义 const int kMaxImageCanvas = 4096 * 4096。 并且该值限制了所有 extension 中图片的大小，当图片大小\nx*y*4+(skia::mojom::Bitmap::Data_) \u0026gt; 4096 * 4096 时就会报错，然而由于现在 2k 甚至 4k 显示器的使用越来越多，当其使用一张全屏图作为主题背景时就会超出 此限制值。\nps:跟 Chromium 的开发人员反馈了一下，然而对方认为只是简单的增大 kMaxImageCanvas 并不合适，可能 需要分场景考虑，所以估计此问题短时间内不会解决。\n技巧：\n因为 Chromium 源码分层比较清晰，查找调用时只在模块内部查找可以提高效率。\n如果源码中有调用 mojo 定义的服务，可以先查看 mojo 定义文件如：services/data_decoder/public/mojom/image_decoder.mojom 然后查看生成的接口定义 gen/services/data_decoder/public/mojom/image_decoder.mojom.h， 然后查找 include 了 image_decoder.mojom.h 的文件，一般可以找到该 mojo 服务的实现。\n##一些 backtrace\n由于 Chromium 多线程特性，在 gdb 中跟踪流程变得比较困难，下面是一些断点的 backtrace。\nextensions::CrxInstaller::InstallCrxFile\n#0 0x000055555a367bcd in extensions::CrxInstaller::InstallCrxFile(extensions::CRXFileInfo const\u0026amp;) (this=0x164ebed6d5a0, source_file=...) at ../../chrome/browser/extensions/crx_installer.cc:180 #1 0x000055555a367b6a in extensions::CrxInstaller::InstallCrx(base::FilePath const\u0026amp;) (this=0x164ebed6d5a0, source_file=...) at ../../chrome/browser/extensions/crx_installer.cc:176 #2 0x00005555590ae5f6 in download_crx_util::OpenChromeExtension(Profile*, download::DownloadItem const\u0026amp;) (profile=0x164ebcaae020, download_item=...) at ../../chrome/browser/download/download_crx_util.cc:117 #3 0x0000555558d483ba in ChromeDownloadManagerDelegate::ShouldOpenDownload(download::DownloadItem*, base::RepeatingCallback\u0026lt;void (bool)\u0026gt; const\u0026amp;) (this=0x164ebf98cde0, item=0x164ebecf3e20, callback=...) at ../../chrome/browser/download/chrome_download_manager_delegate.cc:561 #4 0x00007ffff2c33102 in content::DownloadManagerImpl::ShouldOpenDownload(download::DownloadItemImpl*, base::RepeatingCallback\u0026lt;void (bool)\u0026gt; const\u0026amp;) (this=0x164ebcafc020, item=0x164ebecf3e20, callback=...) at ../../content/browser/download/download_manager_impl.cc:468 #5 0x00007fffea0adad7 in download::DownloadItemImpl::OnDownloadRenamedToFinalName(download::DownloadInterruptReason, base::FilePath const\u0026amp;) (this=0x164ebecf3e20, reason=download::DOWNLOAD_INTERRUPT_REASON_NONE, full_path=...) at ../../components/download/internal/common/download_item_impl.cc:1788 #6 0x00007fffea0b9b8c in base::internal::FunctorTraits\u0026lt;void (download::DownloadItemImpl::*)(download::DownloadInterruptReason, base::FilePath const\u0026amp;), void\u0026gt;::Invoke\u0026lt;void (download::DownloadItemImpl::*)(download::DownloadInterruptReason, base::FilePath const\u0026amp;), base::WeakPtr\u0026lt;download::DownloadItemImpl\u0026gt; const\u0026amp;, download::DownloadInterruptReason, base::FilePath const\u0026amp;\u0026gt;(void (download::DownloadItemImpl::*)(download::DownloadInterruptReason, base::FilePath const\u0026amp;), base::WeakPtr\u0026lt;download::DownloadItemImpl\u0026gt; const\u0026amp;, download::DownloadInterruptReason\u0026amp;\u0026amp;, base::FilePath const\u0026amp;) (method= (void (download::DownloadItemImpl::*)(download::DownloadItemImpl * const, download::DownloadInterruptReason, const base::FilePath \u0026amp;)) 0x7fffea0ad520 \u0026lt;download::DownloadItemImpl::OnDownloadRenamedToFinalName(download::DownloadInterruptReason, base::FilePath const\u0026amp;)\u0026gt;, receiver_ptr=..., args=@0x7fffffffb574: download::DOWNLOAD_INTERRUPT_REASON_NONE, args=...) at ../../base/bind_internal.h:499 #7 0x00007fffea0b9ad4 in base::internal::InvokeHelper\u0026lt;true, void\u0026gt;::MakeItSo\u0026lt;void (download::DownloadItemImpl::* const\u0026amp;)(download::DownloadInterruptReason, base::FilePath const\u0026amp;), base::WeakPtr\u0026lt;download::DownloadItemImpl\u0026gt; const\u0026amp;, download::DownloadInterruptReason, base::FilePath const\u0026amp;\u0026gt;(void (download::DownloadItemImpl::* const\u0026amp;)(download::DownloadInterruptReason, base::FilePath const\u0026amp;), base::WeakPtr\u0026lt;download::DownloadItemImpl\u0026gt; const\u0026amp;, download::DownloadInterruptReason\u0026amp;\u0026amp;, base::FilePath const\u0026amp;) (functor= @0x164ec0be71c0: (void (download::DownloadItemImpl::*)(download::DownloadItemImpl * const, download::DownloadInterruptReason, const base::FilePath \u0026amp;)) 0x7fffea0ad520 \u0026lt;download::DownloadItemImpl::OnDownloadRenamedToFinalName(download::DownloadInterruptReason, base::FilePath const\u0026amp;)\u0026gt;, weak_ptr=..., args=@0x7fffffffb574: download::DOWNLOAD_INTERRUPT_REASON_NONE, args=...) at ../../base/bind_internal.h:619 #8 0x00007fffea0b9a2c in base::internal::Invoker\u0026lt;base::internal::BindState\u0026lt;void (download::DownloadItemImpl::*)(download::DownloadInterruptReason, base::FilePath const\u0026amp;), base::WeakPtr\u0026lt;download::DownloadItemImpl\u0026gt; \u0026gt;, void (download::DownloadInterruptReason, base::FilePath const\u0026amp;)\u0026gt;::RunImpl\u0026lt;void (download::DownloadItemImpl::* const\u0026amp;)(download::DownloadInterruptReason, base::FilePath const\u0026amp;), std::__Cr::tuple\u0026lt;base::WeakPtr\u0026lt;download::DownloadItemImpl\u0026gt; \u0026gt; const\u0026amp;, 0ul\u0026gt;(void (download::DownloadItemImpl::* const\u0026amp;)(download::DownloadInterruptReason, base::FilePath const\u0026amp;), std::__Cr::tuple\u0026lt;base::WeakPtr\u0026lt;download::DownloadItemImpl\u0026gt; \u0026gt; const\u0026amp;, std::__Cr::integer_sequence\u0026lt;unsigned long, 0ul\u0026gt;, download::DownloadInterruptReason\u0026amp;\u0026amp;, base::FilePath const\u0026amp;) (functor= @0x164ec0be71c0: (void (download::DownloadItemImpl::*)(download::DownloadItemImpl * const, download::DownloadInterruptReason, const base::FilePath \u0026amp;)) 0x7fffea0ad520 \u0026lt;download::DownloadItemImpl::OnDownloadRenamedToFinalName(download::DownloadInterruptReason, base::FilePath const\u0026amp;)\u0026gt;, bound=..., unbound_args=@0x7fffffffb574: download::DOWNLOAD_INTERRUPT_REASON_NONE, unbound_args=...) at ../../base/bind_internal.h:672 extensions::SandboxedUnpacker::ReadManifestDone\n#0 0x0000555557b3d20d in extensions::SandboxedUnpacker::ReadManifestDone(base::Optional\u0026lt;base::Value\u0026gt;, base::Optional\u0026lt;std::__Cr::basic_string\u0026lt;char, std::__Cr::char_traits\u0026lt;char\u0026gt;, std::__Cr::allocator\u0026lt;char\u0026gt; \u0026gt; \u0026gt; const\u0026amp;) (this=0x29624dac2820, manifest=..., error=...) at ../../extensions/browser/sandboxed_unpacker.cc:437 #1 0x0000555557b429b7 in base::internal::FunctorTraits\u0026lt;void (extensions::SandboxedUnpacker::*)(base::Optional\u0026lt;base::Value\u0026gt;, base::Optional\u0026lt;std::__Cr::basic_string\u0026lt;char, std::__Cr::char_traits\u0026lt;char\u0026gt;, std::__Cr::allocator\u0026lt;char\u0026gt; \u0026gt; \u0026gt; const\u0026amp;), void\u0026gt;::Invoke\u0026lt;void (extensions::SandboxedUnpacker::*)(base::Optional\u0026lt;base::Value\u0026gt;, base::Optional\u0026lt;std::__Cr::basic_string\u0026lt;char, std::__Cr::char_traits\u0026lt;char\u0026gt;, std::__Cr::allocator\u0026lt;char\u0026gt; \u0026gt; \u0026gt; const\u0026amp;), scoped_refptr\u0026lt;extensions::SandboxedUnpacker\u0026gt;, base::Optional\u0026lt;base::Value\u0026gt;, base::Optional\u0026lt;std::__Cr::basic_string\u0026lt;char, std::__Cr::char_traits\u0026lt;char\u0026gt;, std::__Cr::allocator\u0026lt;char\u0026gt; \u0026gt; \u0026gt; const\u0026amp;\u0026gt;(void (extensions::SandboxedUnpacker::*)(base::Optional\u0026lt;base::Value\u0026gt;, base::Optional\u0026lt;std::__Cr::basic_string\u0026lt;char, std::__Cr::char_traits\u0026lt;char\u0026gt;, std::__Cr::allocator\u0026lt;char\u0026gt; \u0026gt; \u0026gt; const\u0026amp;), scoped_refptr\u0026lt;extensions::SandboxedUnpacker\u0026gt;\u0026amp;\u0026amp;, base::Optional\u0026lt;base::Value\u0026gt;\u0026amp;\u0026amp;, base::Optional\u0026lt;std::__Cr::basic_string\u0026lt;char, std::__Cr::char_traits\u0026lt;char\u0026gt;, std::__Cr::allocator\u0026lt;char\u0026gt; \u0026gt; \u0026gt; const\u0026amp;) (method= (void (extensions::SandboxedUnpacker::*)(extensions::SandboxedUnpacker * const, base::Optional\u0026lt;base::Value\u0026gt;, const base::Optional\u0026lt;std::__Cr::basic_string\u0026lt;char\u0026gt; \u0026gt; \u0026amp;)) 0x555557b3d1e0 \u0026lt;extensions::SandboxedUnpacker::ReadManifestDone(base::Optional\u0026lt;base::Value\u0026gt;, base::Optional\u0026lt;std::__Cr::basic_string\u0026lt;char, std::__Cr::char_traits\u0026lt;char\u0026gt;, std::__Cr::allocator\u0026lt;char\u0026gt; \u0026gt; \u0026gt; const\u0026amp;)\u0026gt;, receiver_ptr=..., args=..., args=...) at ../../base/bind_internal.h:499 #2 0x0000555557b428eb in base::internal::InvokeHelper\u0026lt;false, void\u0026gt;::MakeItSo\u0026lt;void (extensions::SandboxedUnpacker::*)(base::Optional\u0026lt;base::Value\u0026gt;, base::Optional\u0026lt;std::__Cr::basic_string\u0026lt;char, std::__Cr::char_traits\u0026lt;char\u0026gt;, std::__Cr::allocator\u0026lt;char\u0026gt; \u0026gt; \u0026gt; const\u0026amp;), scoped_refptr\u0026lt;extensions::SandboxedUnpacker\u0026gt;, base::Optional\u0026lt;base::Value\u0026gt;, base::Optional\u0026lt;std::__Cr::basic_string\u0026lt;char, std::__Cr::char_traits\u0026lt;char\u0026gt;, std::__Cr::allocator\u0026lt;char\u0026gt; \u0026gt; \u0026gt; const\u0026amp;\u0026gt;(void (extensions::SandboxedUnpacker::*\u0026amp;\u0026amp;)(base::Optional\u0026lt;base::Value\u0026gt;, base::Optional\u0026lt;std::__Cr::basic_string\u0026lt;char, std::__Cr::char_traits\u0026lt;char\u0026gt;, std::__Cr::allocator\u0026lt;char\u0026gt; \u0026gt; \u0026gt; const\u0026amp;), scoped_refptr\u0026lt;extensions::SandboxedUnpacker\u0026gt;\u0026amp;\u0026amp;, base::Optional\u0026lt;base::Value\u0026gt;\u0026amp;\u0026amp;, base::Optional\u0026lt;std::__Cr::basic_string\u0026lt;char, std::__Cr::char_traits\u0026lt;char\u0026gt;, std::__Cr::allocator\u0026lt;char\u0026gt; \u0026gt; \u0026gt; const\u0026amp;) (functor= @0x29624e775dd0: (void (extensions::SandboxedUnpacker::*)(extensions::SandboxedUnpacker * const, base::Optional\u0026lt;base::Value\u0026gt;, const base::Optional\u0026lt;std::__Cr::basic_string\u0026lt;char\u0026gt; \u0026gt; \u0026amp;)) 0x555557b3d1e0 \u0026lt;extensions::SandboxedUnpacker::ReadManifestDone(base::Optional\u0026lt;base::Value\u0026gt;, base::Optional\u0026lt;std::__Cr::basic_string\u0026lt;char, std::__Cr::char_traits\u0026lt;char\u0026gt;, std::__Cr::allocator\u0026lt;char\u0026gt; \u0026gt; \u0026gt; const\u0026amp;)\u0026gt;, args=..., args=..., args=...) at ../../base/bind_internal.h:599 #3 0x0000555557b4285c in base::internal::Invoker\u0026lt;base::internal::BindState\u0026lt;void (extensions::SandboxedUnpacker::*)(base::Optional\u0026lt;base::Value\u0026gt;, base::Optional\u0026lt;std::__Cr::basic_string\u0026lt;char, std::__Cr::char_traits\u0026lt;char\u0026gt;, std::__Cr::allocator\u0026lt;char\u0026gt; \u0026gt; \u0026gt; const\u0026amp;), scoped_refptr\u0026lt;extensions::SandboxedUnpacker\u0026gt; \u0026gt;, void (base::Optional\u0026lt;base::Value\u0026gt;, base::Optional\u0026lt;std::__Cr::basic_string\u0026lt;char, std::__Cr::char_traits\u0026lt;char\u0026gt;, std::__Cr::allocator\u0026lt;char\u0026gt; \u0026gt; \u0026gt; const\u0026amp;)\u0026gt;::RunImpl\u0026lt;void (extensions::SandboxedUnpacker::*)(base::Optional\u0026lt;base::Value\u0026gt;, base::Optional\u0026lt;std::__Cr::basic_string\u0026lt;char, std::__Cr::char_traits\u0026lt;char\u0026gt;, std::__Cr::allocator\u0026lt;char\u0026gt; \u0026gt; \u0026gt; const\u0026amp;), std::__Cr::tuple\u0026lt;scoped_refptr\u0026lt;extensions::SandboxedUnpacker\u0026gt; \u0026gt;, 0ul\u0026gt;(void (extensions::SandboxedUnpacker::*\u0026amp;\u0026amp;)(base::Optional\u0026lt;base::Value\u0026gt;, base::Optional\u0026lt;std::__Cr::basic_string\u0026lt;char, std::__Cr::char_traits\u0026lt;char\u0026gt;, std::__Cr::allocator\u0026lt;char\u0026gt; \u0026gt; \u0026gt; const\u0026amp;), std::__Cr::tuple\u0026lt;scoped_refptr\u0026lt;extensions::SandboxedUnpacker\u0026gt; \u0026gt;\u0026amp;\u0026amp;, std::__Cr::integer_sequence\u0026lt;unsigned long, 0ul\u0026gt;, base::Optional\u0026lt;base::Value\u0026gt;\u0026amp;\u0026amp;, base::Optional\u0026lt;std::__Cr::basic_string\u0026lt;char, std::__Cr::char_traits\u0026lt;char\u0026gt;, std::__Cr::allocator\u0026lt;char\u0026gt; \u0026gt; \u0026gt; const\u0026amp;) (functor= @0x29624e775dd0: (void (extensions::SandboxedUnpacker::*)(extensions::SandboxedUnpacker * const, base::Optional\u0026lt;base::Value\u0026gt;, const base::Optional\u0026lt;std::__Cr::basic_string\u0026lt;char\u0026gt; \u0026gt; \u0026amp;)) 0x555557b3d1e0 \u0026lt;extensions::SandboxedUnpacker::ReadManifestDone(base::Optional\u0026lt;base::Value\u0026gt;, base::Optional\u0026lt;std::__Cr::basic_string\u0026lt;char, std::__Cr::char_traits\u0026lt;char\u0026gt;, std::__Cr::allocator\u0026lt;char\u0026gt; \u0026gt; \u0026gt; const\u0026amp;)\u0026gt;, bound=..., unbound_args=..., unbound_args=...) at ../../base/bind_internal.h:672 #4 0x0000555557b427de in base::internal::Invoker\u0026lt;base::internal::BindState\u0026lt;void (extensions::SandboxedUnpacker::*)(base::Optional\u0026lt;base::Value\u0026gt;, base::Optional\u0026lt;std::__Cr::basic_string\u0026lt;char, std::__Cr::char_traits\u0026lt;char\u0026gt;, std::__Cr::allocator\u0026lt;char\u0026gt; \u0026gt; \u0026gt; const\u0026amp;), scoped_refptr\u0026lt;extensions::SandboxedUnpacker\u0026gt; \u0026gt;, void (base::Optional\u0026lt;base::Value\u0026gt;, base::Optional\u0026lt;std::__Cr::basic_string\u0026lt;char, std::__Cr::char_traits\u0026lt;char\u0026gt;, std::__Cr::allocator\u0026lt;char\u0026gt; \u0026gt; \u0026gt; const\u0026amp;)\u0026gt;::RunOnce(base::internal::BindStateBase*, base::Optional\u0026lt;base::Value\u0026gt;\u0026amp;\u0026amp;, base::Optional\u0026lt;std::__Cr::basic_string\u0026lt;char, std::__Cr::char_traits\u0026lt;char\u0026gt;, std::__Cr::allocator\u0026lt;char\u0026gt; \u0026gt; \u0026gt; const\u0026amp;) (base=0x29624e775db0, unbound_args=..., unbound_args=...) at ../../base/bind_internal.h:641 #5 0x0000555557758b38 in base::OnceCallback\u0026lt;void (mojo::InlinedStructPtr\u0026lt;media::mojom::CdmPromiseResult\u0026gt;, std::__Cr::basic_string\u0026lt;char, std::__Cr::char_traits\u0026lt;char\u0026gt;, std::__Cr::allocator\u0026lt;char\u0026gt; \u0026gt; const\u0026amp;)\u0026gt;::Run(mojo::InlinedStructPtr\u0026lt;media::mojom::CdmPromiseResult\u0026gt;, std::__Cr::basic_string\u0026lt;char, std::__Cr::char_traits\u0026lt;char\u0026gt;, std::__Cr::allocator\u0026lt;char\u0026gt; \u0026gt; const\u0026amp;) \u0026amp;\u0026amp; (this=0x29624ea9d348, args=..., args=...) at ../../base/callback.h:97 #6 0x0000555557b9a041 in data_decoder::mojom::JsonParser_Parse_ForwardToCallback::Accept(mojo::Message*) (this=0x29624ea9d340, message=0x7fffbb0af7d0) at gen/services/data_decoder/public/mojom/json_parser.mojom.cc:194 #7 0x00007ffff7b7fb9d in mojo::InterfaceEndpointClient::HandleValidatedMessage(mojo::Message*) (this=0x29624f2fe560, message=0x7fffbb0af7d0) at ../../mojo/public/cpp/bindings/lib/interface_endpoint_client.cc:428 #8 0x00007ffff7b7f631 in mojo::InterfaceEndpointClient::HandleIncomingMessageThunk::Accept(mojo::Message*) (this=0x29624f2fe590, message=0x7fffbb0af7d0) at ../../mojo/public/cpp/bindings/lib/interface_endpoint_client.cc:133 #9 0x00007ffff7b7e39b in mojo::FilterChain::Accept(mojo::Message*) (this=0x29624f2fe5a0, message=0x7fffbb0af7d0) at ../../mojo/public/cpp/bindings/lib/filter_chain.cc:40 ","permalink":"https://yplam.com/posts/chromium/chromium-image-decode-error/","summary":"\u003cp\u003e偶尔有收到用户关于 \u0026ldquo;Could not decode image: ***\u0026rdquo; 的反馈，并且最近频率有增加的趋势，解开\nTheme 文件除了图片有点大以外看不出其他问题，所以决定花点时间跟踪一下 Chromium 源码。\u003c/p\u003e","title":"Chromium 源码阅读：Could not decode image bug 跟踪"},{"content":"阅读 Chromium 源码的过程中，发现最大的障碍在于自己对 C++ 的理解还停留在大学时期，平时使用 C++ 也 仅仅停留在写个简单类，单例、工厂等简单的模式；所以在此针对 Chromium 源码中自己未曾用过的编程方式 做一个笔记。\nstd:move std:move 可以将 lvalue 转换成 rvalue，减少对象复制，提高效率。\nlvalue: 有名称的、在内存中有实际位置供程序员存取的物件。\nrvalue：没有名称的临时物件，离开当前语句后即被摧毁，如 f(a+b) 中的 a+b\nC++ 11 提供针对 rvalue 引用的方法重载，因为拿到的是 rvalue，那么在方法内部就可以随便把 rvalue 的内容拿来用，因为我们用完后 rvalue 也没有其他用途了，所以可以跳过复制的步骤，提高效率。\nclass string { char* data; public: string(const char* p) { size_t size = strlen(p) + 1; data = new char[size]; memcpy(data, p, size); } ~string() { delete[] data; } string(const string\u0026amp; that) { size_t size = strlen(that.data) + 1; data = new char[size]; memcpy(data, that.data, size); } string(string\u0026amp;\u0026amp; that) // string\u0026amp;\u0026amp; is an rvalue reference to a string { data = that.data; that.data = nullptr; } } 参考：\n[C++] rvalue reference 初入門 What are move semantics? ","permalink":"https://yplam.com/posts/chromium/chromium-cpp/","summary":"\u003cp\u003e阅读 Chromium 源码的过程中，发现最大的障碍在于自己对 C++ 的理解还停留在大学时期，平时使用 C++ 也\n仅仅停留在写个简单类，单例、工厂等简单的模式；所以在此针对 Chromium 源码中自己未曾用过的编程方式\n做一个笔记。\u003c/p\u003e","title":"Chromium 源码阅读：C++ 基础"},{"content":"从上一篇知道 chrome/browser/themes/ 的数据流为从 Extension Service 得到 Theme 安装信息，并且通过 BrowserThemeProvider 为 UI 层提供 Theme UI 信息。本篇分析 UI 的 views 层，不过由于 views 层代码量实在庞大，以及对 Chromium 内部实现机制欠缺了解，所以本文只能作为一个入门概览。\nChromium 官方有提供一个关于 Views 层调试的文档: https://chromium.googlesource.com/chromium/src/+/master/docs/graphical_debugging_aid_chromium_views.md ,不过我用 gdb 的 viewg 始终没有合法的输出，所以最终使用直接代码输出 Log 的方式：\n2019-03-16 更新： 可能是编写 viewg 脚本的开发者粗心或者脚本没及时更新，发现是错把 views 写成 view 了，于是我给官方提交了个 bug fix，然后成了 Chromium 代码贡献量最少的开发者（一个字母，哈哈）。\nGDB 加载完成后使用此命令加载 viewg:\nsource tools/gdb/viewg.gdb 然后添加断点，只要是继承自 View 的类都可以，非静态方法:\nbreak BrowserView::OnActiveTabChanged(content::WebContents*, content::WebContents*, int, int) 切换浏览器标签进入断点后，使用 viewg 命令，就会在个人目录生成 state.svg 文件，拖到浏览器就可以访问。\n以下为旧版本\nBrowserView(chrome/browser/ui/views/frame/browser_view.cc) 算是浏览器窗口 view 的根（继承自views::View），通过 BrowserView 可以打印出整个浏览器 views 树的结构。在 BrowserView 的非静态方法中加入：\nLOG(WARNING) \u0026lt;\u0026lt; \u0026#34;\u0026#34; \u0026lt;\u0026lt; std::endl \u0026lt;\u0026lt;views::PrintViewGraph(this) \u0026lt;\u0026lt; std::endl; 然后编译运行 chrome 就可以在终端日志中得到 views 树输出的 dot 文件内容，将其保存到 ”~/state.dot“，然后通过下面指令生成 svg 图片：\ndot -Tsvg -o ~/state.svg ~/state.dot END旧版本\n注：图片如下，宽度超标，请拖到新窗口查看原图。\n↓↓↓↓↓↓↓↓↓↓\n↑↑↑↑↑↑↑↑↑↑\n其中 bounds: (4, 5), (913x1021) 的含义是 x=4，y=5，width=912，height=1021，而那些处于隐藏状态的 view 这几个值中的一个或多个为 0。\n","permalink":"https://yplam.com/posts/chromium/chromium-src-browser-ui-views/","summary":"\u003cp\u003e从上一篇知道 chrome/browser/themes/ 的数据流为从 Extension Service 得到 Theme 安装信息，并且通过 BrowserThemeProvider 为 UI 层提供 Theme UI 信息。本篇分析 UI 的 views 层，不过由于 views 层代码量实在庞大，以及对 Chromium 内部实现机制欠缺了解，所以本文只能作为一个入门概览。\u003c/p\u003e","title":"Chromium 源码阅读：chrome/browser/ui/views 入门概览"},{"content":"前言：最近花了几天时间解决 Chromium CRX3 文件格式编码问题，然后决定用部分业余时间学习 Chromium 源码，从 UI/Theme/Extension 开始。（因为7,8年前曾经马马虎虎地看了一遍 Theme 以及其渲染过程的代码，并且写了一个简单的 Theme 打包工具，所以现在决定还是以此作为入口。）\nchrome/browser/themes/\nchrome/browser/themes/ 目录包含跟 Theme 格式定义相关代码，Theme 加载相关代码，以及全局的 ThemeService，但并不包含关于 Theme 如何渲染浏览器外观的代码,不包含关于 CRX 打包解包相关代码。\n文件概览 CustomThemeSupplier\ncustom_theme_supplier.cc custom_theme_supplier.h CustomThemeSupplier 是 Theme 表示的基类，并没有提供有效的实现。\nBrowserThemePack\nbrowser_theme_pack.cc browser_theme_pack.h browser_theme_pack_unittest.cc 继承自 CustomThemeSupplier 使用DataPack优化过的Theme表示方式，在Theme安装的时候对图片等进行预处理，然后保存成mmappable文件，用来提升性能。\nIncreasedContrastThemeSupplier\nincreased_contrast_theme_supplier.cc increased_contrast_theme_supplier.h 继承自 CustomThemeSupplier，提供高对比度的 Theme\nThemeProperties\ntheme_properties.cc theme_properties.h theme_properties_unittest.cc ThemeProperties 提供 Theme 相关的属性定义，并提供默认值，Static only class for querying which properties / images are themeable and the defaults of these properties.\nThemeService\ntheme_service.h theme_service.cc theme_service_unittest.cc theme_service_browsertest.cc ThemeService 为 Theme 服务类，负责加载用户设置的 Theme，删除无用的 Theme（监听 extensions::NOTIFICATION_EXTENSIONS_READY_DEPRECATED， 并且延时后），启动 Theme 同步服务。 并且响应 OnExtensionLoaded 事件，更新 Theme。同时为 UI 层提供 ThemeProvide。\nThemeServiceWin\ntheme_service_win.cc theme_service_win.h ThemeServiceWin 继承自ThemeService，针对 Windows 10 的颜色做相关处理。\nThemeServiceAuraX11\ntheme_service_aurax11.cc theme_service_aurax11.h ThemeServiceAuraX11 继承自ThemeService，提供原生的 X11 theme 支持。\nThemeServiceFactory\ntheme_service_factory.cc theme_service_factory.h ThemeServiceFactory 为工厂模式单例，使用者通过 ThemeServiceFactory::GetForProfile 获取当前使用的 ThemeService。\nThemeSyncableService\ntheme_syncable_service.cc theme_syncable_service.h theme_syncable_service_unittest.cc ThemeSyncableService 为 Theme 同步服务，本地安装新 Theme 后同步到后端，并且响应后端同步信息的改变。\n一些流程 为 UI 层提供数据\n浏览器 UI 层，如 chrome/browser/ui/views/bookmarks/bookmark_bar_view.cc 均继承自 views::View (ui/views/view.h) 所有 View 都可以通过 ui::ThemeProvider* GetThemeProvider() ，获取 ThemeProvider 句柄，然后通过 ThemeProvider 获取经过 Theme 后的 UI 颜色、图片等。GetThemeProvider 最终会调用 ThemeService::GetThemeProviderForProfile 或者 ThemeService::GetDefaultThemeProviderForProfile，返回的为 ThemeService 的内部类：\nclass BrowserThemeProvider : public ui::ThemeProvider 在此完成 ThemeService 与 ui::ThemeProvider 的解耦与调用。\nTheme 安装流程\nThemeService 通过加载安装的 Theme，通过 BrowserThemeProvider 内部类提供 UI 层所需的数据，然后通过内部类：\nclass ThemeService::ThemeObserver : public extensions::ExtensionRegistryObserver 与 Extension 子系统的的 ExtensionRegistry 关联，当安装新扩展时，ExtensionRegistry 服务就会回调所有 ExtensionRegistryObserver 的 OnExtensionLoaded 方法，如果此扩展为 Theme，则通过 theme service 更新。\nThemeService::ThemeObserver::OnExtensionLoaded 调用回溯：\n#0 0x000055555916362b in ThemeService::ThemeObserver::OnExtensionLoaded(content::BrowserContext*, extensions::Extension const*) (this=0x3eac7df9acd0, browser_context=0x3eac7ca81ba0, extension=0x3eac7ebd1fe0) at ../../chrome/browser/themes/theme_service.cc:264 #1 0x000055555794596c in extensions::ExtensionRegistry::TriggerOnLoaded(extensions::Extension const*) (this=0x3eac7cad7a20, extension=0x3eac7ebd1fe0) at ../../extensions/browser/extension_registry.cc:64 #2 0x0000555557941c1e in extensions::ExtensionRegistrar::ActivateExtension(extensions::Extension const*, bool) (this=0x3eac7c3b2a60, extension=0x3eac7ebd1fe0, is_newly_added=true) at ../../extensions/browser/extension_registrar.cc:450 #3 0x00005555579419df in extensions::ExtensionRegistrar::AddNewExtension(scoped_refptr\u0026lt;extensions::Extension const\u0026gt;) (this=0x3eac7c3b2a60, extension=...) at ../../extensions/browser/extension_registrar.cc:140 #4 0x0000555557940bf1 in extensions::ExtensionRegistrar::AddExtension(scoped_refptr\u0026lt;extensions::Extension const\u0026gt;) (this=0x3eac7c3b2a60, extension=...) at ../../extensions/browser/extension_registrar.cc:105 #5 0x000055555a1f88d3 in extensions::ExtensionService::AddExtension(extensions::Extension const*) (this=0x3eac7c3b2820, extension=0x3eac7ebd1fe0) at ../../chrome/browser/extensions/extension_service.cc:1188 #6 0x000055555a1fad83 in extensions::ExtensionService::FinishInstallation(extensions::Extension const*) (this=0x3eac7c3b2820, extension=0x3eac7ebd1fe0) at ../../chrome/browser/extensions/extension_service.cc:1617 #7 0x000055555a1f90c5 in extensions::ExtensionService::AddNewOrUpdatedExtension(extensions::Extension const*, extensions::Extension::State, int, syncer::Ordinal\u0026lt;syncer::StringOrdinalTraits\u0026gt; const\u0026amp;, std::__ Cr::basic_string\u0026lt;char, std::__Cr::char_traits\u0026lt;char\u0026gt;, std::__Cr::allocator\u0026lt;char\u0026gt; \u0026gt; const\u0026amp;, base::Optional\u0026lt;int\u0026gt; const\u0026amp;) (this=0x3eac7c3b2820, extension=0x3eac7ebd1fe0, initial_state=extensions::Extension::ENABLED, install_flags=8, page_ordinal=..., install_parameter=..., dnr_ruleset_checksum=...) at ../../chrome/browser/extensions/extension_service.cc:1557 #8 0x000055555a1fa268 in extensions::ExtensionService::OnExtensionInstalled(extensions::Extension const*, syncer::Ordinal\u0026lt;syncer::StringOrdinalTraits\u0026gt; const\u0026amp;, int, base::Optional\u0026lt;int\u0026gt; const\u0026amp;) (this=0x3eac7c3b2820, extension=0x3eac7ebd1fe0, page_ordinal=..., install_flags=8, dnr_ruleset_checksum=...) at ../../chrome/browser/extensions/extension_service.cc:1484 #9 0x000055555a1ba42a in extensions::CrxInstaller::ReportSuccessFromUIThread() (this=0x3eac7f4ed020) at ../../chrome/browser/extensions/crx_installer.cc:956 ","permalink":"https://yplam.com/posts/chromium/chromium-src-chrome-browser-themes/","summary":"\u003cp\u003e前言：最近花了几天时间解决 Chromium CRX3 文件格式编码问题，然后决定用部分业余时间学习 Chromium 源码，从 UI/Theme/Extension 开始。（因为7,8年前曾经马马虎虎地看了一遍 Theme 以及其渲染过程的代码，并且写了一个简单的 Theme 打包工具，所以现在决定还是以此作为入口。）\u003c/p\u003e","title":"Chromium 源码阅读：chrome/browser/themes"},{"content":"最近手上有个小项目需要兼容 Chrome CRX3 版本的扩展格式，Google 了一下竟然完全没有相关介绍文档，于是决定啃一下相关代码。\n本文会持续更新，最后更新时间： 2019-03-06，如有问题欢迎联系 yplam(at)yplam.com。\n上次编译 Chromium 已经是 N 年前的事情，那时伟大的墙还没现在那么大存在感，按官方步骤编译就可以，然而现时（2019年2月）按官方文档竟然连代码都下不下来。本文作为此过程的记录（主要是解决墙的问题）。\n环境：P52(CPU i7-8850H + 16GB内存 + 250GB SSD) + Manjaro 18 Linux（如果你使用的是 Windows 环境，可以参考本文末尾关于 Windows 下的编译方法）。\n环境要求：\n64位系统，需要 8GB 内存（建议16G以上）跟 100GB 硬盘，经测试编译后大概用掉60GB空间，但按默认选项用掉的空间应该会多点。 需要保证有一个高速的科学上网环境，并且需要提供 http proxy，源码大概有 30GB。 git python2，经测试 virtualenv 下的 python2 无法使用，可能是因为某些脚步会调用 bash，跳出 virtualenv 的环境。（如果您解决了这个问题，欢迎反馈，谢谢） 编译 Chromium 基本上按照官方文档,只是开始前解决 proxy 跟 python 版本问题。\n注意：下面过程可能会对您操作系统造成不可知的错误，请仅作为参考\n先查看系统 python 版本：\npython --version 如果不是 2.x 则可以通过建立软链的方式切换到 Python2（或者使用你系统自带的切换工具）\ncd $(dirname $(which python)) \u0026amp;\u0026amp; sudo rm python \u0026amp;\u0026amp; sudo ln -s python2 python 假设 http proxy 端口为 8123，创建 boto.cfg 文件，记下保存路径：\n[Boto] proxy=127.0.0.1 proxy_port=8123 配置 proxy 相关内容：\nexport http_proxy=\u0026#34;127.0.0.1:8123\u0026#34; export https_proxy=\u0026#34;127.0.0.1:8123\u0026#34; export NO_AUTH_BOTO_CONFIG={your path}/boto.cfg git config --global http.proxy 127.0.0.1:8123 至此，可以按照官方文档进行编译。\n下面为相关命令，运行前需要先保证有稳定的网络，以及接上外部电源，在我的 P52 上下载源码大概需要 2小时，编译大概需要 3 小时：\n注意：下面为Manjaro下的编译方式，其他系统请按需修改或者参考官方文档。\nsudo pacman -S --needed python perl gcc gcc-libs bison flex gperf pkgconfig nss alsa-lib glib2 gtk3 nspr ttf-ms-fonts freetype2 cairo dbus libgnome-keyring git clone https://chromium.googlesource.com/chromium/tools/depot_tools.git export PATH=\u0026#34;$PATH:/path/to/depot_tools\u0026#34; mkdir chromium \u0026amp;\u0026amp; cd chromium fetch --nohooks chromium cd src gclient runhooks gn gen --enable_nacl=false --symbol_level=1 --remove_webcore_debug_symbols=true out/Default autoninja -C out/Default chrome git config --global --unset-all http.proxy cd $(dirname $(which python)) \u0026amp;\u0026amp; sudo rm python \u0026amp;\u0026amp; sudo ln -s python3 python 如无意外会生成 out/Default/chrome ,尝试一下是否可以正常运行 ./out/Default/chrome \u0026ndash;no-sandbox\n更新代码 更新代码的方式与上面类似，主要是解决 proxy 问题：\ncd $(dirname $(which python)) \u0026amp;\u0026amp; sudo rm python \u0026amp;\u0026amp; sudo ln -s python2 python export http_proxy=\u0026#34;127.0.0.1:8123\u0026#34; export https_proxy=\u0026#34;127.0.0.1:8123\u0026#34; export NO_AUTH_BOTO_CONFIG=/home/yplam/work/chromium/boto.cfg git config --global http.proxy 127.0.0.1:8123 git rebase-update gclient sync git config --global --unset-all http.proxy cd $(dirname $(which python)) \u0026amp;\u0026amp; sudo rm python \u0026amp;\u0026amp; sudo ln -s python3 python 编译与运行TEST 使用 gn ls 命令可以列出所有可编译的 target，譬如，我想跑跑 ui/gfx/color_utils_unittest.cc ，那么可以使用类似命令找出来:\ngn ls out/Default | grep test | grep ui | grep gfx 可以看到 //ui/gfx:gfx_unittests 的存在， gfx_unittests 定义在 ui/gfx/BUILD.gn，包含 color_utils_unittest.cc。\n可以通过下面命令编译与运行：\nninja -C out/Default ui/gfx:gfx_unittests out/Default/gfx_unittests --gtest_filter=\u0026#34;ColorUtils.*\u0026#34; 因为编译 TEST 比编译整个 Chromium 要快得多，可以通过此方式比较简单的了解与跟踪某些代码的运行。\nGDB 调试 Chromium 官方文档在此：https://chromium.googlesource.com/chromium/src/+/master/docs/linux_debugging.md\n由于GDB启动较慢，如果只是想简单的跟踪一下程序运行信息，可以直接使用 base/logging.h 中定义的方法，如：\nLOG(INFO) \u0026lt;\u0026lt; \u0026#34;Found \u0026#34; \u0026lt;\u0026lt; num_cookies \u0026lt;\u0026lt; \u0026#34; cookies\u0026#34;; 再结合上面提到的 TEST，用来跟踪一些小功能的代码比较有效率。当然，如果要对浏览器运行时的状态进行细致一点的跟踪，那么应该还是用 gdb 好点。\n譬如，chrome/browser/themes/theme_service.cc 提供 Theme 服务类，通过阅读代码，可以知道对 Theme 的更新是通过外部调用 ThemeObserver 的 OnExtensionLoaded 方法更新的，但对于是如何调用 OnExtensionLoaded 的 却不是那么容易可以看出来，那么我们可以简单的使用 GDB 的 backtrace 来查看。\n在开始调试前请保证你的电脑有足够内存（应该需要 5GB+ 的内存，反正我 16GB 内存如果运行其他应用的话有时会内存耗尽），在 src 目录运行下面命令：\ngdb -tui --args out/Default/chrome --disable-seccomp-sandbox http://google.com 加载需要点时间，加载后设置断点，在 theme_service.cc 的 264 行设置断点：\nb theme_service.cc:264 然后运行\nr 启动过程中可能遇到其他断点，使用\nc 继续运行。\n然后进入 extension 页面，打开 developer 模式，拖一个 crx Theme 扩展进去，此时会进入我们的断点，然后\nbt 或者如果只需要看最近8个 backtrace：\nbt 8 得到下面关于 ThemeService::ThemeObserver::OnExtensionLoaded 的调用回溯：\n#0 0x000055555916362b in ThemeService::ThemeObserver::OnExtensionLoaded(content::BrowserContext*, extensions::Extension const*) (this=0x30e87097be90, browser_context=0x30e86f3abca0, extension=0x30e871bd6260) at ../../chrome/browser/themes/theme_service.cc:264 #1 0x000055555794596c in extensions::ExtensionRegistry::TriggerOnLoaded(extensions::Extension const*) (this=0x30e86f412a20, extension=0x30e871bd6260) at ../../extensions/browser/extension_registry.cc:64 #2 0x0000555557941c1e in extensions::ExtensionRegistrar::ActivateExtension(extensions::Extension const*, bool) (this=0x30e86f9dda60, extension=0x30e871bd6260, is_newly_added=true) at ../../extensions/browser/extension_registrar.cc:450)] 244 #3 0x00005555579419df in extensions::ExtensionRegistrar::AddNewExtension(scoped_refptr\u0026lt;extensions::Extension const\u0026gt;) (this=0x30e86f9dda60, extension=...) at ../../extensions/browser/extension_registrar.cc:140 #4 0x0000555557940bf1 in extensions::ExtensionRegistrar::AddExtension(scoped_refptr\u0026lt;extensions::Extension const\u0026gt;) (this=0x30e86f9dda60, extension=...) at ../../extensions/browser/extension_registrar.cc:105 #5 0x000055555a1f88d3 in extensions::ExtensionService::AddExtension(extensions::Extension const*) (this=0x30e86f9dd820, extension=0x30e871bd6260) at ../../chrome/browser/extensions/extension_service.cc:1188 #6 0x000055555a1fad83 in extensions::ExtensionService::FinishInstallation(extensions::Extension const*) (this=0x30e86f9dd820, extension=0x30e871bd6260) at ../../chrome/browser/extensions/extension_service.cc:1617 #7 0x000055555a1f90c5 in extensions::ExtensionService::AddNewOrUpdatedExtension(extensions::Extension const*, extensions::Extension::State, int, syncer::Ordinal\u0026lt;syncer::StringOrdinalTraits\u0026gt; const\u0026amp;, std::_ _Cr::basic_string\u0026lt;char, std::__Cr::char_traits\u0026lt;char\u0026gt;, std::__Cr::allocator\u0026lt;char\u0026gt; \u0026gt; const\u0026amp;, base::Optional\u0026lt;int\u0026gt; const\u0026amp;) (this=0x30e86f9dd820, extension=0x30e871bd6260, initial_state=extensions::Extension::ENABLED, install_flags=0, page_ordinal=..., install_parameter=..., dnr_ruleset_checksum=...) 我们继续执行：\nc 完成关闭浏览器退出，在 gdb 输入：\nq 退出。\n因为对 GDB 也不熟悉，上面只演示了一个基础操作。（ps: GDB的官方文档较枯燥，在网上找找别人的使用心得分享，譬如100-gdb-tips, gdb Debugging Full Example）\n关于CRX3格式的调试结果记录 CRX3格式相关代码位于：\ncomponents/crx_file/crx_creator.cc line 62：\nCreatorResult Create(const base::FilePath\u0026amp; output_path, const base::FilePath\u0026amp; zip_path, crypto::RSAPrivateKey* signing_key) 跟 CRX2 最大的区别在于 CrxFileHeader 部分现在不再是简单的 length+data 的格式，而是使用 Protobuf 编码后的二进制数据，Protobuf格式为 crx3.proto 所示：\n// Copyright 2017 The Chromium Authors. All rights reserved. // Use of this source code is governed by a BSD-style license that can be // found in the LICENSE file syntax = \u0026#34;proto2\u0026#34;; option optimize_for = LITE_RUNTIME; package crx_file; // A CRX₃ file is a binary file of the following format: // [4 octets]: \u0026#34;Cr24\u0026#34;, a magic number. // [4 octets]: The version of the *.crx file format used (currently 3). // [4 octets]: N, little-endian, the length of the header section. // [N octets]: The header (the binary encoding of a CrxFileHeader). // [M octets]: The ZIP archive. // Clients should reject CRX₃ files that contain an N that is too large for the // client to safely handle in memory. message CrxFileHeader { // PSS signature with RSA public key. The public key is formatted as a // X.509 SubjectPublicKeyInfo block, as in CRX₂. In the common case of a // developer key proof, the first 128 bits of the SHA-256 hash of the // public key must equal the crx_id. repeated AsymmetricKeyProof sha256_with_rsa = 2; // ECDSA signature, using the NIST P-256 curve. Public key appears in // named-curve format. // The pinned algorithm will be this, at least on 2017-01-01. repeated AsymmetricKeyProof sha256_with_ecdsa = 3; // The binary form of a SignedData message. We do not use a nested // SignedData message, as handlers of this message must verify the proofs // on exactly these bytes, so it is convenient to parse in two steps. // // All proofs in this CrxFile message are on the value // \u0026#34;CRX3 SignedData\\x00\u0026#34; + signed_header_size + signed_header_data + // archive, where \u0026#34;\\x00\u0026#34; indicates an octet with value 0, \u0026#34;CRX3 SignedData\u0026#34; // is encoded using UTF-8, signed_header_size is the size in octets of the // contents of this field and is encoded using 4 octets in little-endian // order, signed_header_data is exactly the content of this field, and // archive is the remaining contents of the file following the header. optional bytes signed_header_data = 10000; } message AsymmetricKeyProof { optional bytes public_key = 1; optional bytes signature = 2; } message SignedData { // This is simple binary, not UTF-8 encoded mpdecimal; i.e. it is exactly // 16 bytes long. optional bytes crx_id = 1; } 其中 crx_id 为 RSA public key 的 sha256 编码后的前 16 byte。signed_header_data 为 \u0026ldquo;CRX3 SignedData\\x00\u0026rdquo; + signed_header_size + signed_header_data + zip archive 的 OPENSSL_ALGO_SHA256 编码（使用私钥）\n关于 Protobuf 可以使用 Google 官方库，然而由于在此只使用了 bytes 数据类型，操作起来比较简单，可以参考 https://developers.google.com/protocol-buffers/docs/encoding 直接对二进制流进行读写操作。\nWindows 环境下编译 Chromium 下面附带分享一下 Windows 环境编译 Chromium 的附加内容。（2019年1月经测试可以正常下载代码与编译）\n首先第一步是能够解决科学上网，并且网速要够快。\n下载解压 depot_tools 后，先配置proxy，用管理员打开命令行\nnetsh winhttp set proxy 127.0.0.1:1080 修改depot_tools 目录中的 cipd.ps1 文件，配置 System.Net.WebClient 使用代理\n... $proxyAddr = \u0026#34;http://127.0.0.1：1080\u0026#34; $proxy = new-object System.Net.WebProxy $proxy.Address = $proxyAddr ... $wc.proxy = $proxy ... 可能还需要添加这两个命令行变量，不然初次运行gclient可能会报错：\nset HTTP_PROXY=http://127.0.0.1:1080 set HTTPS_PROXY=%HTTP_PROXY% 按官方文档继续配置 depot_tools\n结束后复位一下代理：\nnetsh winhttp reset proxy 后记 折腾了几天 Chromium，解决了 CRX3 文件格式编码问题，突然有点不想就此打住的念头。Chromium 算是自己能遇到的最复杂最优秀的开源项目以及代码库了吧，难得有机会，要不继续学习下去？ Why not？\n参考资料 Checking out and building Chromium on Linux Tips for debugging on Linux Sync Chromium src behind proxy http://blog.gclxry.com/ ","permalink":"https://yplam.com/posts/chromium/chromium-build-debug/","summary":"\u003cp\u003e最近手上有个小项目需要兼容 Chrome CRX3 版本的扩展格式，Google 了一下竟然完全没有相关介绍文档，于是决定啃一下相关代码。\u003c/p\u003e","title":"Chromium 编译与调试笔记"},{"content":"之前用现成的Lora串口模块感觉挺顺手，最近偶尔看到带 LoraRanging 功能的 SX1280，于是买了两个模块回来测试一下。\n源码地址 https://github.com/yplam/LoraRangingTest\n基于 mbed 与 STM32 Nucleo-64 开发板；主机为 NUCLEO_F411RE，从机为 NUCLEO_L476RG。\n硬件为两个 Morpho 转接板，板载一个高抑制比的LDO，使用 SPI 接口通讯；\n![硬件]({{ site.url }}/assets/2019/LoraRangingTest.jpg \u0026ldquo;硬件\u0026rdquo;)\n![电路图]({{ site.url }}/assets/2019/Schematic.png \u0026ldquo;电路图\u0026rdquo;)\n编译 先配置好 mbed 命令行工具以及git，然后运行\ngit clone https://github.com/yplam/LoraRangingTest.git mbed deploy mbed compile -m NUCLEO_F411RE -t gcc_arm mbed compile -m NUCLEO_L476RG -t gcc_arm 主机固件: ./BUILD/NUCLEO_F411RE/GCC_ARM/LoraRangingTest.hex\n从机固件: ./BUILD/NUCLEO_L476RG/GCC_ARM/LoraRangingTest.hex\nmbed_app.json 引脚配置：\n{ \u0026#34;config\u0026#34;: { \u0026#34;trace-level\u0026#34;: { \u0026#34;help\u0026#34;: \u0026#34;Options are TRACE_LEVEL_ERROR,TRACE_LEVEL_WARN,TRACE_LEVEL_INFO,TRACE_LEVEL_DEBUG\u0026#34;, \u0026#34;macro_name\u0026#34;: \u0026#34;MBED_TRACE_MAX_LEVEL\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;TRACE_LEVEL_INFO\u0026#34; } }, \u0026#34;target_overrides\u0026#34;: { \u0026#34;*\u0026#34;: { \u0026#34;target.features_add\u0026#34;: [\u0026#34;COMMON_PAL\u0026#34;], \u0026#34;mbed-trace.enable\u0026#34;: true, \u0026#34;platform.stdio-convert-newlines\u0026#34;: true }, \u0026#34;NUCLEO_F411RE\u0026#34;: { \u0026#34;platform.default-serial-baud-rate\u0026#34;: 115200, \u0026#34;target.OUTPUT_EXT\u0026#34;: \u0026#34;hex\u0026#34;, \u0026#34;target.macros\u0026#34;: [ \u0026#34;LORA_MOSI=PA_7\u0026#34;, \u0026#34;LORA_MISO=PA_6\u0026#34;, \u0026#34;LORA_SCLK=PA_5\u0026#34;, \u0026#34;LORA_NSS=PA_4\u0026#34;, \u0026#34;LORA_BUSY=PC_8\u0026#34;, \u0026#34;LORA_DIO1=PC_6\u0026#34;, \u0026#34;LORA_RST=PA_12\u0026#34;, \u0026#34;APP_HAS_LCD=1\u0026#34;, \u0026#34;LCD_MOSI=PC_3\u0026#34;, \u0026#34;LCD_MISO=PC_2\u0026#34;, \u0026#34;LCD_SCLK=PB_10\u0026#34;, \u0026#34;LCD_NSS=PB_12\u0026#34;, \u0026#34;LCD_RESET=PC_10\u0026#34;, \u0026#34;LCD_DC=PC_11\u0026#34;, \u0026#34;APP_LED1=PC_9\u0026#34;, \u0026#34;APP_LED2=PC_5\u0026#34;, \u0026#34;APP_ENTITY_MODE=MASTER\u0026#34; ] }, \u0026#34;NUCLEO_L476RG\u0026#34;: { \u0026#34;platform.default-serial-baud-rate\u0026#34;: 115200, \u0026#34;target.OUTPUT_EXT\u0026#34;: \u0026#34;hex\u0026#34;, \u0026#34;target.macros\u0026#34;: [ \u0026#34;LORA_MOSI=PA_7\u0026#34;, \u0026#34;LORA_MISO=PA_6\u0026#34;, \u0026#34;LORA_SCLK=PA_5\u0026#34;, \u0026#34;LORA_NSS=PA_4\u0026#34;, \u0026#34;LORA_BUSY=PC_8\u0026#34;, \u0026#34;LORA_DIO1=PC_6\u0026#34;, \u0026#34;LORA_RST=PA_12\u0026#34;, \u0026#34;APP_LED1=PB_13\u0026#34;, \u0026#34;APP_LED2=PC_5\u0026#34;, \u0026#34;APP_ENTITY_MODE=SLAVE\u0026#34; ] } } } 测试效果 周边走了一圈，板载PCB天线，SF7， BW800，发现最大距离也就100米多点（有点树阻挡），并且都有几米的范围波动，距离到100米时差不多在80到120之间\n本来想着如果能有1km左右测距距离的话还可以试试用来做低功耗牛羊耳标，但现在这种距离跟精度感觉真没什么地方可以用\n","permalink":"https://yplam.com/posts/embedded/lora-ranging-test/","summary":"\u003cp\u003e之前用现成的Lora串口模块感觉挺顺手，最近偶尔看到带 LoraRanging 功能的 SX1280，于是买了两个模块回来测试一下。\u003c/p\u003e\n\u003cp\u003e源码地址 \u003ca href=\"https://github.com/yplam/LoraRangingTest\"\u003ehttps://github.com/yplam/LoraRangingTest\u003c/a\u003e\u003c/p\u003e","title":"SX1280 LoraRanging 功能测试"},{"content":"此笔记记录 Mbed OS 在 STM32F405RG 下配置 Bootloader 的过程。 Mbed OS 是 Arm 公司推出的专门面向 Arm 微处理器以及物联网应用的开源实时操作系统。\n对于物联网应用而言，由于其设备联网的特性，可以方便的进行远程升级。一般而言，服务端会记录各个设备的版本信息，当有固件更新时，系统会发消息通知设备端，然后由用户确认升级或者设备自动选择合适时机升级。通常一个简单的升级流程为：设备接收到升级消息后，根据消息内容通过http、ftp等方式下载到本地文件系统，校验通过后按预设名称存储，然后重启。重启后先进入bootloader，bootloader查询文件系统中有预设名称的文件后就会使用 IAP（ In Application Programming）功能，读取新固件并且覆盖旧应用区的内容，删除文件系统中的固件文件，然后跳转到应用区执行。\nBootloader 关于Mbed Bootloader的内容请参考：https://os.mbed.com/docs/latest/tutorials/bootloader.html\n在此借用一下官方的图示：\n|-------------------| APPLICATION_ADDR + APPLICATION_SIZE == End of ROM | | ... | | | Application | | (main program ) | | | +-------------------+ APPLICATION_ADDR == BOOTLOADER_ADDR + BOOTLOADER_SIZE | | | Bootloader | |(my_bootloader.bin)| | | +-------------------+ BOOTLOADER_ADDR == Start of ROM 这次需要实现的 Bootloader 功能与官方范例（ https://github.com/ARMmbed/mbed-os-example-bootloader ）类似，区别在于从spi flash的littlefs上加载固件。由于系统初次上电时可能spi flash可能处于空的状态，因此需要加入文件系统格式化相关检测。由于需要使用 spi flash，在 targets.json 对应配置里需要加上：\n\u0026#34;device_has_add\u0026#34;: [\u0026#34;FLASH\u0026#34;] \u0026#34;components\u0026#34;: [\u0026#34;SPIF\u0026#34;] 在 mbed_app.json 中加上:\n\u0026#34;target.restrict_size\u0026#34;: \u0026#34;0x20000\u0026#34; 其作用在于限制Bootloader的大小，当Bootloader太大时会链接失败，当Bootloader太小时会自动补全到固定大小。\nApplication 应用程序mbed_config.json的配置：\n\u0026#34;target.bootloader_img\u0026#34;: \u0026#34;bootloader/my_bootloader.bin\u0026#34; Mbed 编译的时候会编译出两个bin文件，一个包含 Bootloader，用于出厂刷写，一个不包含 Bootloader，用于发布到后台下载升级。\n由于 Mbed 里并不是所有芯片都加入了 Bootloader 支持，如果你发现 Bootloader 无法跳转到应用程序，可以检查一下芯片的 ld 配置文件，譬如GCC：\n/* Linker script for STM32F405 */ #if !defined(MBED_APP_START) #define MBED_APP_START 0x08000000 #endif #if !defined(MBED_APP_SIZE) #define MBED_APP_SIZE 1024k #endif /* Linker script to configure memory regions. */ MEMORY { FLASH (rx) : ORIGIN = MBED_APP_START, LENGTH = MBED_APP_SIZE CCM (rwx) : ORIGIN = 0x10000000, LENGTH = 64K RAM (rwx) : ORIGIN = 0x20000188, LENGTH = 128K - 0x188 } Mbed cli 会根据项目中对bootloader_img等配置定义MBED_APP_START宏。\n将 system_clock.c 中 VTOR 的配置删除，因为 mbed_start_application 调用中已经进行适当的配置（参考 https://github.com/ARMmbed/mbed-os/commit/d2cf3413486f8c69a7fe81412c82e18bbf534a1e#diff-ea6486a2a085323e73374a757e011799）\n/** /*!\u0026lt; Uncomment the following line if you need to relocate your vector Table in Internal SRAM. */ /* #define VECT_TAB_SRAM */ #define VECT_TAB_OFFSET 0x00 /*!\u0026lt; Vector Table base offset field. This value must be a multiple of 0x200. */ /* Configure the Vector Table location add offset address ------------------*/ #ifdef VECT_TAB_SRAM SCB-\u0026gt;VTOR = SRAM_BASE | VECT_TAB_OFFSET; /* Vector Table Relocation in Internal SRAM */ #else SCB-\u0026gt;VTOR = FLASH_BASE | VECT_TAB_OFFSET; /* Vector Table Relocation in Internal FLASH */ #endif ","permalink":"https://yplam.com/posts/embedded/mbed-custom-bootloader/","summary":"\u003cp\u003e此笔记记录 Mbed OS 在 STM32F405RG 下配置 Bootloader 的过程。 Mbed OS 是 Arm 公司推出的专门面向 Arm 微处理器以及物联网应用的开源实时操作系统。\u003c/p\u003e","title":"Mbed Bootloader配置笔记"},{"content":"Universal Recommender (UR) 是 ActionML 公司基于 PredictionIO 开发的协同过滤引擎，使用 Correlated Cross-Occurrence (CCO) 算法，可以应用与个性化推荐、物品相关推荐、购物车推荐、基于业务逻辑的推荐等。\nCOO算法是协同过滤算法的一种，然而一般的协同过滤只能针对单一行为，CCO算法可以计算交叉行为下的协同关联。例如：它不仅可以通过用户的浏览行为来告诉你 “浏览了内容A的人可能会浏览内容B” ,它还能结合用户的浏览行为和用户的广告点击行为来告诉你 “点击了广告A的人可能会浏览内容F”。关于COO的详细介绍可参考下面文章：基于 CCO 的协同过滤推荐，Multi-domain predictive AI or how to make one thing predict another。\nPredictionIO 与 UR 安装\n参考 PredictionIO 与 UR 的官方文档安装，需要注意的是 UR 需要使用 Elasticsearch 来保存结果，现时（PredictionIO 0.12.1）默认支持的 Elasticsearch 版本为 5.。最简单的方式就是下载tar包然后解压到 PredictionIO 的 vonders/elasticsearch-5..* 目录，然后在pio-env.sh文件进行配置。\n配置完成后可以在 ur 的目录下运行以下命令进行测试：\n./examples/integration-test 此命令会使用 examples/handmade-engine.json 的配置，data/sample-handmade-data.txt 中的数据，导入数据，build模型，deploy模型，使用预设数据进行测试并且与预设结果进行对比。\nDASE实现\nDataSource 只接受 user-item 类型，事件类型可以有多种，如测试数据中的 purchase、view、category-pref，其中第一个为主事件，其余为次要事件。可以使用 $set 请求定义 item 属性。DataSource 读取事件日志，按事件名聚合事件；读取 item 信息，并且将 Properties 信息附加到 item 上；然后返回事件、Item相关的RDD。\nPreparator 根据 minEventsPerUser 的配置过滤掉主事件过少的用户，然后过滤掉没有主事件的用户以及其次要事件。因为 UR 算法需要用到 mahout，Preparator 需要将事件 RDD 转换为 org.apache.mahout.sparkbindings.indexeddataset.IndexedDatasetSpark 供算法使用。IndexedDatasetSpark 包含 userID 的 BiDictionary，itemID 的 BiDictionary 以及 经过 BiDictionary key转换的 user-item 矩阵。\nServing 与 RecommendationEngine 分别为用户请求的响应处理以及引擎的构造描述，较常规没有太多特殊内容。\nURAlgorithm 根据 URAlgorithmParams 配置训练模型，保存，然后做预测。train 过程计算主事件矩阵与自身以及个次要事件的 Log Likelihood Ratio（LLR） 矩阵，然后保存到 ElasticSearch。predict 过程将用户的输入转换为对 ElasticSearch 的搜索请求，此为模型核心。\n模型参数保存：历遍各 LLR 矩阵中的每一行，按降序排序每行的 releate_item，并且构造成 (itemID, Map(actionName -\u0026gt; JArray(vector[releate_item]))) ，然后通过 groupAll 操作，将每个 item 的事件内容与属性内容集合到一起，每个条目均得到类似以下格式内容：\n(Ipad-retina,Map(defaultRank -\u0026gt; JDouble(3.0), expires -\u0026gt; JString(2018-06-15T17:09:41.677740+00:00), countries -\u0026gt; JArray(List(JString(United States), JString(Estados Unidos Mexicanos))), date -\u0026gt; JString(2018-06-13T17:09:41.677740+00:00), category-pref -\u0026gt; JArray(List(JString(tablets))), categories -\u0026gt; JArray(List(JString(Tablets), JString(Electronics), JString(Apple))), available -\u0026gt; JString(2018-06-11T17:09:41.677740+00:00), purchase -\u0026gt; JArray(List(JString(Iphone 6), JString(Iphone 4))), popRank -\u0026gt; JDouble(2.0), view -\u0026gt; JArray(List(JString(Soap))))) 然后创建 Elasticsearch 表索引，最后将 RDD 保存到 Elasticsearch，我们可以先看看数据在 Elasticsearch 中的存在方式，这样会更加清晰：\nGET /urindex_1529048147127/_search { \u0026#34;_index\u0026#34;: \u0026#34;urindex_1529048147127\u0026#34;, \u0026#34;_type\u0026#34;: \u0026#34;items\u0026#34;, \u0026#34;_id\u0026#34;: \u0026#34;Iphone 4\u0026#34;, \u0026#34;_score\u0026#34;: 1, \u0026#34;_source\u0026#34;: { \u0026#34;defaultRank\u0026#34;: 5, \u0026#34;expires\u0026#34;: \u0026#34;2018-06-18T10:45:41.677+08:00\u0026#34;, \u0026#34;countries\u0026#34;: [ \u0026#34;United States\u0026#34;, \u0026#34;Canada\u0026#34;, \u0026#34;Estados Unidos Mexicanos\u0026#34; ], \u0026#34;id\u0026#34;: \u0026#34;Iphone 4\u0026#34;, \u0026#34;date\u0026#34;: \u0026#34;2018-06-16T10:45:41.677+08:00\u0026#34;, \u0026#34;category-pref\u0026#34;: [ \u0026#34;tablets\u0026#34; ], \u0026#34;categories\u0026#34;: [ \u0026#34;Phones\u0026#34;, \u0026#34;Electronics\u0026#34;, \u0026#34;Apple\u0026#34; ], \u0026#34;available\u0026#34;: \u0026#34;2018-06-14T10:45:41.677+08:00\u0026#34;, \u0026#34;purchase\u0026#34;: [ \u0026#34;Ipad-retina\u0026#34;, \u0026#34;Iphone 6\u0026#34; ], \u0026#34;popRank\u0026#34;: 4, \u0026#34;view\u0026#34;: [ \u0026#34;Soap\u0026#34;, \u0026#34;Tablets\u0026#34; ] } } 很明显这是一个基于产品的推荐系统，主事件为 purchase ，所以直观的解释就是 “购买了 Iphone 4 的用户还购买了 Ipad-retina，Iphone 6；购买了 Iphone 4 的用户浏览了 Soap，Tablets；Iphone 4 属于 Phones，Electronics，Apple 分类……”\nUR 模型的 predict 过程实际就是根据查询输入以及用户的历史事件（从Event Storage中查出），构造 ES 的 json query。\n模型定义查询结构如下：\ncase class Query( user: Option[String] = None, // must be a user or item id userBias: Option[Float] = None, // default: whatever is in algorithm params or 1 item: Option[String] = None, // must be a user or item id itemBias: Option[Float] = None, // default: whatever is in algorithm params or 1 itemSet: Option[List[String]] = None, // item-set query, shpping cart for instance. itemSetBias: Option[Float] = None, // default: whatever is in algorithm params or 1 fields: Option[List[Field]] = None, // default: whatever is in algorithm params or None currentDate: Option[String] = None, // if used will override dateRange filter, currentDate must lie between the item\u0026#39;s // expireDateName value and availableDateName value, all are ISO 8601 dates dateRange: Option[DateRange] = None, // optional before and after filter applied to a date field blacklistItems: Option[List[String]] = None, // default: whatever is in algorithm params or None returnSelf: Option[Boolean] = None, // means for an item query should the item itself be returned, defaults // to what is in the algorithm params or false num: Option[Int] = None, // default: whatever is in algorithm params, which itself has a default--probably 20 from: Option[Int] = None, // paginate from this position return \u0026#34;num\u0026#34; eventNames: Option[List[String]], // names used to ID all user actions withRanks: Option[Boolean] = None) // Add to ItemScore rank fields values, default false extends Serializable 然后转换为类似下面的请求：\n{ \u0026#34;size\u0026#34;: 20 \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;should\u0026#34;: [ { \u0026#34;terms\u0026#34;: { \u0026#34;rate\u0026#34;: [\u0026#34;0\u0026#34;, \u0026#34;67\u0026#34;, \u0026#34;4\u0026#34;] } }, { \u0026#34;terms\u0026#34;: { \u0026#34;buy\u0026#34;: [\u0026#34;0\u0026#34;, \u0026#34;32\u0026#34;], \u0026#34;boost\u0026#34;: 2 } }, { // categorical boosts \u0026#34;terms\u0026#34;: { \u0026#34;category\u0026#34;: [\u0026#34;cat1\u0026#34;], \u0026#34;boost\u0026#34;: 1.05 } } ], \u0026#34;must\u0026#34;: [ // categorical filters { \u0026#34;terms\u0026#34;: { \u0026#34;category\u0026#34;: [\u0026#34;cat1\u0026#34;], \u0026#34;boost\u0026#34;: 0 } }, { \u0026#34;must_not\u0026#34;: [//blacklisted items { \u0026#34;ids\u0026#34;: { \u0026#34;values\u0026#34;: [\u0026#34;items-id1\u0026#34;, \u0026#34;item-id2\u0026#34;, ...] } }, { \u0026#34;constant_score\u0026#34;: {// date in query must fall between the expire and available dates of an item \u0026#34;filter\u0026#34;: { \u0026#34;range\u0026#34;: { \u0026#34;availabledate\u0026#34;: { \u0026#34;lte\u0026#34;: \u0026#34;2015-08-30T12:24:41-07:00\u0026#34; } } }, \u0026#34;boost\u0026#34;: 0 } }, { \u0026#34;constant_score\u0026#34;: {// date range filter in query must be between these item property values \u0026#34;filter\u0026#34;: { \u0026#34;range\u0026#34; : { \u0026#34;expiredate\u0026#34; : { \u0026#34;gte\u0026#34;: \u0026#34;2015-08-15T11:28:45.114-07:00\u0026#34; \u0026#34;lt\u0026#34;: \u0026#34;2015-08-20T11:28:45.114-07:00\u0026#34; } } }, \u0026#34;boost\u0026#34;: 0 } }, { \u0026#34;constant_score\u0026#34;: { // this orders popular items for backfill \u0026#34;filter\u0026#34;: { \u0026#34;match_all\u0026#34;: {} }, \u0026#34;boost\u0026#34;: 0.000001 // must have as least a small number to be boostable } } } } } Universal Recommender 虽然原理比较简单，不过它巧妙地利用 Elasticsearch 将业务规则整合进来的方式确实可以给人带来启发。\n以上仅为个人总结笔记，能力所限可能有比较多错误，欢迎交流指正 yplam(at)yplam.com\n","permalink":"https://yplam.com/posts/machinelearning/predictionio-universal-recommender/","summary":"\u003cp\u003eUniversal Recommender (UR) 是 ActionML 公司基于 PredictionIO 开发的协同过滤引擎，使用 Correlated Cross-Occurrence (CCO) 算法，可以应用与个性化推荐、物品相关推荐、购物车推荐、基于业务逻辑的推荐等。\u003c/p\u003e","title":"PredictionIO Universal Recommender 笔记"},{"content":"关注 Apache PredictionIO 已有一段时间，最近需要做一个过滤论坛广告贴的功能，调研了一番市面上提供文本检测的API服务，发现靠谱的公司都比较贵，并且准确率不高（一个可能性是他们使用的训练数据集是互联网上的通用信息，而我们是一个垂直行业论坛，攻击来源也可能是固定的那么若干个），于是尝试自己实现个文本分类器来过滤广告。\n关于文本分类，首先想到的就是朴素贝叶斯分类器，其理论清晰简单，并且各大机器学习框架均支持。\n朴素贝叶斯分类器 关于贝叶斯分类器的的原理可以参考以下文档：算法杂货铺——分类算法之朴素贝叶斯分类(Naive Bayesian classification)\nSpark实现 下面是 Spark 贝叶斯分类器的实现，主要流程为:\n读入数据集 使用 ansj 分词，生成 (label, words) 结构的 dataframe 分割训练集与测试集 创建 HashingTF，IDF，NaiveBayes 的 Pipeline 模型 设置参数矩阵，然后使用 TrainValidationSplit 进行模型训练与参数选择 训练出 bestModal，保存到指定路径 通过最佳模型与测试集得出模型评估 实现代码如下：\npackage com.yplam import org.apache.log4j.{Level, Logger} import org.apache.spark.sql.{Row, SparkSession} import scopt.OptionParser import org.ansj.recognition.impl.StopRecognition import org.ansj.splitWord.analysis.ToAnalysis import org.apache.spark.ml.{Pipeline, PipelineModel} import org.apache.spark.ml.classification.NaiveBayes import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator import org.apache.spark.ml.feature.{HashingTF, IDF} import org.apache.spark.ml.tuning.{ParamGridBuilder, TrainValidationSplit} import org.apache.spark.mllib.evaluation.MulticlassMetrics object SpamFilterTrainer { /** * 运行参数 * @param trainInput 训练数据集路径，格式为 label;content */ case class SpamFilterParams( trainInput: String = null, modelOutput: String = null ) def main(args: Array[String]): Unit = { Logger.getLogger(\u0026#34;org\u0026#34;).setLevel(Level.WARN) val spark = SparkSession .builder() .appName(this.getClass.getSimpleName) .master(\u0026#34;local[*]\u0026#34;) .getOrCreate() val defaultParam = SpamFilterParams() val parser = new OptionParser[SpamFilterParams](this.getClass.getSimpleName) { head(s\u0026#34;${this.getClass.getSimpleName}: BBS Spam filter.\u0026#34;) opt[String](\u0026#34;train\u0026#34;) .text(\u0026#34;train input\u0026#34;) .action((x, c) =\u0026gt; c.copy(trainInput = x)) .required() opt[String](\u0026#34;output\u0026#34;) .text(\u0026#34;model output\u0026#34;) .action((x, c) =\u0026gt; c.copy(modelOutput = x)) .optional() } parser.parse(args, defaultParam).map { params =\u0026gt; run(spark, params.trainInput, params.modelOutput) sys.exit(0) } getOrElse { sys.exit(1) } } def run(spark: SparkSession, trainInput: String, modelOutput: String) : Unit = { import spark.implicits._ import scala.collection.JavaConversions._ val logger = Logger.getLogger(\u0026#34;app\u0026#34;) logger.warn(\u0026#34;Start:\u0026#34; + System.currentTimeMillis().toString) val filter = new StopRecognition() filter.insertStopWords(\u0026#34; \u0026#34;, \u0026#34;,\u0026#34;) // 读取数据集，使用 ansj 分词，生成 (label, words) 结构的 dataframe val inputData = spark.sparkContext.textFile(trainInput).map{ line =\u0026gt; val splits = line.split(\u0026#34;;\u0026#34;, 2) val content = if(splits(1).length \u0026gt; 0){ ToAnalysis.parse(splits(1)).recognition(filter).getTerms.map(_.getRealName) } else List(\u0026#34;\u0026#34;) (splits(0).toInt, content) }.toDF(\u0026#34;label\u0026#34;, \u0026#34;words\u0026#34;) inputData.show() // 分割训练集与测试集 val Array(train, test) = inputData.randomSplit(Array(0.9, 0.1), seed = 12345).map(_.cache()) // 创建 HashingTF，IDF，NaiveBayes 的 Pipeline 模型 val hashingTF = new HashingTF().setInputCol(\u0026#34;words\u0026#34;).setOutputCol(\u0026#34;rawFeatures\u0026#34;).setNumFeatures(5000) val idf = new IDF().setInputCol(\u0026#34;rawFeatures\u0026#34;).setOutputCol(\u0026#34;features\u0026#34;) val nb = new NaiveBayes() .setModelType(\u0026#34;multinomial\u0026#34;) .setFeaturesCol(\u0026#34;features\u0026#34;) .setLabelCol(\u0026#34;label\u0026#34;) val pipeline = new Pipeline() .setStages(Array(hashingTF, idf, nb)) // 设置参数矩阵，然后使用 TrainValidationSplit 进行模型训练与参数选择 val paramGrid = new ParamGridBuilder() .addGrid(hashingTF.numFeatures, Array(50000, 100000)) .addGrid(nb.smoothing, Array(1.0)) .build() val trainValidationSplit = new TrainValidationSplit() .setEstimator(pipeline) .setEvaluator(new MulticlassClassificationEvaluator) .setEstimatorParamMaps(paramGrid) .setTrainRatio(0.8) val model = trainValidationSplit.fit(train) logger.warn(\u0026#34;Train end:\u0026#34; + System.currentTimeMillis().toString) // 训练出 bestModal，保存到指定路径 if(modelOutput != null) model.bestModel.asInstanceOf[PipelineModel].write.overwrite().save(modelOutput) // 将参数与评估结果打印出来 model.getEstimatorParamMaps.zip(model.validationMetrics).foreach(println) val testResult = model.transform(test) .select(\u0026#34;features\u0026#34;, \u0026#34;label\u0026#34;, \u0026#34;prediction\u0026#34;) testResult.show() val testPredictionAndLabels = testResult.select(\u0026#34;prediction\u0026#34;, \u0026#34;label\u0026#34;).rdd.map{ case Row(prediction: Double, label: Int) =\u0026gt; (prediction, label.toDouble) } val metrics = new MulticlassMetrics(testPredictionAndLabels) println(metrics.confusionMatrix) println(\u0026#34;accuracy:\u0026#34; + metrics.accuracy) println(\u0026#34;weightedPrecision:\u0026#34; + metrics.weightedPrecision) println(\u0026#34;weightedRecall:\u0026#34; + metrics.weightedRecall) logger.warn(\u0026#34;Finish:\u0026#34; + System.currentTimeMillis().toString) spark.stop() } } 打包，然后在 Spark 中训练：\nspark-submit --class com.yplam.SpamFilterTrainer spark-scala-playground.jar --train /home/yplam/spark/work/data/bbs --output /home/yplam/spark/work/model/bbs 结果还算可以，约 93% 的准确率。由于我们之前已经保存好最佳模型，可以编写一个简单的json API接口对外提供服务，而另一个可能更加适合的方式就是将模型移到 PredictionIO 上。\nPredictionIO 简介 PredictionIO 是一个开源的机器学习平台，用于构建、评估与发布机器学习算法引擎。PredictionIO 提供事件服务器( Event Server ) 用于接收与保存数据，用于生成训练数据集；引擎模板( engine template )提供各种不同场景应用所需的机器学习算法模板。模型训练出来后 PredictionIO 提供保存与发布服务，发布后的模型可以通过接收 REST API 提供预测结果。对开发者而言，只需要按照 PredictionIO 提供的 DASE 模式实现数据源与预处理(D)、算法(A)、服务(S)、评估指标(E)。PredictionIO 使开发者专注于模型本身，其他的事情它都已经帮你实现。\n![PredictionIO]({{ site.url }}/assets/2018/predictionio-intro.png \u0026ldquo;PredictionIO\u0026rdquo;)\n上面为 PredictionIO 的单模型引擎框架图。\n事件服务器接收与存储事件数据，数据可以有多种格式，譬如对于文本分类器可以是 { \u0026ldquo;entityId\u0026rdquo; : 123, \u0026ldquo;entityType\u0026rdquo; : \u0026ldquo;content\u0026rdquo;, \u0026ldquo;event\u0026rdquo; : \u0026ldquo;$set\u0026rdquo;, \u0026ldquo;properties\u0026rdquo; : { \u0026ldquo;label\u0026rdquo; : \u0026ldquo;spam\u0026rdquo;, \u0026ldquo;text\u0026rdquo; : \u0026ldquo;哈哈哈\u0026rdquo;} }，对于推荐引擎可以是 { \u0026ldquo;entityId\u0026rdquo; : 1, \u0026ldquo;entityType\u0026rdquo; : \u0026ldquo;user\u0026rdquo;, \u0026ldquo;event\u0026rdquo; : \u0026ldquo;buy\u0026rdquo;, \u0026ldquo;targetEntityType\u0026rdquo;:\u0026ldquo;item\u0026rdquo;, \u0026ldquo;targetEntityId\u0026rdquo;:\u0026ldquo;123\u0026rdquo; } 等。关于事件模型的更多内容可以参考 Events Modeling 。 PredictionIO 提供 REST 接口用于接收事件 多种存储后端，包括mysql，pgsql 跟 hbase。\nPredictionIO 实现 由于 PredictionIO 社区提供了大量的引擎模板，因此实现自己模型的最简单方式就是在官方模板的基础上进行修改，譬如 Text Classification中就包含基于贝叶斯算法的文本分类器实现，得益于 PredictionIO 的 DASE 模型，我们只需要拷贝此项目，根据项目实际情况做小修改，然后加入 ansj 分词功能，完成。\n针对 DataSource，我们需要根据我们模型实际数据结构，设定 entityType，eventNames，以及对 Observation 结构的处理。\n针对 Preparator，我们用 ansj 替换原有的分词方式，同时限制了内容长度。\n相关代码地址：https://github.com/yplam/predictionio-spam-detection-cn\n后记：通过分析“漏网之鱼”的内容，发现已经有针对贝叶斯算法的攻击，也就是在长篇内容中夹入少量垃圾信息，通过只截取标题+内容头尾各500个字的方式，可以有一定的效果提升。\n","permalink":"https://yplam.com/posts/machinelearning/predictionio/","summary":"\u003cp\u003e关注 Apache PredictionIO 已有一段时间，最近需要做一个过滤论坛广告贴的功能，调研了一番市面上提供文本检测的API服务，发现靠谱的公司都比较贵，并且准确率不高（一个可能性是他们使用的训练数据集是互联网上的通用信息，而我们是一个垂直行业论坛，攻击来源也可能是固定的那么若干个），于是尝试自己实现个文本分类器来过滤广告。\u003c/p\u003e","title":"PredictionIO实现论坛广告贴过滤"},{"content":"Symfony 4 如期在11月的最后一天发布，相比与 Symfony 2 到 Symfony 3 的升级，Symfony 4 的变化似乎更大，特别是由于加入 Flex 以及 Service Autowired，开发方式都会发生比较大的变化。\nSymfony 4 主要特性：\n基于 Symfony Flex 的包自动化安装。 Service 的 Auto-registered 与 autowired，根据代码自动生成，无需配置。 Symfony 4 成了一个开箱即用的微框架，比 Symfony 3 小 70%。 性能优化 MakerBundle、Webpack 等新特性 安装：\ncomposer create-project symfony/skeleton my_project 安装后的第一感觉变化还是蛮大，web 变到 public，里面就只有一个 index.php 文件，通过 $_SERVER[\u0026lsquo;APP_ENV\u0026rsquo;] 或者 .env 文件来加载环境参数。\n目录结构也有很大的变化，而且都变得很精简。\n但这个精简版的 Symfony 4 功能还有点弱，至少不支持常用的 annotations、twig 以及 profiler，不过得益于Flex的存在，安装配置也简单：\ncomposer require annotations composer require twig composer require --dev profiler Flex 会根据需要将默认配置文件下到本地。\n模板\ntwig 变化不大，只是模板位置变到了项目根目录下的templates文件夹\n前端\n虽然 Assetic 还可以用，但官方推荐使用 Webpack Encore，带来的好处就是前端开发更加专业，并且asset版本控制之类的变得更加方便。\ndeployer\n由于 Symfony 4 使用 env 来设定运行环境参数，发布方式变化较大，之前使用的 php deployer 工具需要做较多修改。\n","permalink":"https://yplam.com/posts/symfony/hello-symfony-4/","summary":"\u003cp\u003eSymfony 4 如期在11月的最后一天发布，相比与 Symfony 2 到 Symfony 3 的升级，Symfony 4 的变化似乎更大，特别是由于加入 Flex 以及 Service Autowired，开发方式都会发生比较大的变化。\u003c/p\u003e","title":"Symfony 4 尝鲜"},{"content":"跟风关注机器学习已有一段时间，最近需要做一个图像识别的项目，刚好 Google 开源了 Tensorflow Object Detection API ， 于是在此基础上做了一次尝试。本笔记从一名程序员的角度记录一次基于 Tensorflow Object Detection API 的图像物体识别项目过程，项目使用 Google Cloud Machine Learning 进行模型训练， 使用阿里云 GPU 服务器进行模型测试评估。\n**目的：**在一批图片中找出包含物体A的图片，并且标出图片中各物体A的位置。\n**环境：**Ubuntu 16.04，python 2.7，virtualenv, tensorflow 1.3, tensorflow-models@d43c736eae267f98061b2cc9aa4f1936e10e2c4e (注：tensorflow models在快速变化中，并且无release版本，如果您按照本文的方式测试出错的话可以尝试checkout这个commit，然后重新生成protobuf)\n过程：\n安装 Tensorflow 与 Tensorflow models 获取与标注图片 生成训练集与测试集 配置、提交 Google Cloud 训练 使用阿里云 GPU 服务器进行测试 安装 CPU 环境下的 Tensorflow 安装非常简单，可以参考官网安装文档，其中 python 版本建议选择 2.7，因为现时（2017年10月） Google Cloud Machine Learning 的命令行对 python3 支持有问题。\nGPU 下的安装稍微复杂，主要是需要解决 NVIDIA 显卡驱动问题，可以参考之前的文章 http://yplam.com/machinelearning/2016/12/12/aws-cuda-tensorflow.html。需要注意的是1.3官方编译版本的Tensorflow使用的是8.0版本的cuda以及6.0版本的cudnn，可以在发布说明页面搜\u0026quot;CUDA\u0026quot;找到相关说明。\n如果你需要在阿里云的GPU服务器上使用，可以使用这个Ansible脚本进行快速初始化。\n简要步骤如下：(详细参考https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md)\n# For CPU pip install tensorflow # For GPU pip install tensorflow-gpu apt-get install protobuf-compiler pip install pillow pip install lxml pip install jupyter pip install matplotlib 编译Protobuf\ncd tensorflow/models/research/ protoc object_detection/protos/*.proto --python_out=. 编辑~/.bashrc，将 Object Detection 库加入python（注：请根据你的实际路径设置）\n# From tensorflow/models/research/ export PYTHONPATH=$PYTHONPATH:tensorflow/models/research:tensorflow/models/research/slim 安装完成后可以跑一下下面的 jupyter notebook 测试 research/object_detection/object_detection_tutorial.ipynb\n数据获取与标注 在进行下面步骤前可以先看看官方的这个文档Quick Start: Distributed Training on the Oxford-IIIT Pets Dataset on Google Cloud，下面的内容均是基于官方文档并且根据本项目情况进行修改。\n所谓数据就是用于训练与测试的预标注图片。图片可以是预先准备好的，或者是通过 Scrapy 等爬虫工具获取。图片可能大小不一，下载下来后可以通过下面命令缩小到1000px宽度：\nconvert \u0026#39;*.jpg[1000x]\u0026#39; -set filename:base \u0026#34;%[base]\u0026#34; \u0026#34;1000/%[filename:base].jpg\u0026#34; 需要注意的是过小的图片可能无法在某些模型中使用。\n然后就到了整个过程中最耗时最无聊的步骤：数据标注（所谓人工智能真的有一大堆人工\u0026hellip;）。\n在此使用 labelimg 进行图片标注，安装与使用方法请参考github项目页面。分享一个技巧就是熟记快捷键，如果有多个类别的话可以设定默认label，并且每次只标注一个类别。\n图片标注后会在目标目录生成一个同名的 xml 文件。\n生成训练集与测试集 Tensorflow Object Detection 使用的是 TFRecord 格式的数据，所以需要将上面标注好的图片与xml文件根据模型的数据格式需要打包到一个 TFRecord 文件中。\n首先，我们需要一个 label.pbtxt 文件，标识分类 id 以及 label 的对应关系，如：\nitem { id: 1 name: \u0026#39;toy\u0026#39; } 然后参考 research/object_detection/create_pet_tf_record.py ，编写自己的 python 脚本生成你的 训练集与测试集 record 文件。\n配置与提交到 Google Cloud 进行模型训练 20171102更新： 突然发现阿里云的GPU竞价实例是个性价比不错的选择，可能是现在用GPU服务器的人不多，竞价实例可以以N分之一的价格拿到，值得一试，还免去科学上网的麻烦。\nTensorflow models 项目页面提供多中模型的配置范例，在此我们使用预训练的 faster_rcnn_resnet101 模型。\n由于需要使用 Google Cloud Machine Learning 服务进行模型训练，所以需要先安装 Google Cloud 相关的客户端，开通 Google Cloud 账号，并且启用 Machine Learning 与 Cloud Storage。可参考下面链接：\nCreate a GCP project. Install the Google Cloud SDK. Enable the ML Engine APIs. Set up a Google Cloud Storage (GCS) bucket. 如果你使用的是ubuntu系统的话这个过程应该还算简单。当然，这还需要你具备“科学上网”技能，以及proxychains等工具的使用。\n将我们前面生成的record文件以及label.pbtxt文件拷贝到Google Cloud Storage，如（请根据实际情况修改）：\n# From tensorflow/models/research/ gsutil cp pet_train.record gs://${YOUR_GCS_BUCKET}/data/pet_train.record gsutil cp pet_val.record gs://${YOUR_GCS_BUCKET}/data/pet_val.record gsutil cp object_detection/data/label.pbtxt gs://${YOUR_GCS_BUCKET}/data/label.pbtxt 下载 COCO-pretrained Faster R-CNN with Resnet-101 模型，解压到 Google Cloud，解压的文件本地也要留一份，后面会用到。\nwget http://storage.googleapis.com/download.tensorflow.org/models/object_detection/faster_rcnn_resnet101_coco_11_06_2017.tar.gz tar -xvf faster_rcnn_resnet101_coco_11_06_2017.tar.gz gsutil cp faster_rcnn_resnet101_coco_11_06_2017/model.ckpt.* gs://${YOUR_GCS_BUCKET}/data/ 参考 faster_rcnn_resnet101_pets.config ，编写我们的config文件，主要是修改 num_classes，fine_tune_checkpoint，input_path，label_map_path，可以先使用本地路径，而不是官方教程中的 \u0026ldquo;gs://***\u0026rdquo; 路径，方便本地调试好再发上去正式训练。因为发到 Google Cloud 训练会有个初始化等待过程，并且由于调用的GPU数量较多，如果因为配置文件不符而导致需要不断修改调试，在这过程中可能会浪费比较多的时间跟费用。\n现在，你本地会有以下文件(名字可能不一样)：\n- faster_rcnn_resnet101_pets.config - model.ckpt.index - model.ckpt.meta - model.ckpt.data-00000-of-00001 - label.pbtxt - pet_train.record - pet_val.record 先在本地测试一下是否能正常训练，开始前尽量把不必要的其他应用关掉，因为将耗费 N 多 cpu 与内存资源。\npython object_detection/train.py --train_dir=tmp --pipeline_config_path=${YOUR_CONFIG_FILE}.config 如果能正常进入训练进程，则说明各种配置正常，那么可以将 faster_rcnn_resnet101_pets.config 中的文件路径设为 gs:// 上面路径。然后提交训练（提交前先将本地faster_rcnn_resnet101_pets.config拷贝到gs://${YOUR_GCS_BUCKET}/data）\n# From tensorflow/models/research/ python setup.py sdist (cd slim \u0026amp;\u0026amp; python setup.py sdist) # From tensorflow/models/research/ gcloud ml-engine jobs submit training `whoami`_object_detection_`date +%s` \\ --job-dir=gs://${YOUR_GCS_BUCKET}/train \\ --packages dist/object_detection-0.1.tar.gz,slim/dist/slim-0.1.tar.gz \\ --module-name object_detection.train \\ --region us-central1 \\ --config object_detection/samples/cloud/cloud.yml \\ -- \\ --train_dir=gs://${YOUR_GCS_BUCKET}/train \\ --pipeline_config_path=gs://${YOUR_GCS_BUCKET}/data/faster_rcnn_resnet101_pets.config 然后可以登录 Google Cloud Console 查看训练进度，需要注意的是费用大概是 $10 一小时，所以如果看到loss降低到一个合适的程度时可以提前停止训练。\n训练后的模型会存储在配置的 \u0026ndash;train_dir 中，包含类似下面三个文件：\nmodel.ckpt-${CHECKPOINT_NUMBER}.data-00000-of-00001 model.ckpt-${CHECKPOINT_NUMBER}.index model.ckpt-${CHECKPOINT_NUMBER}.meta 下载下来后可以通过下面命令导出：\npython object_detection/export_inference_graph.py \\ --input_type image_tensor \\ --pipeline_config_path object_detection/samples/configs/faster_rcnn_resnet101_pets.config \\ --trained_checkpoint_prefix model.ckpt-${CHECKPOINT_NUMBER} \\ --output_directory output_inference_graph.pb output_inference_graph.pb 文件就是导出后的模型文件，可以留作后续使用。\n在阿里云上运行训练后的模型 Resnet 101 模型在本地 i5 台式机上跑预测一次时间大概是30秒，而在阿里云最低配的 M40 GPU AWS 上运行一次只需要不到1秒，所以对于大批量的预测任务，配置一台阿里云的GPU服务器来跑是一个不错的选择。现时阿里云 M40 服务器价格为 ￥10 一小时，相对于动辄过万的GPU台式机，还算是个相对便宜的选择(ps: 如果只是用来测试，可以购买阿里云的竞价实例，可以省更多)。\n使用这个Ansible脚本进行快速初始化Tensorflow环境，本脚本在 阿里云M40 GPU AWS、UBUNTU 16.04、cuda 8、tensorflow 1.3 上测试通过。\n参考资料：\nTensorflow Object Detection API Building a Toy Detector with Tensorflow Object Detection API A Brief History of CNNs in Image Segmentation: From R-CNN to Mask R-CNN ","permalink":"https://yplam.com/posts/machinelearning/tensorflow-object-detection-note/","summary":"\u003cp\u003e跟风关注机器学习已有一段时间，最近需要做一个图像识别的项目，刚好 Google 开源了 \u003ca href=\"https://github.com/tensorflow/models/tree/master/research/object_detection\"\u003eTensorflow Object Detection API\u003c/a\u003e ，\n于是在此基础上做了一次尝试。本笔记从一名程序员的角度记录一次基于 Tensorflow Object Detection API 的图像物体识别项目过程，项目使用 Google Cloud Machine Learning 进行模型训练，\n使用阿里云 GPU 服务器进行模型测试评估。\u003c/p\u003e","title":"Tensorflow Object Detection API 入门笔记 - 基于 Google Cloud 与 阿里云"},{"content":"Netflix Prize 是2006年Netflix启动的一个机器学习和数据挖掘比赛，旨在解决电影评分预测问题。\n训练集包含 480,189 名用户对 17,770 部电影的 100,480,507 份评分，评分为 1-5 分。\nqualifying.txt 中包含需要检验的数据，参赛者根据检验集提供的电影id跟用户id，时间进行评分预测，然后提交结果。（不过因为没有关于结果评分的数据，所以这个文件貌似用处不大）\nprobe.txt 相当于测试集，与 qualifying.txt 的区别在于你可以在训练集中查到对应的评分数据。\n结果的评估使用 RMSE。\n数据集下载：\n百度网盘 Netflix Prize data 论文:\nYehuda Koren,The BellKor Solution to the Netflix Grand Prize A. Töscher, M. Jahrer, R. Bell,The BigChaos Solution to the Netflix Grand Prize M. Piotte, M. Chabbert,The Pragmatic Theory solution to the Netflix Grand Prize 相关文章\nNetflix Prize and SVD 这篇文章对获奖算法做了比较详细的讲解 Predicting movie ratings and recommender systems一份关于Netflix Prize的195页专刊 关于Netflix Prize的总结(翻译) Winning the Netflix Prize: A Summary Netflix推荐系统：从评分预测到消费者法则 《推荐系统 技术、评估及高效算法》第5章 协同过滤算法的高级课题 参考资料\n【Netflix】Netflix Prize 竞赛数据集 Netflix推荐算法 关于Netflix的一些报道：\nNetflix：从传统DVD租赁向流媒体华丽转身 Netflix 是如何用大數據捧紅「紙牌屋」的 ","permalink":"https://yplam.com/posts/machinelearning/netflix-prize/","summary":"\u003cp\u003eNetflix Prize 是2006年Netflix启动的一个机器学习和数据挖掘比赛，旨在解决电影评分预测问题。\u003c/p\u003e","title":"Netflix Prize 相关资料"},{"content":"最近看了一本挺不错的新书：《 Hands-On Machine Learning with Scikit-Learn and TensorFlow 》，在此分享一下。\n这本书分两部分：前半部分讲解了机器学习的一些基础知识，以及在 sklearn 上的实现；后半部分先介绍 Tensorflow，然后是深度学习的内容，最后就是在TensorFlow上的实现。 书上关于数学的内容都写得比较简略，所以需要边看边翻相关基础知识。而后半部分关于 TensorFlow 的内容就比较深入，介绍了不少作者在工程实践上的技巧。\n个人认为第十一章《 Training Deep Neural Nets 》算是本书精华，譬如关于梯度消失/爆炸问题：\nBackPropagation 算法中，越低层的学习速度越慢，甚至出现梯度过小导致权重值一直保持不变的情况 然后 2010 年，avier Glorot 与 Yoshua Bengio 发表的paper “Understanding the Difficulty of Training Deep Feedforward Neural Networks” 中提出了一些猜想的方式，结合 logistic sigmoid 激活函数与均值为 0，标准差为 1 的正态分布来对权重进行初始化；然而效果并不好，因为\u0026hellip; Xavier 与 He Initialization 提出了一个新的初始化方法，根据输入输出神经元数量不同选择不同的标准差，在 Tensorflow 中可以用这个方法实现\u0026hellip; Glorot 与 Bengio 还提出了 ReLU 激活函数，但是有 dying ReLU 问题，可以用 leaky ReLU，后来 15 年又有人提出 ELU，在 Tensorflow 中可以这样使用\u0026hellip; 用 Batch Normalization 来更进一步的解决这个问题，在 Tensorflow 中这样实现\u0026hellip; 还有关于模型训练问题，譬如在TensorFlow中怎么加载预训练的模型，冻结低层参数来训练，缓存其输出；各种优化算法，各种防 Overfitting 的方法。\n总之，跟随作者的这种方式，会对 DNN 的一些概念有更清晰的了解（至少对我这个门外汉而言是这样）。\n下面截取附录中关于机器学习项目的一般步骤。\n主要分为 8 步：\nFrame the problem and look at the big picture. Get the data. Explore the data to gain insights. Prepare the data to better expose the underlying data patterns to Machine Learning algorithms. Explore many different models and short-list the best ones. Fine-tune your models and combine them into a great solution. Present your solution. Launch, monitor, and maintain your system. 书中对每一个步骤都有解释，推荐到 O\u0026rsquo;Reilly 上购买一份电子版（可以Google一下，有50%的优惠券）。\n目录：（点击查看原图）\n[]({{ site.url }}/assets/2017/hands-on-machine-learning.png)\n","permalink":"https://yplam.com/posts/machinelearning/hands-on-machine-learning-scikit-learn--tensorflow/","summary":"\u003cp\u003e最近看了一本挺不错的新书：\u003ca href=\"http://shop.oreilly.com/product/0636920052289.do\"\u003e《 Hands-On Machine Learning with Scikit-Learn and TensorFlow 》\u003c/a\u003e，在此分享一下。\u003c/p\u003e","title":"《 Hands-On Machine Learning with Scikit-Learn and TensorFlow 》笔记"},{"content":"最近在琢磨能不能用 CNN 来训练一个模型，用于控制一个模型小车，实现简单的循迹或者所谓的自动驾驶。于是拿出布灰已久的 Edison + 两轮平衡车 + 罗技摄像头，计划将这几样组装起来，上面运行 ROS 作为我的“机器人”平台，然后在笔记本上运行 master 做运算与控制。本笔记记录 ROS 在 Edison 上安装与运行 usb_cam 获取图像传输到主机的过程。\n主要还是按照 Installing ROS Indigo on Intel Edison, Installing ROS Indigo on Raspberry Pi 这两个文档进行安装，但过程中会遇到不少问题，并且由于 Edison 用户可能比较少，大多都需要找相关资料来解决。\n本笔记假设读者已经拥有基础 Linux 操作技能，某些基础操作不会细说。\n安装 ubilinux 参考下面文档：\nhttps://learn.sparkfun.com/tutorials/loading-debian-ubilinux-on-the-edison\n将 ubilinux 安装到 sd 卡启动 因为 Edison 自带的 emmc 只有 4G，安装各种包之后空间只能勉强够用，因此建议使用 8G 以上的 sd 卡安装系统，安装在sd卡上还有一个好处就是可以简单的将系统备份下来。可参考下面文档：\nhttps://github.com/sarweshkumar47/Boot-Intel-Edison-from-SDCard-with-Debian-Ubilinux\n系统初始化 配置 wifi：\nwpa_passphrase wifiid wifi_password 然后修改 /etc/network/interfaces，禁用 usb 网卡，使用 wlan0，将 wpa-ssid 跟 wpa-psk 配置上。\n初始化的配置，顺便把 locale 配置一下\napt-get update dpkg-reconfigure locale 安装 boost 1.5.3 库 Debian Wheezy 自带的 boost 库版本为 1.4.9，如果按此版本编译安装 ROS Indigo 的话会报以下错误：\nerror: macro \u0026#34;BOOST_SCOPE_EXIT\u0026#34; passed 2 arguments, but takes just 1 查看相关文档得知，Indigo 对应的 boost 版本为 1.5.3，可以按 Getting Started on Unix Variants 编译安装，也可以下载我编译好的 deb 包进行安装（编译一次需要 N 个小时）。当然，如果你有兴趣的话也可以尝试编译自己的deb包，参考 https://github.com/ulikoehler/deb-buildscripts/blob/master/deb-boost.sh\n下载 deb 包： [boost-all_1.53.0-1_i386.deb]({{ site.url }}/assets/2017/boost-all_1.53.0-1_i386.deb) [boost-all-dev_1.53.0-1_i386.deb]({{ site.url }}/assets/2017/boost-all-dev_1.53.0-1_i386.deb)\n安装：\napt-get install libicu48 dpkg -i boost-all_1.53.0-1_i386.deb boost-all-dev_1.53.0-1_i386.deb 安装 opencv 库 编译安装：\n下载opencv 2.4.9 代码\n环境准备\napt-get install build-essential apt-get install cmake git libgtk2.0-dev pkg-config libavcodec-dev libavformat-dev libswscale-dev ffmpeg apt-get install python-dev python-numpy 根据这里对代码进行修改 https://github.com/NextThingCo/buildroot/blob/master/package/opencv/0002-superres-Fix-return-type-value-VideoFrameSource_GPU.patch\n263 行\n- return new VideoFrameSource(fileName); + return new VideoFrameSource_GPU(fileName); 在 CMakeLists.txt 中 set(OPENCV_VCSVERSION \u0026ldquo;2.4.9\u0026rdquo;)\nmkdir release cd release cmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local .. 编辑 CMakeCache.txt CPACK_BINARY_DEB:BOOL=ON make make install 上面这步可能需要运行 N 个小时\nmake package 可能会出错\nCPackDeb: dpkg-shlibdeps: dpkg-shlibdeps: need at least one executable 按照这里的 patch 对 cmake 进行修正：https://public.kitware.com/Bug/view.php?id=13488\n附预编译的 deb 包： [OpenCV-2.4.9-i686-libs.deb]({{ site.url }}/assets/2017/OpenCV-2.4.9-i686-libs.deb) [OpenCV-2.4.9-i686-dev.deb]({{ site.url }}/assets/2017/OpenCV-2.4.9-i686-dev.deb) [OpenCV-2.4.9-i686-python.deb]({{ site.url }}/assets/2017/OpenCV-2.4.9-i686-python.deb)\n编辑安装 ROS 可以参考 Installing ROS Indigo on Intel Edison, Installing ROS Indigo on Raspberry Pi 进行安装，但有两点区别：\n1.2 console_bridge:\n在运行下面命令后\nsudo checkinstall make install 输入 2 并且将包名改为 \u0026rsquo;libconsole_bridge\u0026rsquo; .\n3.2.2 Resolving Dependencies with rosdep\n运行 rosdep install 的时候去掉 -y 参数，并且跳过 apt-get install libboost-all-dev.\nerror while loading shared libraries: libconsole_bridge.so.0.3: cannot open shared object file: No such file or directory\n如果你遇到这个错误，可以通过下面方式处理\ncd /opt/ros/indigo/lib sudo ln -s /usr/local/lib/i386-linux-gnu/libconsole_bridge.so.0.3 libconsole_bridge.so.0.3 编译 usb_cam usb_cam 的编译跟前面 ros_comm 类似：\nmkdir catkin_ws cd catkin_ws mkdir src rosinstall_generator usb_cam image_transport_plugins --rosdistro indigo --deps --wet-only --exclude roslisp --tar \u0026gt; indigo-usb_cam.rosinstall wstool init src indigo-usb_cam.rosinstall rosdep install --from-paths src --ignore-src --rosdistro indigo -r --os=debian:wheezy #跳过opencv boost相关的包 source /opt/ros/indigo/setup.bash catkin_make 你也可以在之前的工作区上操作，因为新工作区会导致某些包又要重新编译，但好处就是以后 make 跑的时间会短一点。\n运行 usb_cam 将 Edison 图像传输到电脑 开始运行之前请确认主机跟从机都可以相互ping通，并且可以ping通自己。\n现在主机运行：\nroscore 主机上开多一个终端，运行：\nrosrun rviz rviz Edison上编辑 launch 文件，运行\nsource devel/setup.bash roscd usb_cam vim launch/usb_cam.launch roslaunch usb_cam.launch usb_cam.launch 的内容，假设你主机的名字为 lam\n\u0026lt;launch\u0026gt; \u0026lt;env name=\u0026#34;ROS_MASTER_URI\u0026#34; value=\u0026#34;http://lam.local:11311\u0026#34;/\u0026gt; \u0026lt;node name=\u0026#34;usb_cam\u0026#34; pkg=\u0026#34;usb_cam\u0026#34; type=\u0026#34;usb_cam_node\u0026#34; output=\u0026#34;screen\u0026#34; \u0026gt; \u0026lt;param name=\u0026#34;video_device\u0026#34; value=\u0026#34;/dev/video0\u0026#34; /\u0026gt; \u0026lt;param name=\u0026#34;image_width\u0026#34; value=\u0026#34;640\u0026#34; /\u0026gt; \u0026lt;param name=\u0026#34;image_height\u0026#34; value=\u0026#34;480\u0026#34; /\u0026gt; \u0026lt;param name=\u0026#34;pixel_format\u0026#34; value=\u0026#34;yuyv\u0026#34; /\u0026gt; \u0026lt;param name=\u0026#34;camera_frame_id\u0026#34; value=\u0026#34;usb_cam\u0026#34; /\u0026gt; \u0026lt;param name=\u0026#34;io_method\u0026#34; value=\u0026#34;mmap\u0026#34;/\u0026gt; \u0026lt;/node\u0026gt; \u0026lt;/launch\u0026gt; 在 rviz 窗口上添加一个 Image，topic 为 /usb_cam/image_raw ，使用 compressed 传输。\nDone.\nUpdate 2017-04-22:\n最终成果，由于加上电池后二轮平衡车难以平衡起来，干脆在万能的淘宝加工了几张有机玻璃板做成三轮车。Edison用串口跟单片机通讯，控制前进后退转弯。\n发现 ROS 的确方便，除了跟底层通讯的模块用 C 写之外，其他用 python 写起来会感觉好享受。\n![Edison ROS]({{ site.url }}/assets/2017/20170422ros.jpg \u0026ldquo;Edison ROS\u0026rdquo;)\n","permalink":"https://yplam.com/posts/embedded/edison-ros-indigo-step-by-step/","summary":"\u003cp\u003e最近在琢磨能不能用 CNN 来训练一个模型，用于控制一个模型小车，实现简单的循迹或者所谓的自动驾驶。于是拿出布灰已久的 Edison + 两轮平衡车 + 罗技摄像头，计划将这几样组装起来，上面运行 ROS 作为我的“机器人”平台，然后在笔记本上运行 master 做运算与控制。本笔记记录 ROS 在 Edison 上安装与运行 usb_cam 获取图像传输到主机的过程。\u003c/p\u003e","title":"一步步搭建 Edison ROS Indigo 环境"},{"content":"This tutorial shows you how to install ROS Indigo on Edison Ubilinux from source.\nYou can mainly follow these instructions Installing ROS Indigo on Intel Edison, Installing ROS Indigo on Raspberry Pi except the following differences:\ncompile and install boost 1.5.3\nFollow this instruction Getting Started on Unix Variants to install boost 1.5.3 because the default boost 1.4.9 on wheezy does not works with ROS Indigo.\nWithout installing boost 1.5.3, you may get the error message like this:\nerror: macro \u0026#34;BOOST_SCOPE_EXIT\u0026#34; passed 2 arguments, but takes just 1 1.2 console_bridge:\nIn :\nsudo checkinstall make install Enter 2 and rename the package to \u0026rsquo;libconsole_bridge\u0026rsquo; .\n3.2.2 Resolving Dependencies with rosdep\nRun rosdep install without the -y argument and skip apt-get install libboost-all-dev lib.\nerror while loading shared libraries: libconsole_bridge.so.0.3: cannot open shared object file: No such file or directory\nAfter the whole install, if you got this error while starting roscore, you can fix it like this:\ncd /opt/ros/indigo/lib sudo ln -s /usr/local/lib/i386-linux-gnu/libconsole_bridge.so.0.3 libconsole_bridge.so.0.3 ","permalink":"https://yplam.com/posts/embedded/edison-ros-install/","summary":"\u003cp\u003eThis tutorial shows you how to install ROS Indigo on Edison Ubilinux from source.\u003c/p\u003e","title":"Install ROS Indigo on Edison Ubilinux"},{"content":"注：本文为 Predicting customer behavior: How we use machine learning to identify paying customers before they subscribe 的简单翻译版本，详细内容请阅读原文。\n本案例为 strong.io 公司的一位创业公司客户，该客户开发了一个类SaaS软件，但在经过多年的稳固发展后，他们的每月收入增长却开始变得很缓慢。他们曾经尝试改善他们的产品，但效果可能不好，因此现在将重点放在客户获取上面。\n该产品现在每月有超过3000个试用下载，但只有大约3%的用户转化为付费版。\n为了弄清是什么原因，他们开始做一个试验：雇佣一些人员，用整整一个月时间，打电话或者email给那些下载了试用版的用户，问问他们对产品的看法，并且帮助他们解决问题。这样一个月过去后，他们的转化率从3.7%上升到5.4%；同时，他们知道了其中很多用户根本对购买付费版没兴趣，他们仅仅是想使用一下免费版里面带的一些工具\u0026ndash;他们并不是目标客户！\n他们希望 strong.io 通过技术手段将潜在的付费用户区分出来，然后让客户支持团队将精力集中在该潜在客户上。\n解决方案 1、记录完整的用户行为信息，每一个用户都会记录维度为70的数据。\n2、测试各种机器学习方法。使用 AUC (Area Under the Curve) 方法进行评价；使用一年的数据进行模型训练，使用随后半年的数据进行测试； 其中 Logistic 模型最好可以达到 78% AUC，随机森林模型可以达到 80% AUC，梯度提升模型可以达到 93% AUC。最后，选用了RNN， 可以达到 95% AUC。\n3、生成每个试用用户的转化概率，集成到CRM中\n4、最终，该公司的转化率上升并且稳定在7.4%.\n![用户行为预测]({{ site.url }}/assets/2017/strongio.png \u0026ldquo;用户行为预测\u0026rdquo;)\n","permalink":"https://yplam.com/posts/machinelearning/machine-learning-predicting-customer-behavior/","summary":"\u003cp\u003e\u003cstrong\u003e注\u003c/strong\u003e：本文为 \u003ca href=\"http://www.strong.io/blog/predicting-customer-behavior-machine-learning-to-identify-paying-customers\"\u003ePredicting customer behavior: How we use machine learning to identify paying customers before they subscribe\u003c/a\u003e 的简单翻译版本，详细内容请阅读原文。\u003c/p\u003e\n\u003cp\u003e本案例为 strong.io 公司的一位创业公司客户，该客户开发了一个类SaaS软件，但在经过多年的稳固发展后，他们的每月收入增长却开始变得很缓慢。他们曾经尝试改善他们的产品，但效果可能不好，因此现在将重点放在客户获取上面。\u003c/p\u003e","title":"[翻译]用户行为预测：使用机器学习技术预测付费用户"},{"content":"用户画像是根据用户社会属性、生活习惯和消费行为等信息而抽象出的一个标签化的用户模型。构建用户画像的核心工作即是给用户贴“标签”，而标签是通过对用户信息分析而来的高度精炼的特征标识。\n用户画像要建立在真实的数据之上 当有多个用户画像的时候,需要考虑用户画像的优先级 用户画像是处在不断修正中的 用户画像的作用 精准营销，分析产品潜在用户，针对特定群体利用短信邮件等方式进行营销； 用户统计，比如中国大学购买书籍人数 TOP10，全国分城市奶爸指数； 数据挖掘，构建智能推荐系统，利用关联规则计算，喜欢红酒的人通常喜欢什么运动品牌，利用聚类算法分析，喜欢红酒的人年龄段分布情况； 进行效果评估，完善产品运营，提升服务质量，其实这也就相当于市场调研、用户调研，迅速下定位服务群体，提供高水平的服务； 对服务或产品进行私人定制，即个性化的服务某类群体甚至每一位用户（个人认为这是目前的发展趋势，未来的消费主流）。 业务经营分析以及竞争分析，影响企业发展战略 用户画像构建流程 ![user profiling]({{ site.url }}/assets/2017/userprofiling.png \u0026ldquo;用户画像\u0026rdquo;)\n1、基础数据收集\n静态信息数据\n人口属性：性别、年龄、地域、职业、学历、月收入、婚姻状况等 商业属性：消费等级、消费周期等 动态信息数据\n网络行为数据：活跃人数、页面浏览量、访问时长、激活率、外部触点、社交数据等 服务内行为数据：浏览路径、页面停留时间、访问深度、唯一页面浏览次数等 用户内容便好数据：浏览／收藏内容、评论内容、互动内容、生活形态偏好、品牌偏好等 用户交易数据（交易类服务）：贡献率、客单价、连带率、回头率、流失率等 2、行为建模\n该阶段是对上阶段收集到数据的处理，进行行为建模，以抽象出用户的标签，这个阶段注重的应是大概率事件，通过数学算法模型尽可能地排除用户的偶然行为。在这个阶段，需要用到很多模型来给用户贴标签。\n用户汽车模型: 根据用户对“汽车”话题的关注或购买相关产品的情况来判断用户是否有车、是否准备买车 用户活跃度模型: 通过判断＋聚类算法判断用户的活跃度 身高体型模型: 根据用户购买服装鞋帽等用品判断 用户价值模型: 判断用户对于网站的价值，对于提高用户留存率非常有用（电商网站一般使用RFM 实现） 促销敏感度模型: 根据订单中优惠券与代金券占比，定义客户对促销信息的敏感度 3、构建画像\n基本属性 购买能力 行为特征 社交网络 心理特征 兴趣爱好 用户画像构建的技术 todo\n用户画像资料汇总 User Profiling Trends, Techniques and Applications Learning User Profiles from Tagging Data and Leveraging them for Personal(ized) Information Access Harvesting Multiple Sources for User Profile Learning: a Big Data Study 慕课网：电商大数据应用之用户画像 参考资料 知乎：什么是用户画像呢？一般用户画像的作用是什么？ 慕课网：电商大数据应用之用户画像 ","permalink":"https://yplam.com/posts/machinelearning/user-profile-learning-notes/","summary":"\u003cp\u003e用户画像是根据用户社会属性、生活习惯和消费行为等信息而抽象出的一个标签化的用户模型。构建用户画像的核心工作即是给用户贴“标签”，而标签是通过对用户信息分析而来的高度精炼的特征标识。\u003c/p\u003e","title":"用户画像笔记"},{"content":"最近迷上了机器学习，花了不少时间学习相关的基础内容；虽然数学跟不上，也不妨碍跟风玩玩各位大牛的开源成果。 本文记录了购买AWS GPU服务器，安装cuda、 TensorFlow，运行 Neural Style 测试的过程。\nupdate: 2018-05-17，本文内容可能已不适合，请参考末尾命令行日志做修改。\n购买AWS EC2 p2.xlarge 购买p2.xlarge实例（1 NVIDIA K80 GPU， 4核CPU，61G内存，$0.9/小时），空间需要10G以上，建议20G，因为nvidia与cuda包的安装都需要不少的空间（按下面的安装方法，使用的空间接近10G）。 选择 aws 提供的 ubuntu 16.04，跟需求配置安装。\n安装后建议设置一下locale，不然下面的步骤中可能会报错。\nexport LC_ALL=\u0026#34;en_US.UTF-8\u0026#34; export LC_CTYPE=\u0026#34;en_US.UTF-8\u0026#34; sudo dpkg-reconfigure locales 安装Nvidia显卡驱动 首先，检查一下服务器中是否真的存在Nvidia显卡：\n$ lspci | grep -i nvidia 直接使用ubuntu官方提供的Nvidia显卡驱动，目前版本是367：\napt-cache search nvidia sudo apt-get install nvidia-367 nvidia-modprobe 检测驱动是否正常安装：\nnvidia-smi 正常情况下会输出：\n+-----------------------------------------------------------------------------+ | NVIDIA-SMI 367.57 Driver Version: 367.57 | |-------------------------------+----------------------+----------------------+ | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | |===============================+======================+======================| | 0 Tesla K80 Off | 0000:00:1E.0 Off | 0 | | N/A 29C P0 74W / 149W | 0MiB / 11439MiB | 99% Default | +-------------------------------+----------------------+----------------------+ +-----------------------------------------------------------------------------+ | Processes: GPU Memory | | GPU PID Type Process name Usage | |=============================================================================| | No running processes found | +-----------------------------------------------------------------------------+ 安装cuda cuDNN 到官网下载最新版本的cuda，以及对应的cudnn，安装：\nwget http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/cuda-repo-ubuntu1604_8.0.44-1_amd64.deb sudo dpkg -i cuda-repo-ubuntu1604_8.0.44-1_amd64.deb sudo apt-get update sudo apt-get install cuda 下载与安装cuDNN（需要到官方注册登录后才能得到下载地址）\ntar xvzf cudnn-8.0-linux-x64-v5.1.tgz sudo cp -P cuda/include/cudnn.h /usr/local/cuda/include sudo cp -P cuda/lib64/libcudnn* /usr/local/cuda/lib64 sudo chmod a+r /usr/local/cuda/include/cudnn.h /usr/local/cuda/lib64/libcudnn* 安装TensorFlow sudo apt-get install python-pip python-dev sudo pip install --upgrade pip sudo pip install tensorflow-gpu 测试Neural Style sudo apt-get install libatlas-base-dev sudo pip install numpy scipy pillow git clone https://github.com/anishathalye/neural-style.git cd neural-style wget http://www.vlfeat.org/matconvnet/models/beta16/imagenet-vgg-verydeep-19.mat python neural_style.py --content examples/1-content.jpg --styles examples/1-style.jpg --output 1.jpg 完成。\n跑一次 Neural Style 大概需要7分钟。\n测试后记得讲实例停掉，然后制作image，留作下次测试用，讲运行中的实例删除，毕竟$0.9/小时也不便宜（image保存在EBS中，也会消耗小量的费用）。\n玩了一天5个小时，消耗4.5刀，虽然不算便宜，但相比动辄两三万的深度学习工作站，平时玩玩的话还算可以。\n成果：\nupdate: 2018-05-17,新版安装流程\nexport LC_ALL=\u0026#34;en_US.UTF-8\u0026#34; export LC_CTYPE=\u0026#34;en_US.UTF-8\u0026#34; sudo dpkg-reconfigure locales lspci | grep -i nvidia sudo apt-get update sudo apt-cache search nvidia wget http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/cuda-repo-ubuntu1604_9.0.176-1_amd64.deb sudo dpkg -i cuda-repo-ubuntu1604_9.0.176-1_amd64.deb sudo apt-key adv --fetch-keys http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/7fa2af80.pub sudo apt-get update sudo apt-get install cuda-9-0 wget \u0026#34;https://developer.download.nvidia.com/compute/machine-learning/cudnn/secure/v7.0.5/prod/9.0_20171129/Ubuntu16_04-x64/libcudnn7_7.0.5.15-1%2Bcuda9.0_amd64.deb?*** dpkg -i libcudnn7_7.0.5.15-1+cuda9.0_amd64.deb sudo dpkg -i libcudnn7_7.0.5.15-1+cuda9.0_amd64.deb nvidia-smi sudo apt-get install python-pip python-dev sudo pip install --upgrade pip sudo pip install tensorflow-gpu sudo pip install scikit-image ","permalink":"https://yplam.com/posts/machinelearning/aws-cuda-tensorflow/","summary":"\u003cp\u003e最近迷上了机器学习，花了不少时间学习相关的基础内容；虽然数学跟不上，也不妨碍跟风玩玩各位大牛的开源成果。\n本文记录了购买AWS GPU服务器，安装cuda、 TensorFlow，运行 Neural Style 测试的过程。\u003c/p\u003e","title":"AWS TensorFlow 安装与测试"},{"content":"机器学习是人工智能的一个分支。人工智能的研究是从以“推理”为重点到以“知识”为重点，再到以“学习”为重点，一条自然、清晰的脉络。显然，机器学习是实现人工智能的一个途径，即以机器学习为手段解决人工智能中的问题。机器学习在近30多年已发展为一门多领域交叉学科，涉及概率论、统计学、逼近论、凸分析、计算复杂性理论等多门学科。机器学习理论主要是设计和分析一些让计算机可以自动“学习”的算法。机器学习算法是一类从数据中自动分析获得规律，并利用规律对未知数据进行预测的算法。因为学习算法中涉及了大量的统计学理论，机器学习与推断统计学联系尤为密切，也被称为统计学习理论。来源\n本文记录机器学习相关的概念与资料索引。\n机器学习分类 机器学习可以分成下面几种类别：\n监督学习从给定的训练数据集中学习出一个函数，当新的数据到来时，可以根据这个函数预测结果。监督学习的训练集要求是包括输入和输出，也可以说是特征和目标。训练集中的目标是由人标注的。常见的监督学习算法包括回归分析和统计分类。 无监督学习与监督学习相比，训练集没有人为标注的结果。常见的无监督学习算法有聚类。 半监督学习介于监督学习与无监督学习之间。 增强学习通过观察来学习做成如何的动作。每个动作都会对环境有所影响，学习对象根据观察到的周围环境的反馈来做出判断。 机器学习资料及读后感 李航《统计学习方法》，薄薄的一本书，内容很清晰，直接了当，但没有涉及数学基础的讲解，需要边看边翻数学书恶补基础，总的来说值得化时间认真看几遍。感知机、k近邻法、朴素贝叶斯法、决策树、逻辑斯谛回归与最大熵模型、支持向量机、提升方法、EM算法、隐马尔可夫模型和条件随机场。 TOBY SEGARAN 《集体智慧编程》，应用类的书，主要是为了加深理解，并且避免连续看纯理论的书影响积极性。 Neural Networks and Deep Learning用一种比较简单的方式介绍神经网络、深度学习、卷积神经网络。特别是用了独立的一章来介绍反向传播算法，讲解以及代码实现都非常清晰。 Principles of training multi-layer neural network using backpropagation 一个非常简单的关于反向传播算法图解。 colah\u0026rsquo;s blog，一位研究员的博客，写得很用心详细。内容涉及神经网络(NN, Neural Networks)，循环神经网络(RNN, Recurrent Neural Networks),卷积神经网络(CNN, Convolutional Neural Networks), 神经网络可视化. The Elements of Statistical Learning,正在看的一本书，主要涉及机器学习相关数学基础，可以作为《统计学习方法》的补充，未完待续。 CS231n课程笔记翻译：反向传播笔记,对反向传播解析得比较仔细。 深度学习论文阅读路线图 ","permalink":"https://yplam.com/posts/machinelearning/machine-learning-notes/","summary":"\u003cp\u003e机器学习是人工智能的一个分支。人工智能的研究是从以“推理”为重点到以“知识”为重点，再到以“学习”为重点，一条自然、清晰的脉络。显然，机器学习是实现人工智能的一个途径，即以机器学习为手段解决人工智能中的问题。机器学习在近30多年已发展为一门多领域交叉学科，涉及概率论、统计学、逼近论、凸分析、计算复杂性理论等多门学科。机器学习理论主要是设计和分析一些让计算机可以自动“学习”的算法。机器学习算法是一类从数据中自动分析获得规律，并利用规律对未知数据进行预测的算法。因为学习算法中涉及了大量的统计学理论，机器学习与推断统计学联系尤为密切，也被称为统计学习理论。\u003ca href=\"https://zh.wikipedia.org/wiki/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0\"\u003e来源\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e本文记录机器学习相关的概念与资料索引。\u003c/p\u003e","title":"机器学习笔记"},{"content":"localStorage 对象用来在浏览器本地存取数据，并且数据不因浏览器的关闭而丢失。浏览器中同一个域下的窗口可以共享 localStorage 数据。因此我们可以利用这一特性进行跨浏览器内的跨页的事件发送，从而进行通讯。\n下面介绍一个简单的应用场景：用户打开了我们网站的多个页面，其状态为未登录，那么可能所有页面上都会有登录按钮或者登录框，评论框也会提示登录，而当他在某一个页面登陆后，我们希望同时更新其他非活动页面的UI，这样当他返回到其他在登录前已打开的页面时，可以以已登录状态进行相关操作（至少不会再出现登录框）。\n// isLogin 由后台模板生成，标识当前页用户的登录状态 var isLogin = true; var isLoginLocal = localStorage.getItem(\u0026#39;isLogin\u0026#39;); if(isLogin \u0026amp;\u0026amp; (isLoginLocal==\u0026#39;no\u0026#39; || isLoginLocal==null)){ localStorage.setItem(\u0026#39;isLogin\u0026#39;, \u0026#39;yes\u0026#39;); } else if( !isLogin \u0026amp;\u0026amp; (isLoginLocal==\u0026#39;yes\u0026#39; || isLoginLocal==null)){ localStorage.setItem(\u0026#39;isLogin\u0026#39;, \u0026#39;no\u0026#39;); } window.addEventListener(\u0026#34;storage\u0026#34;, function(e){ if(e.key == \u0026#39;isLogin\u0026#39;){ // 用户在其他页面进行登录或者登出操作，当前页面ui需要做相应的调整 if(e.newValue == \u0026#39;yes\u0026#39;){ $(\u0026#39;.showLogin\u0026#39;).show(); $(\u0026#39;.hideLogin\u0026#39;).hide(); } else{ $(\u0026#39;.showLogin\u0026#39;).hide(); $(\u0026#39;.hideLogin\u0026#39;).show(); } } }, false); ","permalink":"https://yplam.com/posts/javascript/localstorage-cross-page-comm/","summary":"\u003cp\u003elocalStorage 对象用来在浏览器本地存取数据，并且数据不因浏览器的关闭而丢失。浏览器中同一个域下的窗口可以共享 localStorage 数据。因此我们可以利用这一特性进行跨浏览器内的跨页的事件发送，从而进行通讯。\u003c/p\u003e","title":"使用localStorage进行跨标签页通讯"},{"content":"ELK Stack 由 Elastic.co 公司名下的 Elasticsearch、Logstash、Kibana 三个开源软件的组成，用于日志的快速搜索和分析。\n![ELK stack]({{ site.url }}/assets/2016/elk.png \u0026ldquo;ELK stack\u0026rdquo;)\n本文整理了 ELK 的相关基础知识，并且结合最近对nginx日志分析的一个需求进行记录。\nELK 简介 ELK Stack 是 Elasticsearch、Logstash、Kibana 三个开源软件的组合。在实时数据检索和分析场合，三者通常是配合共用，而且又都先后归于 Elastic.co 公司名下，故有此简称。\nELK Stack 在最近两年迅速崛起，成为机器数据分析，或者说实时日志处理领域，开源界的第一选择。和传统的日志处理方案相比，ELK Stack 具有如下几个优点：\n处理方式灵活。Elasticsearch 是实时全文索引，不需要像 storm 那样预先编程才能使用； 配置简易上手。Elasticsearch 全部采用 JSON 接口，Logstash 是 Ruby DSL 设计，都是目前业界最通用的配置语法设计； 检索性能高效。虽然每次查询都是实时计算，但是优秀的设计和实现基本可以达到全天数据查询的秒级响应； 集群线性扩展。不管是 Elasticsearch 集群还是 Logstash 集群都是可以线性扩展的； 前端操作炫丽。Kibana 界面上，只需要点击鼠标，就可以完成搜索、聚合功能，生成炫丽的仪表板。 摘自 ELKstack 中文指南\n使用ELK的原因 公司的资讯网站运行在一个相对老旧的CMS上，虽然有记录nginx访问日志，但通常是用于数据后分析上，对服务器突发的CPU、带宽暴涨，缺乏快速的分析响应。使用ELK后可以很直观的在Kibana面板 上看到关于网站访问的实时数据，并且可以针对重点需求设置特定面板，通过快速查看实时日志分析各种服务器资源波动原因。\nELK 安装 ELK的安装相对简单，只需要安装好java，然后添加官方源就可以使用系统自带的包管理工具安装。\n详细安装过程可以参考下面两个链接 ubuntu, Centos\nLogstash Logstash 可以看作是一个ETL工具，负责对日志的抽取、转换、加载，在ELK栈中，Logstash 负责监听日志文件，从日志文件中抽取有用数据，拆分，转换，然后保存到 Elasticsearch。Logstash 除了可以监听日志文件以外， 还可以跟filebeat等工具配合使用，将多个服务器的日志集合到一起，再中转存储。Logstash 会将日志按天来生成 Type，添加到索引中。\ninput { beats { host =\u0026gt; \u0026#34;1.2.3.4\u0026#34; port =\u0026gt; 5044 ssl =\u0026gt; false codec =\u0026gt; json } } filter { mutate { convert =\u0026gt; [\u0026#34;status\u0026#34;, \u0026#34;integer\u0026#34;] } mutate { remove_field =\u0026gt; [\u0026#34;@version\u0026#34;] } } output { elasticsearch { hosts =\u0026gt; [\u0026#34;1.2.3.4:9200\u0026#34;] index =\u0026gt; \u0026#34;abc-log\u0026#34; document_type =\u0026gt; \u0026#34;%{+YYYY.MM.dd}\u0026#34; workers =\u0026gt; 1 flush_size =\u0026gt; 200 idle_flush_time =\u0026gt; 5 } } Elasticsearch 在Logstash发送日志信息过来之前，Elasticsearch 需要先创建好索引mapping。\n{ \u0026#34;mappings\u0026#34;: { \u0026#34;_default_\u0026#34;: { \u0026#34;dynamic_templates\u0026#34;: [ { \u0026#34;notanalyzed\u0026#34;: { \u0026#34;mapping\u0026#34;: { \u0026#34;index\u0026#34;: \u0026#34;not_analyzed\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, \u0026#34;match\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;match_mapping_type\u0026#34;: \u0026#34;string\u0026#34; } } ], \u0026#34;properties\u0026#34;: { \u0026#34;agent\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, \u0026#34;clientip\u0026#34;: { \u0026#34;index\u0026#34;: \u0026#34;not_analyzed\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, \u0026#34;host\u0026#34;: { \u0026#34;index\u0026#34;: \u0026#34;not_analyzed\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, \u0026#34;http_host\u0026#34;: { \u0026#34;index\u0026#34;: \u0026#34;not_analyzed\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, \u0026#34;http_referer\u0026#34;: { \u0026#34;index\u0026#34;: \u0026#34;not_analyzed\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, \u0026#34;path\u0026#34;: { \u0026#34;index\u0026#34;: \u0026#34;not_analyzed\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, \u0026#34;request\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, \u0026#34;responsetime\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;double\u0026#34; }, \u0026#34;size\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, \u0026#34;status\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; } } } } } Kibana Kibana 不需要太多的配置，只需要访问到 Elasticsearch，并且发现相关的索引。\nKibana 按照 搜索 -\u0026gt; 可视化 -\u0026gt; 面板 的流程，将你需要看到的信息逐步构建出来。\n使用phantomjs定期发送Kibana报告 下面是使用 phantomjs 发送Kibana报告的测试代码。其原理是使用 phantomjs 模拟浏览器访问 Kibana，然后对访问内容进行截图，然后将生成的截图通过 http post的方式调用 sendcloud 接口发送邮件。（发送邮件的调用有点繁琐，因为找不到很好的读取本地文件的方式，而 phantomjs webpage 模块的 renderBuffer 实际上又无法使用）\nvar page = require(\u0026#39;webpage\u0026#39;).create(); var fs = require(\u0026#39;fs\u0026#39;); var url = \u0026#34;***\u0026#34;; page.settings.userName = \u0026#34;***\u0026#34;; // http auth page.settings.password = \u0026#34;***\u0026#34;; page.viewportSize = { width: 1280, height: 900 }; page.open(url, function(status) { if (status !== \u0026#39;success\u0026#39;) { console.log(\u0026#39;Unable to load the address!\u0026#39;); phantom.exit(1); } else { window.setTimeout(function () { page.render(\u0026#39;abc.png\u0026#39;); var rawFile = new XMLHttpRequest(); rawFile.open(\u0026#34;GET\u0026#34;, \u0026#39;file://****abc.png\u0026#39;, false); rawFile.responseType = \u0026#34;blob\u0026#34;; rawFile.onload = function () { var formPost = new FormData(); var apiUser = \u0026#39;***\u0026#39;; var apiKey = \u0026#39;***\u0026#39;; var currentDate = new Date(); formPost.append(\u0026#39;apiUser\u0026#39;, apiUser); formPost.append(\u0026#39;apiKey\u0026#39;, apiKey); formPost.append(\u0026#39;from\u0026#39;, \u0026#39;***\u0026#39;); formPost.append(\u0026#39;to\u0026#39;, \u0026#39;***\u0026#39;); formPost.append(\u0026#39;subject\u0026#39;, \u0026#39;***数据日报 - \u0026#39;+currentDate.toString()); formPost.append(\u0026#39;html\u0026#39;, \u0026#39;\u0026lt;h1\u0026gt;***数据日报\u0026lt;/h1\u0026gt;\u0026lt;p\u0026gt;此数据由程序自动生成，如果需要调整相关指标，请反馈给产品经理。\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;img src=\u0026#34;cid:abc.png\u0026#34;/\u0026gt;\u0026lt;/p\u0026gt;\u0026#39;); formPost.append(\u0026#39;useAddressList\u0026#39;, true); formPost.append(\u0026#39;attachments\u0026#39;, rawFile.response, \u0026#39;abc.png\u0026#39;); formPost.append(\u0026#39;embeddedImage\u0026#39;, rawFile.response, \u0026#39;abc.png\u0026#39;); formPost.append(\u0026#39;embeddedCid\u0026#39;, \u0026#34;abc.png\u0026#34;); var xhr = new XMLHttpRequest(); xhr.open(\u0026#39;POST\u0026#39;, \u0026#39;http://api.sendcloud.net/apiv2/mail/send\u0026#39;, true); xhr.send(formPost); xhr.onload = function (e) { if (xhr.readyState === 4) { if (xhr.status === 200) { console.log(xhr.responseText); } else { console.error(xhr.statusText); } } }; xhr.onerror = function (e) { console.error(xhr.statusText); }; }; rawFile.send(null); window.setTimeout(function(){ phantom.exit(); }, 5000); }, 20000); } }); 将上面内容保存为js文件，然后用下面命令调用\nphantomjs --web-security=false --local-to-remote-url-access=true ***.js 参考资料 The Complete Guide to the ELK Stack ELKstack 中文指南 ","permalink":"https://yplam.com/posts/linux/elk-log-analytics/","summary":"\u003cp\u003eELK Stack 由 Elastic.co 公司名下的 Elasticsearch、Logstash、Kibana 三个开源软件的组成，用于日志的快速搜索和分析。\u003c/p\u003e","title":"ELK日志分析入门"},{"content":"测试环境 ubuntu 14.04, php 5.5.9，使用 ab -c 10 -t 5 的方式针对不同的Symfony配置进行性能测试。\n首先，symfony new test 3.0 命令行创建3.0版本的symfony\n初始性能测试\nRequests per second: 263.32 [#/sec] (mean) Time per request: 37.977 [ms] (mean) 使用APC\nRequests per second: 307.96 [#/sec] (mean) Time per request: 32.472 [ms] (mean) $loader = require __DIR__.\u0026#39;/../app/autoload.php\u0026#39;; include_once __DIR__.\u0026#39;/../var/bootstrap.php.cache\u0026#39;; $apcLoader = new Symfony\\Component\\ClassLoader\\ApcClassLoader(sha1(__FILE__), $loader); $loader-\u0026gt;unregister(); $apcLoader-\u0026gt;register(true); 在产线环境还可以对apc进行优化以提升性能，不过需要注意deploy后重启php-fpm apc.stat=0\n不使用twig，直接输出json\nRequests per second: 372.09 [#/sec] (mean) Time per request: 26.875 [ms] (mean) use Symfony\\Component\\HttpFoundation\\JsonResponse; class DefaultController extends Controller { /** * @Route(\u0026#34;/\u0026#34;, name=\u0026#34;homepage\u0026#34;) */ public function indexAction(Request $request) { return new JsonResponse(array(\u0026#39;hello\u0026#39;=\u0026gt;\u0026#39;world\u0026#39;)); } } 禁用monolog\n如果你不需要在产线记录日志，或者你根本没有看过产线日志，那么禁用monolog也可以带来性能的提升。当然，使用redis log也是一个不错的选择。\nRequests per second: 405.40 [#/sec] (mean) Time per request: 24.667 [ms] (mean) 禁用SwiftMailer\n对于需要经常发送邮件的应用而言，SwiftMailer是一个不错的选择，然而SwiftMailer会监听kernel.terminate事件来发送邮件，这样就是对于没有发送邮件需求的请求，使用SwiftMailer还会产生4-5ms的时间消耗，对于性能要求高的应用，这也是不可接受的。\n并且，就算是需要发送邮件，对于一个高性能的应用，将邮件放在队列中发送比在kernel.terminate中发送要更加合理一些。\nRequests per second: 506.43 [#/sec] (mean) Time per request: 19.746 [ms] (mean) 以上就是暂时能够整理出来的Symfony性能最优化初始配置，当然，此配置只能做一些简单的restful应用。\n在实际项目中，我们在创建新的service，添加新bundle时必须要关注其带来的性能影响，下面是一些常用的避免性能恶化的实践：\n避免在service构造函数中做过多操作\n特别是一些事件监听类服务，可能每次请求都会对该服务进行实例化操作，而实际上监听器只会在某些情况下才会进行真实的操作，因此那些消耗资源的初始化工作应该在真正用到前才进行。\n使用doctrine cache，适当选择使用dql或者orm\n","permalink":"https://yplam.com/posts/symfony/symfony-performance/","summary":"\u003cp\u003e测试环境 ubuntu 14.04, php 5.5.9，使用 ab -c 10 -t 5 的方式针对不同的Symfony配置进行性能测试。\u003c/p\u003e","title":"Symfony 性能优化"},{"content":"This post show you how to configure Ubuntu as 6LoWPAN router and bridge 6LoWPAN devices to the IPv4/IPv6 Internet.\nSlip-radio\nBecause I do not have a CC2531 Dongle around, I use a SensorTag CC2650 with DevPack as Slip-radio.\nFirst, change dir to contiki/examples/ipv6/slip-radio, run command:\nmake TARGET=srf06-cc26xx BOARD=sensortag/cc2650 Then flash slip-radio.bin to SensorTag using uniflash.\nYou need to validate that slip radio is running:\nsudo minicom -s Config minicom to use /dev/ttyACM0 with 115200 8N1. Your will see message like this after resetting SensorTag:\nStarting Contiki-3.x-2102-g9f1376d With DriverLib v0.44336 TI CC2650 SensorTag Net: slipnet MAC: nullmac RDC: ContikiMAC, Channel Check Interval: 16 ticks RF: Channel 25 Slip Radio started... 1) Edge Router\nFollow the instructions on the following link to compile and install the 6lbr router: https://github.com/cetic/6lbr/wiki/Other-Linux-Software-Configuration\nEdit /etc/6lbr/6lbr.conf as follow:\nMODE=ROUTER RAW_ETH=0 DEV_TAP=tap0 BRIDGE=1 CREATE_BRIDGE=6LBR DEV_BRIDGE=eth0 ETH_JOIN_BRIDGE=0 DEV_RADIO=/dev/ttyACM0 BAUDRATE=115200 More about configure options: https://github.com/cetic/6lbr/wiki/6LBR-Configuration-file\nStart 6lbr:\nsudo service 6lbr start Config 6LBR to access WSN network:\nsudo route -A inet6 add aaaa::/64 gw bbbb::100 Now open http://[bbbb::100] in your browser and you can access the embedded web server.\n2) Use Smart Bridge to access localhost MQTT Server\nEdit /etc/6lbr/6lbr.conf as follow:\nMODE=ROUTER RAW_ETH=0 DEV_TAP=tap0 BRIDGE=1 CREATE_BRIDGE=6LBR DEV_BRIDGE=eth0 ETH_JOIN_BRIDGE=0 DEV_RADIO=/dev/ttyACM0 BAUDRATE=115200 Add /etc/6lbr/ifup.d/60dev\n#!/bin/bash . $CETIC_6LBR_CONF . $1/6lbr-functions config_default MODE_6LBR=$2 DEV=$3 OS=`uname` ip -6 address add 2001:db8:2::2/64 dev tap0 sysctl -w net.ipv4.conf.all.forwarding=1 sysctl -w net.ipv6.conf.all.forwarding=1 Add /etc/6lbr/ifdown.d/60dev\n#!/bin/bash . $CETIC_6LBR_CONF . $1/6lbr-functions config_default MODE_6LBR=$2 DEV=$3 OS=`uname` sysctl -w net.ipv4.conf.all.forwarding=0 sysctl -w net.ipv6.conf.all.forwarding=0 You alse need to run:\nchmod +x /etc/6lbr/ifup.d/60dev chmod +x /etc/6lbr/ifdown.d/60dev Install and configure radvd:\ninterface tap0 { AdvSendAdvert on; AdvManagedFlag off; #stateless autoconfiguration AdvOtherConfigFlag on; #clients get extra parameters via DHCPv6 MaxRtrAdvInterval 10; #resend RA @ random times, max 10sec delay prefix 2001:db8:2::/64 #announce prefix to clients { AdvOnLink on; AdvAutonomous on; AdvRouterAddr on; }; RDNSS 2001:db8:2::2 { }; }; Start 6lbr and radvd, you can access router machine var 2001:db8:2::2 from a WSN node. And your WSN node will get an ipv6 address like 2001:db8:2:::::**** from radvd.\n3) MQTT over IPV4 WAN\nI only have IPV4 WAN access, and have a mosquitto server running on my Linode server. So I need a NAT64 tool to bridge ipv6 to ipv4 network.\nAfter trying jool with no luck, I decided to use 6tunnel to forward ipv6 traffic.\nsudo apt-get install 6tunnel 6tunnel -6 1883 your.mqtt.server.ip 1883 That\u0026rsquo;s all!\nSee also:\nhttp://processors.wiki.ti.com/index.php/Contiki-6LOWPAN-BBB\n","permalink":"https://yplam.com/posts/embedded/configuring-6lbr-ubuntu-sensortag-cc2650/","summary":"\u003cp\u003eThis post show you how to configure Ubuntu as 6LoWPAN router and bridge 6LoWPAN devices to the IPv4/IPv6 Internet.\u003c/p\u003e","title":"Configuring 6lbr for Ubuntu and SensorTag CC2650"},{"content":"Symfony2 是一个全功能的框架，因此有些开发人员会以它太“重”了（而不是太“难”了）为理由而拒绝使用。在开发环境下，一个简单的Symfony页面大概需要花费 70ms，而prod环境下大概需要30ms（以上是个人在一个Web App上实践后数据）。虽然相对其提供的功能而言，这是一个可观的数据，但对于一个简单的REST API请求而言，这也许真的太“重”了。\nSymfony 2.8 引入了微内核的功能，用来创建简单，甚至是单文件的Symfony 应用。\n下面是一个简单的例子：\n// app/MicroKernel.php use Symfony\\Bundle\\FrameworkBundle\\Kernel\\MicroKernelTrait; use Symfony\\Component\\Config\\Loader\\LoaderInterface; use Symfony\\Component\\DependencyInjection\\ContainerBuilder; use Symfony\\Component\\HttpFoundation\\Response; use Symfony\\Component\\HttpKernel\\Kernel; use Symfony\\Component\\Routing\\RouteCollectionBuilder; class MicroKernel extends Kernel { use MicroKernelTrait; public function registerBundles() { return array(new Symfony\\Bundle\\FrameworkBundle\\FrameworkBundle()); } protected function configureRoutes(RouteCollectionBuilder $routes) { $routes-\u0026gt;add(\u0026#39;/\u0026#39;, \u0026#39;kernel:indexAction\u0026#39;, \u0026#39;index\u0026#39;); } protected function configureContainer(ContainerBuilder $c, LoaderInterface $loader) { $c-\u0026gt;loadFromExtension(\u0026#39;framework\u0026#39;, [\u0026#39;secret\u0026#39; =\u0026gt; \u0026#39;12345\u0026#39;]); } public function indexAction() { return new Response(\u0026#39;Hello World\u0026#39;); } } MicroKernel类主要实现配置 bundle、配置路由、路由响应的功能；只需要简单几行代码就完成一个Symfony应用。当然，MicroKernel实际上不会提升Symfony的运行性能，它只不过是改变了Symfony配置路由与bundle的方式，但是这样的改变使得你的应用只使用Symfony最基本的功能，禁用了大量的特性，因此可以带来性能的提升：\n![全框架与微框架]({{ site.url }}/assets/2015/symfony_micro.jpg \u0026ldquo;全框架与微框架\u0026rdquo;)\n显然，这样做带来一个非常大的灵活性，你可以在Symfony的基础上开发你的应用，避免通常微框架所带来的限制，当你的应用越来越复杂的时候，你可以逐渐的将需要用到的Symfony特性加进去。\n譬如，下面的例子就是在上面的基础上添加了Twig模板、Web调试工具栏的支持，依然可以写在一个文件里。\n// app/MicroKernel.php class MicroKernel extends Kernel { use MicroKernelTrait; public function registerBundles() { $bundles = array( new Symfony\\Bundle\\FrameworkBundle\\FrameworkBundle(), new Symfony\\Bundle\\TwigBundle\\TwigBundle(), ); if (in_array($this-\u0026gt;getEnvironment(), array(\u0026#39;dev\u0026#39;, \u0026#39;test\u0026#39;), true)) { $bundles[] = new Symfony\\Bundle\\WebProfilerBundle\\WebProfilerBundle(); } return $bundles; } protected function configureRoutes(RouteCollectionBuilder $routes) { $routes-\u0026gt;mount(\u0026#39;/_wdt\u0026#39;, $routes-\u0026gt;import(\u0026#39;@WebProfilerBundle/Resources/config/routing/wdt.xml\u0026#39;)); $routes-\u0026gt;mount(\u0026#39;/_profiler\u0026#39;, $routes-\u0026gt;import(\u0026#39;@WebProfilerBundle/Resources/config/routing/profiler.xml\u0026#39;)); $routes-\u0026gt;add(\u0026#39;/\u0026#39;, \u0026#39;kernel:indexAction\u0026#39;, \u0026#39;index\u0026#39;); } protected function configureContainer(ContainerBuilder $c, LoaderInterface $loader) { // load bundles\u0026#39; configuration $c-\u0026gt;loadFromExtension(\u0026#39;framework\u0026#39;, [ \u0026#39;secret\u0026#39; =\u0026gt; \u0026#39;12345\u0026#39;, \u0026#39;profiler\u0026#39; =\u0026gt; null, \u0026#39;templating\u0026#39; =\u0026gt; [\u0026#39;engines\u0026#39; =\u0026gt; [\u0026#39;twig\u0026#39;]], ]); $c-\u0026gt;loadFromExtension(\u0026#39;web_profiler\u0026#39;, [\u0026#39;toolbar\u0026#39; =\u0026gt; true]); // add configuration parameters $c-\u0026gt;setParameter(\u0026#39;mail_sender\u0026#39;, \u0026#39;user@example.com\u0026#39;); // register services $c-\u0026gt;register(\u0026#39;app.markdown\u0026#39;, \u0026#39;AppBundle\\\\Service\\\\Parser\\\\Markdown\u0026#39;); } public function indexAction() { return $this-\u0026gt;container-\u0026gt;get(\u0026#39;templating\u0026#39;)-\u0026gt;renderResponse(\u0026#39;index.html.twig\u0026#39;); } } 单文件应用可能会导致代码显得混乱，下面是一个可以在真实场景中使用的例子，包括单个service.yml、config.yml配置，路由使用 annotations 注释：\n// app/MicroKernel.php // ... class MicroKernel extends Kernel { use MicroKernelTrait; public function registerBundles() { return array( new Sensio\\Bundle\\FrameworkExtraBundle\\SensioFrameworkExtraBundle(), new Symfony\\Bundle\\FrameworkBundle\\FrameworkBundle(), new Symfony\\Bundle\\TwigBundle\\TwigBundle(), new AppBundle\\AppBundle(), ); } protected function configureRoutes(RouteCollectionBuilder $routes) { $routes-\u0026gt;mount(\u0026#39;/\u0026#39;, $routes-\u0026gt;import(\u0026#39;@AppBundle/Controller\u0026#39;, \u0026#39;annotation\u0026#39;)); } protected function configureContainer(ContainerBuilder $c, LoaderInterface $loader) { $loader-\u0026gt;load(__DIR__.\u0026#39;/config/config_\u0026#39;.$this-\u0026gt;getEnvironment().\u0026#39;.yml\u0026#39;); $loader-\u0026gt;load(__DIR__.\u0026#39;/config/services.yml\u0026#39;); } } 当然，不要忘记在入口文件中使用MicroKernel :)\n// web/app.php use Symfony\\Component\\HttpFoundation\\Request; $loader = require __DIR__.\u0026#39;/../app/autoload.php\u0026#39;; require_once __DIR__.\u0026#39;/../app/MicroKernel.php\u0026#39;; $app = new MicroKernel(\u0026#39;prod\u0026#39;, false); $app-\u0026gt;loadClassCache(); $app-\u0026gt;handle(Request::createFromGlobals())-\u0026gt;send(); Symfony2引入微内核，还会带来另外一个便利，通常，对于后台、内容编辑、内容提交的页面，我们需要全功能的支持，然而对于一些只需要简单的JSON API接口，我们可以添加多一个使用微内核的入口文件，提高接口的响应速度，减少资源消耗。\n","permalink":"https://yplam.com/posts/symfony/symfony-micro-framework/","summary":"\u003cp\u003eSymfony2 是一个全功能的框架，因此有些开发人员会以它太“重”了（而不是太“难”了）为理由而拒绝使用。在开发环境下，一个简单的Symfony页面大概需要花费 70ms，而prod环境下大概需要30ms（以上是个人在一个Web App上实践后数据）。虽然相对其提供的功能而言，这是一个可观的数据，但对于一个简单的REST API请求而言，这也许真的太“重”了。\u003c/p\u003e","title":"Symfony2 太“重”了？试试 Symfony2 微框架"},{"content":"持续集成是一种软件开发实践，对于提高软件开发效率并保障软件开发质量提供了理论基础。Jenkins 是一个开源软件项目，旨在提供一个开放易用的软件平台，使持续集成变成可能。本文记录如何使用 Jenkins 与 Github 对 Symfony 2 应用进行持续集成。\n服务器环境\n下面的内容基于Debian 7, Linode 2GB, PHP 5.5, Nginx 1.8, 理论上应该适用于最近版本的Debian、Ubuntu。\n持续集成概述 什么是持续集成\n随着软件开发复杂度的不断提高，团队开发成员间如何更好地协同工作以确保软件开发的质量已经慢慢成为开发过程中不可回避的问题。尤其是近些年来，敏捷（Agile） 在软件工程领域越来越红火，如何能再不断变化的需求中快速适应和保证软件的质量也显得尤其的重要。\n持续集成正是针对这一类问题的一种软件开发实践。它倡导团队开发成员必须经常集成他们的工作，甚至每天都可能发生多次集成。而每次的集成都是通过自动化的构建来验证，包括自动编译、发布和测试，从而尽快地发现集成错误，让团队能够更快的开发内聚的软件。\n持续集成的核心价值在于：\n持续集成中的任何一个环节都是自动完成的，无需太多的人工干预，有利于减少重复过程以节省时间、费用和工作量； 持续集成保障了每个时间点上团队成员提交的代码是能成功集成的。换言之，任何时间点都能第一时间发现软件的集成问题，使任意时间发布可部署的软件成为了可能； 持续集成还能利于软件本身的发展趋势，这点在需求不明确或是频繁性变更的情景中尤其重要，持续集成的质量能帮助团队进行有效决策，同时建立团队对开发产品的信心。 持续集成的原则\n业界普遍认同的持续集成的原则包括：\n需要版本控制软件保障团队成员提交的代码不会导致集成失败。常用的版本控制软件有 IBM Rational ClearCase、CVS、Subversion 等； 开发人员必须及时向版本控制库中提交代码，也必须经常性地从版本控制库中更新代码到本地； 需要有专门的集成服务器来执行集成构建。根据项目的具体实际，集成构建可以被软件的修改来直接触发，也可以定时启动，如每半个小时构建一次； 必须保证构建的成功。如果构建失败，修复构建过程中的错误是优先级最高的工作。一旦修复，需要手动启动一次构建。 持续集成系统的组成\n由此可见，一个完整的构建系统必须包括：\n一个自动构建过程，包括自动编译、分发、部署和测试等。 一个代码存储库，即需要版本控制软件来保障代码的可维护性，同时作为构建过程的素材库。 一个持续集成服务器。本文中介绍的 Jenkins 就是一个配置简单和使用方便的持续集成服务器。 以上内容引用自 https://www.ibm.com/developerworks/cn/java/j-lo-jenkins/\n安装Jenkins Jenkins 是一个开源项目，提供了一种易于使用的持续集成系统，使开发者从繁杂的集成中解脱出来，专注于更为重要的业务逻辑实现上。同时 Jenkins 能实施监控集成中存在的错误，提供详细的日志文件和提醒功能，还能用图表的形式形象地展示项目构建的趋势和稳定性。\nDebian 下 Jenkins 的安装非常简单\nwget -q -O - https://jenkins-ci.org/debian/jenkins-ci.org.key | sudo apt-key add - sudo sh -c \u0026#39;echo deb http://pkg.jenkins-ci.org/debian binary/ \u0026gt; /etc/apt/sources.list.d/jenkins.list\u0026#39; sudo apt-get update sudo apt-get install jenkins 安装完成后，可以通过 /etc/default/jenkins 文件修改jenkins的启动参数；然后启动服务\nservice jenkins start 也可以将jenkins加入到自动启动服务中\nupdate-rc.d jenkins defaults 在默认配置下，访问服务器的8080端口，就可以看到Jenkins的界面；当然，你的服务器可能只开了nginx的80端口，那么需要配置nginx反向代理，以下是一个简单的配置：\nserver { listen 80; server_name ****.com; # 你的服务器域名 location / { proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_pass http://127.0.0.1:8080; proxy_read_timeout 90; } } 这样你就可以通过 80 端口访问jenkins。\n安装完Jenkins后你会发现，Jenkins默认没有开启任何安全认证，所以第一步就是在 Manage Jenkins \u0026gt; Configure Global Security 中勾选 Enable security，使用 Jenkins’ own user database，Allow users to sign up，Logged-in users can do anything；然后注册、登录一个账号；再取消 Allow users to sign up选项；这里的操作有点繁琐，目的只是为了在你配置好Jenkins之前不会被别人捣乱。\n配置插件与PHP库\n在 Manage Jenkins \u0026gt; Manage Plugin 的 Available 标签中搜索安装以下插件\nCheckStyle Clover PHP HTML Publisher DRY JDepend PMD Violations xUnit Git Github Green Balls 然后安装对应的PHP库，可以手动下载或者用 PEAR :\npear channel-discover pear.pdepend.org pear channel-discover pear.phpmd.org pear channel-discover pear.phpunit.de pear channel-discover pear.phpdoc.org pear channel-discover components.ez.no pear channel-discover pear.symfony-project.com pear install pdepend/PHP_Depend pear install phpmd/PHP_PMD pear install phpunit/phpcpd pear install phpunit/phploc pear install --alldeps phpunit/PHP_CodeBrowser pear install --alldeps phpunit/PHPUnit pear install phpdoc/phpDocumentor-alpha pear install PHP_CodeSniffer 对于Symfony2 项目，我们还需要安装Symfony codeing standard，参考：https://github.com/escapestudios/Symfony2-coding-standard\n配置ANT BUILD\n在代码的根目录添加build.xml文件：\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;project name=\u0026#34;name-of-project\u0026#34; default=\u0026#34;build-local\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;workspace\u0026#34; value=\u0026#34;${basedir}\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;sourcedir\u0026#34; value=\u0026#34;${basedir}/src\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;builddir\u0026#34; value=\u0026#34;${workspace}/app/build\u0026#34; /\u0026gt; \u0026lt;target name=\u0026#34;build\u0026#34; depends=\u0026#34;prepare,parameters,vendors,lint,phploc,pdepend,phpmd-ci,phpcs-ci,phpcpd,phpunit,phpcb\u0026#34;/\u0026gt; \u0026lt;target name=\u0026#34;build-local\u0026#34; depends=\u0026#34;prepare,lint,phploc,pdepend,phpmd-ci,phpcs-ci,phpcpd,phpunit\u0026#34;/\u0026gt; \u0026lt;target name=\u0026#34;clean\u0026#34; description=\u0026#34;Cleanup build artifacts\u0026#34;\u0026gt; \u0026lt;delete dir=\u0026#34;${basedir}/app/build/api\u0026#34;/\u0026gt; \u0026lt;delete dir=\u0026#34;${basedir}/app/build/code-browser\u0026#34;/\u0026gt; \u0026lt;delete dir=\u0026#34;${basedir}/app/build/coverage\u0026#34;/\u0026gt; \u0026lt;delete dir=\u0026#34;${basedir}/app/build/logs\u0026#34;/\u0026gt; \u0026lt;delete dir=\u0026#34;${basedir}/app/build/pdepend\u0026#34;/\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;target name=\u0026#34;prepare\u0026#34; depends=\u0026#34;clean\u0026#34; description=\u0026#34;Prepare for build\u0026#34;\u0026gt; \u0026lt;mkdir dir=\u0026#34;${basedir}/app/build/api\u0026#34;/\u0026gt; \u0026lt;mkdir dir=\u0026#34;${basedir}/app/build/code-browser\u0026#34;/\u0026gt; \u0026lt;mkdir dir=\u0026#34;${basedir}/app/build/coverage\u0026#34;/\u0026gt; \u0026lt;mkdir dir=\u0026#34;${basedir}/app/build/logs\u0026#34;/\u0026gt; \u0026lt;mkdir dir=\u0026#34;${basedir}/app/build/pdepend\u0026#34;/\u0026gt; \u0026lt;mkdir dir=\u0026#34;${basedir}/app/build/phpdox\u0026#34;/\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;target name=\u0026#34;phpunit\u0026#34; description=\u0026#34;Run unit tests with PHPUnit\u0026#34;\u0026gt; \u0026lt;exec executable=\u0026#34;phpunit\u0026#34; failonerror=\u0026#34;true\u0026#34;\u0026gt; \u0026lt;arg value=\u0026#34;-c\u0026#34; /\u0026gt; \u0026lt;arg path=\u0026#34;app\u0026#34; /\u0026gt; \u0026lt;/exec\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;target name=\u0026#34;lint\u0026#34; description=\u0026#34;Perform syntax check of sourcecode files\u0026#34;\u0026gt; \u0026lt;apply executable=\u0026#34;php\u0026#34; failonerror=\u0026#34;true\u0026#34;\u0026gt; \u0026lt;arg value=\u0026#34;-l\u0026#34; /\u0026gt; \u0026lt;fileset dir=\u0026#34;${sourcedir}\u0026#34;\u0026gt; \u0026lt;include name=\u0026#34;**/*.php\u0026#34; /\u0026gt; \u0026lt;modified /\u0026gt; \u0026lt;/fileset\u0026gt; \u0026lt;fileset dir=\u0026#34;${basedir}/src/\u0026#34;\u0026gt; \u0026lt;include name=\u0026#34;**/*Test.php\u0026#34; /\u0026gt; \u0026lt;modified /\u0026gt; \u0026lt;/fileset\u0026gt; \u0026lt;/apply\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;target name=\u0026#34;phploc\u0026#34; description=\u0026#34;Measure project size using PHPLOC\u0026#34;\u0026gt; \u0026lt;exec executable=\u0026#34;phploc\u0026#34;\u0026gt; \u0026lt;arg value=\u0026#34;--log-csv\u0026#34; /\u0026gt; \u0026lt;arg value=\u0026#34;${basedir}/app/build/logs/phploc.csv\u0026#34; /\u0026gt; \u0026lt;arg path=\u0026#34;${basedir}/src\u0026#34; /\u0026gt; \u0026lt;/exec\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;target name=\u0026#34;pdepend\u0026#34; description=\u0026#34;Calculate software metrics using PHP_Depend\u0026#34;\u0026gt; \u0026lt;exec executable=\u0026#34;pdepend\u0026#34;\u0026gt; \u0026lt;arg value=\u0026#34;--jdepend-xml=${basedir}/app/build/logs/jdepend.xml\u0026#34; /\u0026gt; \u0026lt;arg value=\u0026#34;--jdepend-chart=${basedir}/app/build/pdepend/dependencies.svg\u0026#34; /\u0026gt; \u0026lt;arg value=\u0026#34;--overview-pyramid=${basedir}/app/build/pdepend/overview-pyramid.svg\u0026#34; /\u0026gt; \u0026lt;arg path=\u0026#34;${basedir}/src\u0026#34; /\u0026gt; \u0026lt;/exec\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;target name=\u0026#34;phpmd-ci\u0026#34; description=\u0026#34;Perform project mess detection using PHPMD creating a log file for the continuous integration server\u0026#34;\u0026gt; \u0026lt;exec executable=\u0026#34;phpmd\u0026#34;\u0026gt; \u0026lt;arg path=\u0026#34;${basedir}/src\u0026#34; /\u0026gt; \u0026lt;arg value=\u0026#34;xml\u0026#34; /\u0026gt; \u0026lt;arg value=\u0026#34;${basedir}/app/Resources/jenkins/phpmd.xml\u0026#34; /\u0026gt; \u0026lt;arg value=\u0026#34;--reportfile\u0026#34; /\u0026gt; \u0026lt;arg value=\u0026#34;${basedir}/app/build/logs/pmd.xml\u0026#34; /\u0026gt; \u0026lt;/exec\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;target name=\u0026#34;phpcs-ci\u0026#34; description=\u0026#34;Find coding standard violations using PHP_CodeSniffer creating a log file for the continuous integration server\u0026#34;\u0026gt; \u0026lt;exec executable=\u0026#34;phpcs\u0026#34;\u0026gt; \u0026lt;arg value=\u0026#34;--report=checkstyle\u0026#34; /\u0026gt; \u0026lt;arg value=\u0026#34;--report-file=${basedir}/app/build/logs/checkstyle.xml\u0026#34; /\u0026gt; \u0026lt;arg value=\u0026#34;--standard=Symfony2\u0026#34; /\u0026gt; \u0026lt;arg path=\u0026#34;${basedir}/src\u0026#34; /\u0026gt; \u0026lt;/exec\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;target name=\u0026#34;phpcpd\u0026#34; description=\u0026#34;Find duplicate code using PHPCPD\u0026#34;\u0026gt; \u0026lt;exec executable=\u0026#34;phpcpd\u0026#34;\u0026gt; \u0026lt;arg value=\u0026#34;--log-pmd\u0026#34; /\u0026gt; \u0026lt;arg value=\u0026#34;${basedir}/app/build/logs/pmd-cpd.xml\u0026#34; /\u0026gt; \u0026lt;arg path=\u0026#34;${basedir}/src\u0026#34; /\u0026gt; \u0026lt;/exec\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;target name=\u0026#34;phpcb\u0026#34; description=\u0026#34;Aggregate tool output with PHP_CodeBrowser\u0026#34;\u0026gt; \u0026lt;exec executable=\u0026#34;phpcb\u0026#34;\u0026gt; \u0026lt;arg value=\u0026#34;--log\u0026#34; /\u0026gt; \u0026lt;arg path=\u0026#34;${basedir}/app/build/logs\u0026#34; /\u0026gt; \u0026lt;arg value=\u0026#34;--source\u0026#34; /\u0026gt; \u0026lt;arg path=\u0026#34;${basedir}/src\u0026#34; /\u0026gt; \u0026lt;arg value=\u0026#34;--output\u0026#34; /\u0026gt; \u0026lt;arg path=\u0026#34;${basedir}/app/build/code-browser\u0026#34; /\u0026gt; \u0026lt;/exec\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;target name=\u0026#34;vendors\u0026#34; description=\u0026#34;Update vendors\u0026#34;\u0026gt; \u0026lt;exec executable=\u0026#34;composer\u0026#34; failonerror=\u0026#34;true\u0026#34;\u0026gt; \u0026lt;arg value=\u0026#34;update\u0026#34; /\u0026gt; \u0026lt;/exec\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;target name=\u0026#34;parameters\u0026#34; description=\u0026#34;Copy parameters\u0026#34;\u0026gt; \u0026lt;exec executable=\u0026#34;cp\u0026#34; failonerror=\u0026#34;true\u0026#34;\u0026gt; \u0026lt;arg path=\u0026#34;app/config/parameters.yml.dist\u0026#34; /\u0026gt; \u0026lt;arg path=\u0026#34;app/config/parameters.yml\u0026#34; /\u0026gt; \u0026lt;/exec\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;/project\u0026gt; 添加 app/Resources/jenkins/phpmd.xml 文件：\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34;?\u0026gt; \u0026lt;ruleset name=\u0026#34;Symfony2 ruleset\u0026#34; xmlns=\u0026#34;http://pmd.sf.net/ruleset/1.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://pmd.sf.net/ruleset/1.0.0 http://pmd.sf.net/ruleset_xml_schema.xsd\u0026#34; xsi:noNamespaceSchemaLocation=\u0026#34;http://pmd.sf.net/ruleset_xml_schema.xsd\u0026#34;\u0026gt; \u0026lt;description\u0026gt; Custom ruleset. \u0026lt;/description\u0026gt; \u0026lt;rule ref=\u0026#34;rulesets/design.xml\u0026#34; /\u0026gt; \u0026lt;rule ref=\u0026#34;rulesets/unusedcode.xml\u0026#34; /\u0026gt; \u0026lt;rule ref=\u0026#34;rulesets/codesize.xml\u0026#34; /\u0026gt; \u0026lt;rule ref=\u0026#34;rulesets/naming.xml\u0026#34; /\u0026gt; \u0026lt;/ruleset\u0026gt; 以上的配置仅作为参考，您可以根据自己的项目有所增删；需要注意的是，上面配置中，要求 app/config/parameters.yml.dist 中的内容为测试机上面的环境配置，譬如：当你的phpunit中需要跟数据库有交互，这些配置选项必须正确。\n配置Github\n在开始创建Jenkins工程前，需要先确保你的服务器能正常访问Github。\n点击 Manage Jenkins \u0026gt; Configure System 找到 GitHub Plugin Configuration，选择Add github server config 选择下边的 Advanced\u0026hellip; 在 Additional actions 中选择cover login and password to token，输入github的用户名与密码，点击create token，会生成一个token供以后使用（这个可以在github后台进行管理） 由于新生成的token不会自动刷新，在此需要先保存，然后重新进入此配置页面，这样在github配置的Credentials选项里就会多了上面生成的token 选择该token，然后点击validate credentials，会返回验证成功的信息 完成上面步骤后Jenkins就有权限访问你的github项目，譬如Jenkins可以自动更新项目的Webhooks，而无需在Github网站进行手动操作。\n另外，如果你使用的时私有工程，那么你需要为Jenkins用户配置访问github的ssh keys，详情请参考：\n创建Jenkins工程\n点击 Create New Job，选择 Free Style Project 配置github相关地址 选择 Build when a change is pushed to GitHub Build类型选择ANT，地址为build.xml 根据需要添加POST Action，如 CheckStype **/app/build/logs/checkstyle.xml pmd **/app/build/logs/pmd.xml Duplicate code results **/app/build/logs/cpd.xml 运行\n配置完成后，点击Build Now开始运行，此时可以在该任务页面中打开终端查看运行状态，进行调错。如无意外，你每次push到github后就会自动触发Jenkins对项目进行Build。\n安全配置\n至此，Jenkins已经可以正常运行，然而，你会发现：就算是没有登录的用户，都可以随意的查看你网站上的项目概况，这对于私有项目来说很不好，因此我们需要配置基于角色的权限管理。\n安装 Role-based Authorization Strategy 插件 在安全配置处启用 Role-Based Strategy Manage Jenkins \u0026gt; Manage and Assign Roles 中按需进行配置，如果只有一个用户，也可以使用默认配置 这样，没登录用户将无法查看关于Jenkins的项目信息。\n参考资料\nhttp://blog.lazycloud.net/en/using-jenkins-for-a-symfony2-project/\n","permalink":"https://yplam.com/posts/symfony/symfony-github-jenkins/","summary":"\u003cp\u003e持续集成是一种软件开发实践，对于提高软件开发效率并保障软件开发质量提供了理论基础。Jenkins 是一个开源软件项目，旨在提供一个开放易用的软件平台，使持续集成变成可能。本文记录如何使用 Jenkins 与 Github 对 Symfony 2 应用进行持续集成。\u003c/p\u003e","title":"使用 Jenkins 与 Github 对 Symfony 2 应用进行持续集成"},{"content":"网络世界充满漏洞，同样，网络世界充满着寻找漏洞的人。为Web服务器的后台路径添加HTTP AUTH认证，是防范漏洞被探测到的一个简单有有效的方法。\n不妨打开你网站的404日志，其中肯定不乏一堆对后台路径的试探性探测，这其中有一些是用来确定你网站使用的是哪种系统，而更多的是直接对各种已知系统漏洞的扫描。\n一个比较有效阻止这种扫描的方法是在Web服务器的层面上添加HTTP认证。\n首先，安装htpasswd工具\nsudo apt-get install apache2-utils 然后生成用户名密码：\nsudo htpasswd -c /etc/nginx/.htpasswd myuser 最后，为需要进行保护的路径添加认证\nlocation location ~ /admin(/.*) { ... auth_basic \u0026#34;Restricted\u0026#34;; auth_basic_user_file /etc/nginx/.htpasswd; ... } 这样，用户在访问admin路径下的内容时都会多一层HTTP认证。\n然而，我们可以对上面的配置做一点人性化的修改。譬如，针对公司用户而言，IP地址是固定的，我们可以将该地址设为可信，这样就免除了公司内部人员认证的麻烦：\nlocation location ~ /admin(/.*) { ... satisfy any; include allow-ips.conf; deny all; auth_basic \u0026#34;Restricted\u0026#34;; auth_basic_user_file /etc/nginx/.htpasswd; ... } allow-ips.conf 配置免除HTTP认证的IP地址，内容如：\nallow 119.147.176.159; ","permalink":"https://yplam.com/posts/linux/nginx-http-auth/","summary":"\u003cp\u003e网络世界充满漏洞，同样，网络世界充满着寻找漏洞的人。为Web服务器的后台路径添加HTTP AUTH认证，是防范漏洞被探测到的一个简单有有效的方法。\u003c/p\u003e","title":"配置 Nginx Http 认证以及 IP 访问策略"},{"content":"Redis 由于功能强大、性能优越、支持持久化等优点，在很多应用上已经替代Memcached，成为首选的缓存系统，还可以作为简单的db使用。\n正因为如此，有时我们需要将redis同时作为下面几种功能使用：\ncache，不需要持久化 session，只需要简单的持久化，隔个十分钟存一下就好，丢失一些也不会造成太大问题 db，不能丢失数据，需要比较积极的持久化策略，日志记录等 虽然你可以按db的方式来统一对待所有的需求，将它们放在同一个实例中，使用不同的database区分，但是将它们分到不同实例的方式可能会更好。\n配置文件\n配置文件位与 /etc/redis 目录，默认有 redis.conf\n我们可以将redis.conf重命名为common.conf，然后用include的方式来定制每一个redis实例的配置\n如 redis-session.conf\ninclude /etc/redis/common.conf pidfile /var/run/redis/redis-session.pid port 6380 save 900 1 save 60 10000 dbfilename dump-session.rdb Service配置\n如果你想将你自定义的redis实例变成系统的service，使用debian自带的service命令来启动重启，那么你需要配置service脚本\n复制 /lib/systemd/system/redis-server.service 到 /lib/systemd/system/redis-session.service\n然后根据需求修改里面的配置，主要是配置文件，pid路径等。\n你可以通过 service redis-session start 或者 status 等命令来测试，如果启动失败，请通过 /var/log/syslog 文件来查看问题\nINIT脚本\n如果你想你的redis实例可以开机自动运行，那么就需要配置init脚本\n复制 /etc/init.d/redis-server 到 /etc/init.d/redis-session\n根据需求修改里面的配置，主要也是命名、配置等信息，然后通过\nupdate-rc.d redis-session defaults 命令来设置开机自动运行\n","permalink":"https://yplam.com/posts/linux/debian-mul-redis/","summary":"\u003cp\u003eRedis 由于功能强大、性能优越、支持持久化等优点，在很多应用上已经替代Memcached，成为首选的缓存系统，还可以作为简单的db使用。\u003c/p\u003e","title":"Debian 8 服务器运行多Redis实例"},{"content":"对于一些UGC（用户创建内容）类网站而言，特别是图片网站，随着用户数的增长，时间的推移，网站上的文件会越来越多；得益于云服务的出现，存储系统的扩展变得简单，一个比较常用的做法就是将文件存储于AWS S3，然后用户通过S3或者CloudFront下载。然而虽然AWS S3的储存价格相对便宜，但流量价格却非常高，最终导致网站的托管开销增加。\n下面介绍的方式，文件存储在AWS S3服务器上，Nginx配置成S3的反向代理，Nginx将热门文件缓存在本地服务器，大大减少对S3的文件请求，从而降低流量费用。\nproxy_cache_path /var/nginx/cache/aws levels=2:2:2 use_temp_path=off keys_zone=aws:1000m inactive=30d max_size=100g; server{ ... location @proxy { set $s3_bucket \u0026#39;testaws.s3.amazonaws.com\u0026#39;; add_header x-by \u0026#34;aws\u0026#34;; proxy_http_version 1.1; proxy_set_header Host $s3_bucket; proxy_set_header Authorization \u0026#39;\u0026#39;; proxy_hide_header x-amz-id-2; proxy_hide_header x-amz-request-id; proxy_hide_header Set-Cookie; proxy_ignore_headers \u0026#34;Set-Cookie\u0026#34;; proxy_buffering on; proxy_intercept_errors on; proxy_cache aws; proxy_cache_valid any 1m; proxy_cache_valid 200 302 30d; proxy_cache_bypass $http_cache_purge; add_header X-Cached $upstream_cache_status; proxy_cache_lock on; proxy_buffer_size 128k; proxy_buffers 200 128k; resolver 8.8.8.8 valid=300s; resolver_timeout 10s; proxy_pass http://$s3_bucket$uri; } ... } 使用上面的方式对一台Linode 16G服务器进行配置，原来文件均存储在本地，本地磁盘空间使用接近90%，CPU与带宽余量还较大，如果对Linode进行升级，则成本会增加一倍，并且随着内容的增加，不久的未来又会因为磁盘问题需要升级到更高版本；使用上面方案，先将旧附件迁移到AWS S3，可以满足文件持续增长的需求，服务器方面的开销也会跟网站的发展比较同步，不会出现跳跃式的增加。\n","permalink":"https://yplam.com/posts/linux/nginx-aws-proxy/","summary":"\u003cp\u003e对于一些UGC（用户创建内容）类网站而言，特别是图片网站，随着用户数的增长，时间的推移，网站上的文件会越来越多；得益于云服务的出现，存储系统的扩展变得简单，一个比较常用的做法就是将文件存储于AWS S3，然后用户通过S3或者CloudFront下载。然而虽然AWS S3的储存价格相对便宜，但流量价格却非常高，最终导致网站的托管开销增加。\u003c/p\u003e","title":"使用Nginx做AWS S3的反向代理"},{"content":"在Apache环境下使用 .htaccess 进行URL重写或许已经是一种非常常用的方式；然而，如果URL重写规则比较复杂，使用.htaccess的方式可能会影响到Apache的性能。\n测试方式\n一个简单的echo语句，分别进行以下测试：\nallowoverride=none,无rewrite allowoverride=all,无.htaccess allowoverride=all,简单的.htaccess allowoverride=none,简单的rewrite allowoverride=all,复杂的.htaccess allowoverride=none,复杂的rewrite 结果\n先说结果，当rewrite规则比较简单时，性能影响不大，17201 vs 19486。\n当rewrite规则比较复杂，超过900行，有较多正则表达式，跳转（用来做栏目rewrite），性能变化较大 1497 vs 7108\n如果访问的目录路径比较深，在allowoverride开启的情况下，apache需要历遍每一个目录去读取.htaccess，性能的影响理论上会更大，测试数据 15623 vs 17201（7层目录vs根目录）。\n当然，在实际应用场景中，相对PHP跟Mysql而言，Apache的这点性能损失可能不算什么；但是，只需要简单的将rewrite规则从htaccess复制到apache.conf中就可以得到性能的提升，何乐而不为呢？ :)\n测试数据\nallowoverride=none，无rewrite\nConcurrency Level: 10 Time taken for tests: 0.500 seconds Complete requests: 10000 Failed requests: 0 Total transferred: 1880000 bytes HTML transferred: 10000 bytes Requests per second: 20008.88 [#/sec] (mean) Time per request: 0.500 [ms] (mean) Time per request: 0.050 [ms] (mean, across all concurrent requests) Transfer rate: 3673.51 [Kbytes/sec] received allowoverride=all，无.htaccess\nConcurrency Level: 10 Time taken for tests: 0.491 seconds Complete requests: 10000 Failed requests: 0 Total transferred: 1880000 bytes HTML transferred: 10000 bytes Requests per second: 20371.66 [#/sec] (mean) Time per request: 0.491 [ms] (mean) Time per request: 0.049 [ms] (mean, across all concurrent requests) Transfer rate: 3740.11 [Kbytes/sec] received 简单的.htaccess(符合单入口文件类的网站)\nConcurrency Level: 10 Time taken for tests: 0.581 seconds Complete requests: 10000 Failed requests: 0 Total transferred: 1880000 bytes HTML transferred: 10000 bytes Requests per second: 17201.99 [#/sec] (mean) Time per request: 0.581 [ms] (mean) Time per request: 0.058 [ms] (mean, across all concurrent requests) Transfer rate: 3158.18 [Kbytes/sec] received 简单.htaccess，访问 /a/b/c/d/e/f/g/ 路径\nConcurrency Level: 10 Time taken for tests: 0.640 seconds Complete requests: 10000 Failed requests: 0 Total transferred: 1880000 bytes HTML transferred: 10000 bytes Requests per second: 15623.29 [#/sec] (mean) Time per request: 0.640 [ms] (mean) Time per request: 0.064 [ms] (mean, across all concurrent requests) Transfer rate: 2868.34 [Kbytes/sec] received 简单的rewrite规则，写入apache.conf\nConcurrency Level: 10 Time taken for tests: 0.513 seconds Complete requests: 10000 Failed requests: 0 Total transferred: 1880000 bytes HTML transferred: 10000 bytes Requests per second: 19486.15 [#/sec] (mean) Time per request: 0.513 [ms] (mean) Time per request: 0.051 [ms] (mean, across all concurrent requests) Transfer rate: 3577.54 [Kbytes/sec] received 复杂的.htaccess(900行，使用正则表达式对栏目内容进行映射，还有对旧内容的重定向等)\nConcurrency Level: 10 Time taken for tests: 6.677 seconds Complete requests: 10000 Failed requests: 0 Total transferred: 1880000 bytes HTML transferred: 10000 bytes Requests per second: 1497.75 [#/sec] (mean) Time per request: 6.677 [ms] (mean) Time per request: 0.668 [ms] (mean, across all concurrent requests) Transfer rate: 274.98 [Kbytes/sec] received 将规则写入apache.conf，并且禁用allowoverride后：\nConcurrency Level: 10 Time taken for tests: 1.407 seconds Complete requests: 10000 Failed requests: 0 Total transferred: 1880000 bytes HTML transferred: 10000 bytes Requests per second: 7108.94 [#/sec] (mean) Time per request: 1.407 [ms] (mean) Time per request: 0.141 [ms] (mean, across all concurrent requests) Transfer rate: 1305.16 [Kbytes/sec] received ","permalink":"https://yplam.com/posts/linux/apache-htaccess-performance/","summary":"\u003cp\u003e在Apache环境下使用 .htaccess 进行URL重写或许已经是一种非常常用的方式；然而，如果URL重写规则比较复杂，使用.htaccess的方式可能会影响到Apache的性能。\u003c/p\u003e","title":"不能忽略 .htaccess 对性能的影响"},{"content":"最近拿到几块Intel的企业级SSD准备搭建新的服务器，下面分享一些这段时间的测试数据。\n测试主要在DELL R610、阿里云4核非IO优化SSD服务器环境下进行，测试工具为sysbench。\n测试过程主要是使用sysbench命令分别对 SATA、SAS、SSD盘进行测试，其中测试重点在于SSD性能对比。\n结果\n对比显示，RAID0与RAID10的SSD性能最好，当中，家用SSD比商用的也快不少。\nSSD搭建RAID1后性能有部分损失，但不大，162/199；\nSSD组RAID5后性能有明显损失，73/199；\n测试主要命令：\nsysbench --test=fileio --file-total-size=2G prepare sysbench --test=fileio --file-total-size=2G --file-test-mode=rndrw --init-rng=on --max-time=300 --max-requests=0 run sysbench --test=fileio --file-total-size=2G cleanup 下面为测试数据：\n普通sata硬盘\nOperations performed: 148200 Read, 98800 Write, 316059 Other = 563059 Total Read 2.2614Gb Written 1.5076Gb Total transferred 3.7689Gb (12.862Mb/sec) 823.17 Requests/sec executed Test execution summary: total time: 300.0585s total number of events: 247000 total time taken by event execution: 2.2265 per-request statistics: min: 0.01ms avg: 0.01ms max: 0.15ms approx. 95 percentile: 0.01ms Threads fairness: events (avg/stddev): 247000.0000/0.00 execution time (avg/stddev): 2.2265/0.00 SAS盘RAID5\nOperations performed: 213600 Read, 142400 Write, 455562 Other = 811562 Total Read 3.2593Gb Written 2.1729Gb Total transferred 5.4321Gb (18.523Mb/sec) 1185.46 Requests/sec executed Test execution summary: total time: 300.3062s total number of events: 356000 total time taken by event execution: 3.6042 per-request statistics: min: 0.00ms avg: 0.01ms max: 0.74ms approx. 95 percentile: 0.01ms Threads fairness: events (avg/stddev): 356000.0000/0.00 execution time (avg/stddev): 3.6042/0.00 阿里云SSD，非IO优化\nOperations performed: 253860 Read, 169240 Write, 541558 Other = 964658 Total Read 3.8736Gb Written 2.5824Gb Total transferred 6.456Gb (22.036Mb/sec) 1410.33 Requests/sec executed Test execution summary: total time: 300.0010s total number of events: 423100 total time taken by event execution: 3.2958 per-request statistics: min: 0.00ms avg: 0.01ms max: 11.76ms approx. 95 percentile: 0.01ms Threads fairness: events (avg/stddev): 423100.0000/0.00 execution time (avg/stddev): 3.2958/0.00 金士顿普通SSD，RAID0\nOperations performed: 3112380 Read, 2074920 Write, 6639620 Other = 11826920 Total Read 47.491Gb Written 31.661Gb Total transferred 79.152Gb (270.17Mb/sec) 17290.98 Requests/sec executed Test execution summary: total time: 300.0004s total number of events: 5187300 total time taken by event execution: 42.7006 per-request statistics: min: 0.00ms avg: 0.01ms max: 0.12ms approx. 95 percentile: 0.01ms Threads fairness: events (avg/stddev): 5187300.0000/0.00 execution time (avg/stddev): 42.7006/0.00 INTEL企业级SSD，RAID0\nOperations performed: 2292180 Read, 1528120 Write, 4889859 Other = 8710159 Total Read 34.976Gb Written 23.317Gb Total transferred 58.293Gb (198.97Mb/sec) 12734.30 Requests/sec executed Test execution summary: total time: 300.0007s total number of events: 3820300 total time taken by event execution: 16.8218 per-request statistics: min: 0.00ms avg: 0.00ms max: 0.21ms approx. 95 percentile: 0.01ms Threads fairness: events (avg/stddev): 3820300.0000/0.00 execution time (avg/stddev): 16.8218/0.00 INTEL企业级SSD RAID10, 4盘\nOperations performed: 2323620 Read, 1549080 Write, 4956949 Other = 8829649 Total Read 35.456Gb Written 23.637Gb Total transferred 59.093Gb (201.7Mb/sec) 12908.99 Requests/sec executed Test execution summary: total time: 300.0003s total number of events: 3872700 total time taken by event execution: 18.8378 per-request statistics: min: 0.00ms avg: 0.00ms max: 7.08ms approx. 95 percentile: 0.01ms Threads fairness: events (avg/stddev): 3872700.0000/0.00 execution time (avg/stddev): 18.8378/0.00 INTEL企业级SSD，RAID1\nOperations performed: 1868760 Read, 1245840 Write, 3986627 Other = 7101227 Total Read 28.515Gb Written 19.01Gb Total transferred 47.525Gb (162.22Mb/sec) 10381.99 Requests/sec executed Test execution summary: total time: 300.0002s total number of events: 3114600 total time taken by event execution: 14.2077 per-request statistics: min: 0.00ms avg: 0.00ms max: 0.58ms approx. 95 percentile: 0.01ms Threads fairness: events (avg/stddev): 3114600.0000/0.00 execution time (avg/stddev): 14.2077/0.00 INTEL企业级SSD，RAID5,3盘\nOperations performed: 844500 Read, 563000 Write, 1801541 Other = 3209041 Total Read 12.886Gb Written 8.5907Gb Total transferred 21.477Gb (73.307Mb/sec) 4691.66 Requests/sec executed Test execution summary: total time: 300.0006s total number of events: 1407500 total time taken by event execution: 7.8239 per-request statistics: min: 0.00ms avg: 0.01ms max: 0.13ms approx. 95 percentile: 0.01ms Threads fairness: events (avg/stddev): 1407500.0000/0.00 execution time (avg/stddev): 7.8239/0.00 ","permalink":"https://yplam.com/posts/linux/ssd-raid-performance/","summary":"\u003cp\u003e最近拿到几块Intel的企业级SSD准备搭建新的服务器，下面分享一些这段时间的测试数据。\u003c/p\u003e\n\u003cp\u003e测试主要在DELL R610、阿里云4核非IO优化SSD服务器环境下进行，测试工具为sysbench。\u003c/p\u003e\n\u003cp\u003e测试过程主要是使用sysbench命令分别对 SATA、SAS、SSD盘进行测试，其中测试重点在于SSD性能对比。\u003c/p\u003e","title":"服务器SSD以及SSD RAID性能测试"},{"content":"如何能让个人博客显得更有逼格？配置成HTTPS访问是一个不错的选择，下面分享 yplam.com 切换到 HTTPS 的过程。\n环境\nyplam.com 域名注册商为Godaddy，托管商为Linode，使用 debian + nginx + php 的服务器环境\n配置过程\n首先，需要购买个SSL证书，当然这不是免费的，甚至有可能很贵。在这里我们使用Godaddy最便宜的SSL证书，每年四百多，使用优惠码还可以便宜30%。\n购买证书时需要提供csr文件内容，这个可以在服务器提前生成：\nopenssl req -new -newkey rsa:2048 -nodes -keyout yplam.key -out yplam.csr 然后根据你的需求填入信息，其中比较重要的是 Common Name 需要填你证书的域名。\n生成后打开csr文件，将内容拷贝到Godaddy SSL证书申请的输入框中，提交。\n如无意外，付款后就可以进入配置页面（在这过程之间可能需要等待几分钟）\n因为域名也是在Godaddy上注册的，接着不需要做其他配置，只需要等待过程完成。\n完成后Godaddy会让你下载一个zip文件（web服务器类型选其他），将zip上传到服务器，用unzip命令解压出来两个 .crt 文件，其中以 gd_bundle 开头的文件为链式证书，另一个为服务器证书，使用nginx时需要将其合为一个：\ncat e1bb80d***.crt gd_bundle-***.crt \u0026gt; yplam.crt 需要注意的是合并时的顺序是服务器证书在前，否则nginx会报错：\nSSL_CTX_use_PrivateKey_file(\u0026#34; ... /www.example.com.key\u0026#34;) failed (SSL: error:0B080074:x509 certificate routines: X509_check_private_key:key values mismatch) 然后可以配置服务器：\nserver { listen 443 ssl; server_name www.example.com; ssl_certificate www.example.com.chained.crt; ssl_certificate_key www.example.com.key; ... } 配置完成，测试是否正常：\nopenssl s_client -connect www.godaddy.com:443 最后，如果你设置整站HTTPS的话不要忘了在nginx中对旧内容做个跳转：\nserver { listen 80; server_name www.yplam.com yplam.com; return 301 https://yplam.com$request_uri; } 一切配置完成后，可以访问 https://www.ssllabs.com/ssltest/index.html 对服务器的配置情况进行校验，然后根据相关建议选择进行修复\n譬如，在debian 8 下会有 Diffie-Hellman (DH) key 警告，那么可以参考 https://weakdh.org/sysadmin.html 这里的提示进一步进行安全配置。\n参考文档\nhttp://nginx.org/en/docs/http/configuring_https_servers.html\nhttps://www.godaddy.com/help/generating-nginx-csrs-certificate-signing-requests-3601\n","permalink":"https://yplam.com/posts/linux/nginx-https/","summary":"\u003cp\u003e如何能让个人博客显得更有逼格？配置成HTTPS访问是一个不错的选择，下面分享 yplam.com 切换到 HTTPS 的过程。\u003c/p\u003e","title":"为个人博客配置 HTTPS 访问"},{"content":"最近尝试将自己的一些Drupal网站转移到Symfony（这个个人博客就是其中之一），下面分享一些转移过程的心得，主要包括Drupal基本功能在Symfony上的实现。\n用户管理\nFOSUserBundle提供用户登录、注册、找回密码等基本功能，并且提供个可选的Group功能，将用户分组，按组设定权限。\n权限管理\n对于常规路径的权限（类似Drupal的HookMenu），Symfony 可以在security中根据角色权限配置，结合FOSUserBundle的分组功能可以容易搞掂。 对于某个特定内容的CRUD权限，Symfony可以用Voter的方式来设定 管理后台\n使用SonataAdminBundle，只需要简单的编写一个服务，就可以完成常规的CRUD后台，对于特定需求，可以通过extend CRUD Controller的方式完成，而针对非CRUD类的管理后台，可以使用自定义页面。\nHook钩子\nDrupal中钩子可以说是最基础的功能，而Symfony中可以很方便的用Event来实现。\n数据迁移\n对于简单型网站（如这个博客），可以使用 node_export 模块导出XML文件，然后在Symfony下写个Command导入内容。\n用户或者内容结构较为复杂的网站，可以直接写Command，通过分析数据库结构用SQL语句导入内容。\n由于Symfony与Drupal的密码加密方式不一致，我们可以使用自己的PasswordEncoder服务，覆盖 isPasswordValid 方法，对旧密码加密方式做兼容。\n对path的兼容比较麻烦，在此的处理方式是使用一个controller专门做旧内容的跳转。当然，也可以通过监听 NotFoundHttpException 事件来进行处理跳转\n比Drupal更好用的功能\n首先，最明显的就是网站速度变快了，并且Symfony可以有多种方式来管理缓存，优化性能，而Drupal针对登录用户的缓存功能相对较弱。\n针对开发者而言，网站deploy变得非常简单，使用capifony以及doctrine migrations，一条命令可以搞掂。\n网站模板不在是一件痛苦的事情，使用twig基本上可以完美的将一个html模板重现；而Drupal，可能70%以上的时间需要花在模板上。\n更新：现在网站已迁移到github。\n","permalink":"https://yplam.com/posts/symfony/drupal-2-symfony/","summary":"\u003cp\u003e最近尝试将自己的一些Drupal网站转移到Symfony（这个个人博客就是其中之一），下面分享一些转移过程的心得，主要包括Drupal基本功能在Symfony上的实现。\u003c/p\u003e","title":"如何将一个Drupal网站转到Symfony"},{"content":"SonataAdminBundle可以非常简便地实现CRUD页面，然而，如果我们需要在后台中实现与Entity无关的管理页面，应该怎么办呢？下面分享自己在摸索工程中的一个实现方法。\n首先 Google 一番，发现已经有人遇到过这个问题，并且提供了一些解决方法：\nCustom page \u0026amp; controller in Sonata Admin Bundle\nThe page which had not been connect with entity, in SonataAdminBundle\nsonataadminbundle创建一个自定义页面\n然而，上面的方法均有一个特点，就是通过覆写SonataAdminBundle的dashboard模板来将自定义页面的链接加进去。身为一名具有处女座精神的程序猿，这种方法当然不能接受 :)\n查看代码，发现SonataAdminBundle的实现方式也很简单：实现一个Block，然后将Block配置到SonataAdmin中。\n创建Block\n假设我们需要创建一个Block来显示管理页面的链接，那么我们可以添加一个区块服务：\nservices.yml\napp.admin.block.manager_list: class: AppBundle\\Block\\AdminManagerBlockService tags: - { name: sonata.block } arguments: - app.admin.block.manager_list - @templating 在config.yml中配置这个区块：\nsonata_block: default_contexts: [cms] blocks: # Enable the SonataAdminBundle block sonata.admin.block.admin_list: contexts: [admin] app.admin.block.manager_list: contexts: [admin] sonata_admin: title: Admin dashboard: blocks: - position: left type: sonata.admin.block.admin_list - position: top type: app.admin.block.manager_list 实现Block内容输出\nnamespace AppBundle\\Block; use Sonata\\BlockBundle\\Block\\BlockContextInterface; use Symfony\\Component\\HttpFoundation\\Response; use Symfony\\Bundle\\FrameworkBundle\\Templating\\EngineInterface; use Sonata\\AdminBundle\\Form\\FormMapper; use Sonata\\AdminBundle\\Validator\\ErrorElement; use Sonata\\AdminBundle\\Admin\\Pool; use Sonata\\BlockBundle\\Model\\BlockInterface; use Sonata\\BlockBundle\\Block\\BaseBlockService; use Symfony\\Component\\OptionsResolver\\OptionsResolver; use Symfony\\Component\\OptionsResolver\\OptionsResolverInterface; /** * */ class AdminManagerBlockService extends BaseBlockService { /** * @param string $name * @param \\Symfony\\Bundle\\FrameworkBundle\\Templating\\EngineInterface $templating */ public function __construct($name, EngineInterface $templating) { parent::__construct($name, $templating); } /** * {@inheritdoc} */ public function execute(BlockContextInterface $blockContext, Response $response = null) { $settings = $blockContext-\u0026gt;getSettings(); return $this-\u0026gt;renderPrivateResponse(\u0026#39;AppBundle:Block:manager_list.html.twig\u0026#39;, array( \u0026#39;block\u0026#39; =\u0026gt; $blockContext-\u0026gt;getBlock(), \u0026#39;settings\u0026#39; =\u0026gt; $settings, ), $response); } /** * {@inheritdoc} */ public function validateBlock(ErrorElement $errorElement, BlockInterface $block) { // TODO: Implement validateBlock() method. } /** * {@inheritdoc} */ public function buildEditForm(FormMapper $formMapper, BlockInterface $block) { } /** * {@inheritdoc} */ public function getName() { return \u0026#39;Admin Manager\u0026#39;; } /** * {@inheritdoc} */ public function setDefaultSettings(OptionsResolverInterface $resolver) { $resolver-\u0026gt;setDefaults(array( \u0026#39;groups\u0026#39; =\u0026gt; false )); $resolver-\u0026gt;setAllowedTypes(array( \u0026#39;groups\u0026#39; =\u0026gt; array(\u0026#39;bool\u0026#39;, \u0026#39;array\u0026#39;) )); } } 继承SonataAdminBundle的模板\n{% raw %} {% extends sonata_block.templates.block_base %} {% block block %} \u0026lt;div class=\u0026#34;box\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;box-header\u0026#34;\u0026gt; \u0026lt;h3 class=\u0026#34;box-title\u0026#34;\u0026gt;Manager\u0026lt;/h3\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;box-body\u0026#34;\u0026gt; \u0026lt;table class=\u0026#34;table table-hover\u0026#34;\u0026gt; \u0026lt;tbody\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td class=\u0026#34;sonata-ba-list-label\u0026#34; width=\u0026#34;40%\u0026#34;\u0026gt; 统计数据 \u0026lt;/td\u0026gt; \u0026lt;td\u0026gt; \u0026lt;div class=\u0026#34;btn-group\u0026#34;\u0026gt; \u0026lt;a class=\u0026#34;btn btn-link btn-flat\u0026#34; href=\u0026#34;\u0026#34;\u0026gt; \u0026lt;i class=\u0026#34;glyphicon glyphicon-list\u0026#34;\u0026gt;\u0026lt;/i\u0026gt;List \u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/tbody\u0026gt; \u0026lt;/table\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; {% endblock %} {% endraw %} 这样，就可以在SonataAdminBundle的Dashboard页面头部添加自己的管理区块。\n","permalink":"https://yplam.com/posts/symfony/sonata-admin-custom-page/","summary":"\u003cp\u003eSonataAdminBundle可以非常简便地实现CRUD页面，然而，如果我们需要在后台中实现与Entity无关的管理页面，应该怎么办呢？下面分享自己在摸索工程中的一个实现方法。\u003c/p\u003e","title":"SonataAdminBundle创建自定义后台页面"},{"content":"所谓区块，就是在页面中展示的一块内容，可以与当前页面内容相关或者无关。譬如常见的在网站侧边栏展示 “最新文章”区块，或者在文章内容页展示“相关文章”区块。\n对于与当前页面相关的区块，我们可以在页面的控制器中通过查询数据库等方式获取数据，在模板中 渲染；而对于与当前页面内容无关的区块，我们则需要通过其他方式。\nSymfony在处理这些区块时，提供两种种方式：\n(来源：http://symfony.com/doc/current/book/templating.html)\ninclude，用来渲染页面相关内容\n{% raw %} {# app/Resources/views/article/list.html.twig #} {% extends \u0026#39;layout.html.twig\u0026#39; %} {% block body %} \u0026lt;h1\u0026gt;Recent Articles\u0026lt;h1\u0026gt; {% for article in articles %} {{ include(\u0026#39;article/article_details.html.twig\u0026#39;, { \u0026#39;article\u0026#39;: article }) }} {% endfor %} {% endblock %} {% endraw %} render，用来渲染页面无关内容\n{% raw %} {# app/Resources/views/base.html.twig #} {# ... #} \u0026lt;div id=\u0026#34;sidebar\u0026#34;\u0026gt; {{ render(controller( \u0026#39;AcmeArticleBundle:Article:recentArticles\u0026#39;, { \u0026#39;max\u0026#39;: 3 } )) }} \u0026lt;/div\u0026gt; {% endraw %} 然而，由render的运行原理可以看出，它会发送一个子请求，调用子控制器。虽然官方说它很快，但是测试过后发现有很明显的时间消耗。\n使用Twig扩展函数\nTwig扩展函数是另一个很好的输出区块内容的方式（虽然Symfony官方的介绍不多）。\n譬如：\n\u0026lt;?php namespace AppBundle\\Twig\\Extension; use Symfony\\Component\\HttpKernel\\KernelInterface; use JMS\\DiExtraBundle\\Annotation as DI; /** * @DI\\Service(\u0026#34;app.twig.extension\u0026#34;, public=false) * @DI\\Tag(\u0026#34;twig.extension\u0026#34;) */ class AppExtension extends \\Twig_Extension { /** * {@inheritdoc} */ public function getFunctions() { return array( \u0026#39;app_sidemenu\u0026#39; =\u0026gt; new \\Twig_Function_Method($this, \u0026#39;renderSideMenu\u0026#39;, array( \u0026#39;is_safe\u0026#39; =\u0026gt; array(\u0026#39;html\u0026#39;), \u0026#39;needs_environment\u0026#39; =\u0026gt; true, )), ); } /** * 侧边栏信息 */ public function renderSideMenu ( \\Twig_Environment $twig ) { $categories = array(); /* 在此处处理区块逻辑 */ $template = $twig-\u0026gt;loadTemplate(\u0026#39;AppBundle:Common:sideblock.html.twig\u0026#39;); $content = $template-\u0026gt;render(array(\u0026#39;categories\u0026#39; =\u0026gt; $categories)); return $content; } /** * {@inheritdoc} */ public function getName() { return \u0026#39;app_bundle\u0026#39;; } } 上面是一个简单的Twig扩展，其作用就是提供app_sidemenu函数，在页面中显示网站侧边栏分类菜单。 renderSideMenu方法从数据库中获取分类信息，用twig模板渲染成菜单html，然后缓存到redis里。\n需要注意的是 getFunctions 方法中，返回数据的 needs_environment 参数，如果设为true，它会为你的回调函数 传入 \\Twig_Environment $twig，使你在回调函数中方便地进行模板渲染。\n使用 twigExtension 来渲染区块还有个好处就是可以很方便的管理缓存，因为我们可以将render出来的内容存在cache中，这样不同的区块可以有自己的缓存清理逻辑。\n下面我们尝试在扩展中使用Redis来缓存区块内容。\nnamespace AppBundle\\Twig\\Extension; use Symfony\\Component\\HttpKernel\\KernelInterface; use JMS\\DiExtraBundle\\Annotation as DI; /** * @DI\\Service(\u0026#34;app.twig.site.extension\u0026#34;) * @DI\\Tag(\u0026#34;twig.extension\u0026#34;) */ class AppSiteExtension extends \\Twig_Extension { protected $redis; /** * @DI\\InjectParams({ * \u0026#34;redis\u0026#34; = @DI\\Inject(\u0026#34;snc_redis.cache\u0026#34;) * }) */ public function __construct($redis){ $this-\u0026gt;redis = $redis; } /** * {@inheritdoc} */ public function getFunctions() { return array( \u0026#39;app_header\u0026#39; =\u0026gt; new \\Twig_Function_Method($this, \u0026#39;renderHeader\u0026#39;, array( \u0026#39;is_safe\u0026#39; =\u0026gt; array(\u0026#39;html\u0026#39;), \u0026#39;needs_environment\u0026#39; =\u0026gt; true, )), ); } /** * 缓存头部信息，缓存时间 36000s */ public function renderHeader( \\Twig_Environment $twig){ $key = \u0026#39;app:cache:header\u0026#39;; if($content = $this-\u0026gt;redis-\u0026gt;get($key)){ return $content; } $template = $twig-\u0026gt;loadTemplate(\u0026#39;AppBundle:Common:header.html.twig\u0026#39;); $content = $template-\u0026gt;render(array()); $this-\u0026gt;redis-\u0026gt;setex($key, 36000, $content); return $content; } /** * {@inheritdoc} */ public function getName() { return \u0026#39;app_bundle_site\u0026#39;; } } 上面是一个使用redis缓存区块内容的简单应用，跟yii的widget缓存类似（对yii了解不多，错了请指正）。\n我们在扩展的构造函数中注入 $redis 实例，然后将渲染后的网站头部模板内容缓存到rendis中，在下一次访问中直接输出。\nps:在此只是给缓存信息一个定期的过期时间，实际应用场景中对cache的处理可能会更复杂。\n","permalink":"https://yplam.com/posts/symfony/symfony-twig-block/","summary":"\u003cp\u003e所谓区块，就是在页面中展示的一块内容，可以与当前页面内容相关或者无关。譬如常见的在网站侧边栏展示\n“最新文章”区块，或者在文章内容页展示“相关文章”区块。\u003c/p\u003e","title":"使用twigExtension实现页面区块功能"},{"content":"在Symfony官网上有个投票，让用户选出工作中最有用的组件，下面是评选结果：\nFOSUserBundle (60%) 提供用户注册、管理相关的功能，推荐！ FOSRestBundle (30%) Restful Api，推荐！ KnpMenuBundle (25%) 菜单功能，推荐！ StofDoctrineExtensionsBundle (25%) 提供一堆有用的的Doctrine扩展，推荐！ JMSSerializerBundle (24%) 序列化支持，可以与FOSRestBundle一起使用 SonataAdminBundle (24%) 非常好用的一个管理后台组件，极力推荐！ FOSJsRoutingBundle (23%) 将路由信息开放给前端 LiipImagineBundle (22%) 类似Drupal中的Imagecache功能，为图片提供自动的缩放切割功能，推荐！ KnpPaginatorBundle (16%) 提供分页功能，推荐！ NelmioApiDocBundle (11%) 在代码注释中提供文档，可以在线阅读 FOSElasticaBundle (11%) 整合 ElasticSearch HWIOAuthBundle (11%) 提供OAuth登陆功能，国内的新浪、qq等都有提供，并且容易扩展，极力推荐！ VichUploaderBundle (10%) 自动帮你上传文件 RaulFraileLadyBugBundle (9%) 输出调试信息，替代var_dump，类似Drupal的dsm KnpSnappyBundle (8%) 生成pdf或者图片 DoctrineFixturesBundle (8%) Doctrine2 Data Fixtures library. into Symfony so that you can load data fixtures programmatically into the Doctrine ORM or ODM. WhiteOctoberPagerFantaBundle (8%) 分页相关功能 DoctrineMigrationsBundle (8%) 提供Doctrine升级数据库相关的功能 MopaBootstrapBundle (7%) Bootstrap模板相关 JMSSecurityExtraBundle (6%) 扩展Symfony的Securety DoctrineBundle (5%) Doctrine AvalancheImagineBundle (5%) 类Imagecache功能，已经不维护 JMSDiExtraBundle (5%) 扩展Symfony的依赖注入 GenemuFormBundle (4%) 提供一些常用的表单 KnpGaufretteBundle (4%) 文件管理 SncRedisBundle (4%) Redis LexikFormFilterBundle (3%) This Symfony2 bundle aims to provide classes to build a form filter and then build a doctrine query from this form filter. JMSI18nRoutingBundle (3%) This bundle allows you to create i18n routes. LiuggioExcelBundle (3%) This bundle permits you to create, modify and read excel objects. JMSTranslationBundle (3%) This bundle puts the Symfony Translation Component on steroids. 总结：\n作为一名从Drupal转过来的Symfony新手，感觉这个投票结果还是挺熟悉的。其中前10名中有9个组件曾经在自己的项目中用过（除了FOSJsRoutingBundle，可能是因为自己做的都是中规中矩的网站）。\n其中，FOSUserBundle + HWIOAuthBundle + SonataAdminBundle 基本上是项目开展时的标配，提供用户与后台\nKnpMenuBundle、 LiipImagineBundle、 KnpPaginatorBundle、StofDoctrineExtensionsBundle 基本上也是必备模块\n配置好上面这些模块，会发现：咦？一个熟悉的Drupal基础框架就出来了，有了用户、后台、pager、imagecache、菜单，下面就可以完全按你的想法去开发，Cool！\nPS：其实这些功能Drupal基本上都是已经自带有，但虽然使用Drupal可能可以在一两天内搭出一个满足你90%需求的网站（当然，不包括主题），但剩下的10%会成为你漫长的折磨 :)\n","permalink":"https://yplam.com/posts/symfony/symfony-hot-bundles/","summary":"\u003cp\u003e在Symfony官网上有个投票，让用户选出工作中最有用的组件，下面是评选结果：\u003c/p\u003e","title":"30个最常用的Symfony组件"},{"content":"对PHP程序员而言，empty()与isset()肯定不会陌生，甚至是每天都会调用N百遍，正因为如此，我们每个人都认为对它们已经熟悉的不得了，甚至连文档都懒得再翻阅一下，前赴后继的往坑里冲。\n我今天又掉坑里一次了，所以特意又翻阅了一遍文档：\nempty — 检查一个变量是否为空\nbool empty ( mixed $var ) 如果 var 是非空或非零的值，则 empty() 返回 FALSE。换句话说，\u0026quot;\u0026quot;、0、\u0026ldquo;0\u0026rdquo;、NULL、FALSE、array()、var $var; 以及没有任何属性的对象都将被认为是空的，如果 var 为空，则返回 TRUE。\n因为是一个语言构造器而不是一个函数，不能被 可变函数 调用。empty() 只检测变量，检测任何非变量的东西都将导致解析错误。换句话说，后边的语句将不会起作用： empty(addslashes($name))。\nisset — 检测变量是否设置\nbool isset ( mixed $var [, mixed $... ] ) 检测变量是否设置，并且不是 NULL。\n如果已经使用 unset() 释放了一个变量之后，它将不再是 isset()。若使用 isset() 测试一个被设置成 NULL 的变量，将返回 FALSE。同时要注意的是一个 NULL 字节（\u0026quot;\\0\u0026quot;）并不等同于 PHP 的 NULL 常数。\n因为是一个语言构造器而不是一个函数，不能被 可变函数 调用\nPHP 5.4 中empty()与isset()已经发生改变 PHP 5.4 changes how empty() behaves when passed string offsets.\n$expected_array_got_string = \u0026#39;somestring\u0026#39;; var_dump(empty($expected_array_got_string[\u0026#39;some_key\u0026#39;])); var_dump(empty($expected_array_got_string[0])); var_dump(empty($expected_array_got_string[\u0026#39;0\u0026#39;])); var_dump(empty($expected_array_got_string[0.5])); var_dump(empty($expected_array_got_string[\u0026#39;0.5\u0026#39;])); var_dump(empty($expected_array_got_string[\u0026#39;0 Mostel\u0026#39;])); 以上例程在PHP 5.3中的输出：\nbool(false) bool(false) bool(false) bool(false) bool(false) bool(false) 以上例程在PHP 5.4中的输出：\nbool(true) bool(false) bool(false) bool(false) bool(true) bool(true) PHP 5.4 changes how isset() behaves when passed string offsets.\n$expected_array_got_string = \u0026#39;somestring\u0026#39;; var_dump(isset($expected_array_got_string[\u0026#39;some_key\u0026#39;])); var_dump(isset($expected_array_got_string[0])); var_dump(isset($expected_array_got_string[\u0026#39;0\u0026#39;])); var_dump(isset($expected_array_got_string[0.5])); var_dump(isset($expected_array_got_string[\u0026#39;0.5\u0026#39;])); var_dump(isset($expected_array_got_string[\u0026#39;0 Mostel\u0026#39;])); 以上例程在PHP 5.3中的输出：\nbool(true) bool(true) bool(true) bool(true) bool(true) bool(true) 以上例程在PHP 5.4中的输出：\nbool(false) bool(true) bool(true) bool(true) bool(false) bool(false)","permalink":"https://yplam.com/posts/php/php-isset-empty/","summary":"\u003cp\u003e对PHP程序员而言，empty()与isset()肯定不会陌生，甚至是每天都会调用N百遍，正因为如此，我们每个人都认为对它们已经熟悉的不得了，甚至连文档都懒得再翻阅一下，前赴后继的往坑里冲。\u003c/p\u003e","title":"PHP中的empty()与isset()"},{"content":"Discuz论坛内置提供针对移动端开发的json接口，下面根据源码进行一些分析。\n入口 api/mobile/index.php\n功能比较简单，指向source/plugins/mobile/mobile.php 或者check.php，check.php只有当类似$_GET[\u0026lsquo;check\u0026rsquo;] == \u0026lsquo;check\u0026rsquo;的情况下才运行，返回系统基本信息；其他请求均通过mobile.php接管。\nmobile.php\nmobile.php的基本思想是根据$_GET[\u0026lsquo;module\u0026rsquo;]以及$_GET[\u0026lsquo;version\u0026rsquo;]来调用相关的module文件，$_GET[\u0026lsquo;version\u0026rsquo;]参数可以做到版本兼容。\nmobile/api/%version%/%module%.php\n实现相当简单，根据需求设置$_GET[\u0026lsquo;mod\u0026rsquo;]等参数，然后将请求转到Discuz网页版页面，完成请求。同时，文件中定义mobile_api类。\nmobile_api类\nmobile_api类包含两个方法:common与output，common方法对应discuz的runhooks调用；output方法对应discuz的hookscriptoutput调用。\n流程\nDiscuz调用runhooks时，调用mobile_plugin-\u0026gt;common()，调用mobile_api-\u0026gt;common()\nDiscuz在模板中调用hookscriptoutput()时，调用mobile_plugin-\u0026gt;global_mobile()，调用mobile_api-\u0026gt;output()\n总结\nDiscuz大量使用$_G全局变量来保存系统运行过程中的结果，这为移动端内容输出提供便利，只需要在模板输出前截获$_G变量，然后根据需求从$_G变量中提取所需数据，并使用json格式返回。这就是Discuz移动端接口的基本实现方式。\n","permalink":"https://yplam.com/posts/php/discuz-api/","summary":"\u003cp\u003eDiscuz论坛内置提供针对移动端开发的json接口，下面根据源码进行一些分析。\u003c/p\u003e","title":"Discuz移动接口原理简介"},{"content":"原文地址：Services and dependency injection in Drupal 8\nDrupal 8 引入了服务的概念，用来解耦可复用的功能，并且可以通过在服务容器中注册这些服务，让它们可插拔与可替换。身为开发者，最佳的方式就是通过服务容器来访问Drupal提供的所有服务，这样可以保证遵循系统的解耦特性。在Symfony 2的文档中对服务有非常好的介绍。\n对开发者而言，服务用来执行类似访问数据库，发送邮件等操作。我们不使用PHP原生的MySQL函数，而是通过服务容器来使用Drupal提供的核心服务来执行这些操作，这样我们的代码可以很简单的访问数据库，而不需要考虑数据库是MySQL还是SQLite，同样，发邮件时也不需要考虑是通过SMTP还是其他方式。\n核心服务\n核心服务在CoreServiceProvider.php 与 core.services.yml 中定义。如：\n... language_manager: class: Drupal\\Core\\Language\\LanguageManager arguments: [\u0026#39;@language.default\u0026#39;] ... path.alias_manager: class: Drupal\\Core\\Path\\AliasManager arguments: [\u0026#39;@path.crud\u0026#39;, \u0026#39;@path.alias_whitelist\u0026#39;, \u0026#39;@language_manager\u0026#39;] ... string_translation: class: Drupal\\Core\\StringTranslation\\TranslationManager ... breadcrumb: class: Drupal\\Core\\Breadcrumb\\BreadcrumbManager arguments: [\u0026#39;@module_handler\u0026#39;] ... 某个服务可以依赖于其他服务。譬如在上面的例子中，path.alias_manager在arguments参数中指定依赖服务 path.crud， path.alias_whitelist 与 language_manager。可以通过@服务名的方式来定义一个服务的依赖，如@language_manager。当Drupal中的某代码请求path.alias_manager服务时，服务容器会保证path.crud， path.alias_whitelist 与 language_manager 服务可以传递给path.alias_manager的构造函数，因此它会先请求上面的每一个服务。依次地，language_manager依赖于language.default，等等等。\nDrupal包含大量的服务，获取该列表的最好方法是查看CoreServiceProvider.php 与 core.services.yml 文件。\n服务容器（或者叫依赖注入容器）是一个管理服务实例的PHP对象。Drupal的服务容器是在Symfony服务容器的基础上建立的，关于文件结构、特殊字符、可选依赖等相关内容文档可以查看Symfony 2服务容器文档。\n通过依赖注入来访问服务\n在Drupal 8中，依赖注入是访问服务的首选方式，并且应该尽可能的使用。服务通过构造函数参数或者setter方法的方式进行传递，而不是直接调用全局的服务容器。很多由核心模块提供的控制器以及插件类都是使用此方式，并且在运行中被视作是优质资源。\nDrupal全局类用于全局函数中。然而，Drupal 8的控制器、插件等是基于类的。其首先方式是将依赖的服务以构造函数参数的方式进行传递，或者以服务setter方法来注入，而不是调用全局的服务容器。\n将某个对象依赖的服务显式传递，称为依赖注入。在很多情况下，依赖都是通过构造函数进行显式传递。如：路由访问检测在服务创建时插入当前用户，而当前请求对象则在访问检测时传递。你也可以通过setter方法来设置依赖。\n在全局函数中访问服务\nDrupal全局类提供静态方法来访问一些最常用的服务，如：Drupal::moduleHandler()返回模块处理程序服务，Drupal::translation()返回字符串翻译服务。如果你调用的服务没有专用方法，你也可以使用Drupal::service()来获取任何已定义的服务。\n例子：使用专用方法\\Drupal::database()来访问数据库服务\n// Returns a Drupal\\Core\\Database\\Connection object. $connection = \\Drupal::database(); $result = $connection-\u0026gt;select(\u0026#39;node\u0026#39;, \u0026#39;n\u0026#39;) -\u0026gt;fields(\u0026#39;n\u0026#39;, array(\u0026#39;nid\u0026#39;)) -\u0026gt;execute(); 例子：使用通用的\\Drupal::service()方法来访问date服务\n\u0026lt;?php // Returns a Drupal\\Core\\Datetime\\Date object. $date = \\Drupal::service(\u0026#39;date\u0026#39;); ?\u0026gt; 理想情况下，你应该尽量少的使用全局函数，并且重构控制器、事件监听、插件等。适当的方式应该是使用依赖注入；查看下面的文档。\n在Symfony 2的文档中均有代码范例。\n定义你的服务\n你可以使用example.services.yml文件来定义自己的服务，其中example就是你定义服务所在的模块名称。文件的格式与core.services.yml相同。\n有多个子系统需要你定义服务，如：自定义路由访问检测类，自定义参数转换，或者定义一个插件管理器，这都需要将你的类注册为服务。\n也可以使用 $GLOBALS[\u0026lsquo;conf\u0026rsquo;][\u0026lsquo;container_yamls\u0026rsquo;]来增加用于定义服务的YAML文件，只是这样做十分少见。\nDrupal 7全局函数与Drupal 8服务对比\n我们用运行一个模块钩子所需要的代码来对比一下Drupal 7与8的区别。在Drupal中，你会使用module_invoke_all(\u0026lsquo;help\u0026rsquo;)来运行所有hook_help钩子，因为我们是在代码中直接调用module_invoke_all()函数，那么其他人就很难在不改变Drupal核心函数的情况下修改Drupal运行钩子的方式。\n在Drupal 8中，用ModuleHandler代替了module_*函数。因此在Drupal 8中，你应该使用\\Drupal::moduleHandler()-\u0026gt;invokeAll(\u0026lsquo;help\u0026rsquo;)。在这个例子中\\Drupal::moduleHandler()通过服务容器找出已注册的模块处理程序服务，然后调用服务的invokeAll()方法。\n这种机制比Drupal 7的好，因为它允许Drupal 发行版、托管商或者其他模块通过修改注册的模块处理服务类，实现ModuleHandlerInterface接口，来覆写模块运行其他模块钩子的方式。这种修改对于其他部分的Drupal代码而言是透明的。这意味着Drupal的更多部分可以在不修改核心的情况下进行替换。代码的依赖也有更好的文档并且有关的边界也更好的分离。最好，服务可以通过接口进行更加简便的单元测试，而不是整合测试。\n对比Drupal 7全局变量与Drupal 8服务\nDrupal7的一些全局变量，如 global $language 与 global $user 在Drupal 8中也是通过服务进行访问（并且不再是全局变量）。请参考Drupal::languageManager()-\u0026gt;getLanguage(Language::TYPE_INTERFACE) 与 Drupal::currentUser()。\n","permalink":"https://yplam.com/posts/php/drupal-services-and-dependency-injection/","summary":"\u003cp\u003e原文地址：\u003ca href=\"https://www.drupal.org/node/2133171\"\u003eServices and dependency injection in Drupal 8\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eDrupal 8 引入了服务的概念，用来解耦可复用的功能，并且可以通过在服务容器中注册这些服务，让它们可插拔与可替换。身为开发者，最佳的方式就是通过服务容器来访问Drupal提供的所有服务，这样可以保证遵循系统的解耦特性。在\u003ca href=\"http://symfony.com/doc/current/book/service_container.html\"\u003eSymfony 2的文档\u003c/a\u003e中对服务有非常好的介绍。\u003c/p\u003e","title":"Drupal 8服务与依赖注入"},{"content":"Drupal Special Topic 模块提供一种通用并且可定制的 Drupal 专题页面功能。\n这里的专题页面，指的是将网站中与某个话题相关的内容聚合到一个页面中，具有特殊的布局与样式设计。国内常见的专题页面大多以区块的形式展现，不同的位置显示不同的内容列表，有链接与图文混合等展示形式。\n本模块提供Special Topic内容类型，其功能类似于 Panel Node + EntityReference 的相加，用户可以利用Panel的功能来定制页面结构以及各部分显示的内容，又可以在其他Node类型中添加 special_topic field，指定其所属的专题以及在专题中的位置。\n模块提供CTools的content_types插件，通过此方式来将专题相关的内容通过比较简单的方式提取出来，输出标准的content_types。\n同时，模块提供了topic_render插件类型，用户可以通过实现此插件为Special Topic相关的content_types提供theme功能，用不同的形式展现内容。\n模块依赖于ctools与panel。\n模块相关代码请访问 https://github.com/yplam/special_topic\n","permalink":"https://yplam.com/posts/php/drupal-special-topic/","summary":"\u003cp\u003eDrupal Special Topic 模块提供一种通用并且可定制的 Drupal 专题页面功能。\u003c/p\u003e\n\u003cp\u003e这里的专题页面，指的是将网站中与某个话题相关的内容聚合到一个页面中，具有特殊的布局与样式设计。国内常见的专题页面大多以区块的形式展现，不同的位置显示不同的内容列表，有链接与图文混合等展示形式。\u003c/p\u003e","title":"Drupal 专题页面模块"},{"content":"最近在用Drupal做一个微信公众平台后台，决定发扬一下开源精神，将微信部分的module分享出来，给有需要的朋友参考使用。现在还是不稳定版本，有任何建议请反馈 yplam#yplam.com 欢迎关注测试反馈：\ngithub地址 https://github.com/yplam/wechat\n功能\n微信菜单管理 消息事件钩子 设置默认回复信息，包括用户输入与菜单点击 微信登录与用户授权绑定相关的API 配置\n根据需要填入您的公众账号appid，appsecret，token，以及默认回复信息\n菜单管理\n安装模块后会自动生成一个名称为wechat的菜单，可以通过此菜单来配置，配置好后通过模块配置页面来更新菜单。\n消息事件钩子\n当接收到信息后提供 wechat_message，wechat_message_alter两个hook，开发者可以通过实现这两个hook来对特定消息进行响应。\n微信登录与用户授权API\n如果访客在微信中打开网站页面，可以通过调用 wechat_snsapi_base 或者 wechat_snsapi_userinfo 进行微信授权认证，此两个方法均会通过获取微信用户openid，然后自动注册、登录用户，然后将访客以一个已登录的状态跳转到开发者提供的页面，方便开发者在一些web app中进行用户管理。\n","permalink":"https://yplam.com/posts/php/drupal-wechat/","summary":"\u003cp\u003e最近在用Drupal做一个微信公众平台后台，决定发扬一下开源精神，将微信部分的module分享出来，给有需要的朋友参考使用。现在还是不稳定版本，有任何建议请反馈 yplam#yplam.com 欢迎关注测试反馈：\u003c/p\u003e","title":"Drupal微信公众平台模块"},{"content":"Symfony2 文档翻译：http://symfony.com/doc/current/cookbook/doctrine/resolve_target_entity.html\n使用代码包（Bundle）的其中一个目标就是使相互间的依赖更少，这样用户在在其他应用中使用这个功能，而不许要包含不必要的代码。 Doctrine 2.2 中包含了一个新的功能： ResolveTargetEntityListener, 通过此功能你可以拦截Doctrine中的某些调用，在运行时覆写Doctrine 实体（Entity）映射配置中的 targetEntity 参数。这样，在你的代码包中可以使用接口或者抽象类来做实体映射然后在运行时指定正确的 Entity。 这个功能的作用在于你可以通过配置的方式来实现实体见的关系，而不需要在代码包中写死。 背景\n假设你有一个InvoiceBundle，提供与发票相关的功能；一个CustomerBundle，提供用户管理的功能。你希望将这两个代码包分开，这样在其他系统中他们可以独立使用，但是当前的应用需要同时用到这两个功能。 在这种情况下，你可以定义一个Invoice实体，与之关联的是一个不存在的实体：InvoiceSubjectInterface。这样做的目的是可以用一个实现了以上接口的实体ResolveTargetEntityListener 来代替掉InvoiceSubjectInterface。 实现\n下面用一个简单的例子来示范如何实现ResolveTargetEntityListener。 Customer 实体::\n// src/Acme/AppBundle/Entity/Customer.php namespace Acme\\AppBundle\\Entity; use Doctrine\\ORM\\Mapping as ORM; use Acme\\CustomerBundle\\Entity\\Customer as BaseCustomer; use Acme\\InvoiceBundle\\Model\\InvoiceSubjectInterface; /** * @ORM\\Entity * @ORM\\Table(name=\u0026#34;customer\u0026#34;) */ class Customer extends BaseCustomer implements InvoiceSubjectInterface { // In our example, any methods defined in the InvoiceSubjectInterface // are already implemented in the BaseCustomer // 假设 BaseCustomer 已经实现了InvoiceSubjectInterface } Invoice 实体::\n// src/Acme/InvoiceBundle/Entity/Invoice.php namespace Acme\\InvoiceBundle\\Entity; use Doctrine\\ORM\\Mapping AS ORM; use Acme\\InvoiceBundle\\Model\\InvoiceSubjectInterface; /** * Represents an Invoice. * * @ORM\\Entity * @ORM\\Table(name=\u0026#34;invoice\u0026#34;) */ class Invoice { /** * @ORM\\ManyToOne(targetEntity=\u0026#34;Acme\\InvoiceBundle\\Model\\InvoiceSubjectInterface\u0026#34;) * @var InvoiceSubjectInterface */ protected $subject; } InvoiceSubjectInterface 接口::\n// src/Acme/InvoiceBundle/Model/InvoiceSubjectInterface.php namespace Acme\\InvoiceBundle\\Model; /** * An interface that the invoice Subject object should implement. * In most circumstances, only a single object should implement * this interface as the ResolveTargetEntityListener can only * change the target to a single object. * InvoiceSubject需要实现的接口 */ interface InvoiceSubjectInterface { // 接口需要实现的方法 /** * @return string */ public function getName(); } 然后，你需要配置监听器（Listener），配置好替换关系\n# app/config/config.yml doctrine: # .... orm: # .... resolve_target_entities: Acme\\InvoiceBundle\\Model\\InvoiceSubjectInterface: Acme\\AppBundle\\Entity\\Customer 总结\n有了 ResolveTargetEntityListener，代码包间可以更好的解藕。使代码包的功能更加独立，同时又可以通过这种方式来定义不同实体间的关系，使代码包更加容易维护。\n","permalink":"https://yplam.com/posts/symfony/doctrine-resolve-target-entity/","summary":"\u003cp\u003eSymfony2 文档翻译：\u003ca href=\"http://symfony.com/doc/current/cookbook/doctrine/resolve_target_entity.html\"\u003ehttp://symfony.com/doc/current/cookbook/doctrine/resolve_target_entity.html\u003c/a\u003e\u003c/p\u003e","title":"如何通过抽象类与接口来定义关联"},{"content":"这是一篇介绍FOSUserBundle的安装与配置笔记，面向Symfony2.1+，更详细的内容请参考：https://github.com/FriendsOfSymfony/FOSUserBundle/blob/master/Resources/doc/index.md\nSymfony2的安全组件提供了一个具有扩展性的安全机制，允许你从配置文件、数据库或者任何你能想象到的地方加载用户。FOSUserBundle就是基于这种安全机制上建立的，为你提供一个简便的方式来将用户保存在数据库中。\n下载FOSUserBundle\n修改composer.json文件，在require部分增加以下内容：\n\u0026#34;friendsofsymfony/user-bundle\u0026#34;: \u0026#34;~2.0@dev\u0026#34; 使用composer更新\n$ php composer.phar update friendsofsymfony/user-bundle 使能FOSUserBundle\n修改app/AppKernel.php文件，使能FOSUserBundle\n\u0026lt;?php // app/AppKernel.php public function registerBundles() { $bundles = array( // ... new FOS\\UserBundle\\FOSUserBundle(), ); } 创建用户类\n创建一个自己的UserBundle，建立自己的User Entity。这样做有一个好处是以后可以用这个UserBundle来覆写FOSUserBundle。\n\u0026lt;?php // src/Acme/UserBundle/Entity/User.php namespace Acme\\UserBundle\\Entity; use FOS\\UserBundle\\Model\\User as BaseUser; use Doctrine\\ORM\\Mapping as ORM; /** * @ORM\\Entity * @ORM\\Table(name=\u0026#34;fos_user\u0026#34;) */ class User extends BaseUser { /** * @ORM\\Id * @ORM\\Column(type=\u0026#34;integer\u0026#34;) * @ORM\\GeneratedValue(strategy=\u0026#34;AUTO\u0026#34;) */ protected $id; public function __construct() { parent::__construct(); // your own logic } } 配置security.yml\n# app/config/security.yml security: encoders: FOS\\UserBundle\\Model\\UserInterface: sha512 role_hierarchy: ROLE_ADMIN: ROLE_USER ROLE_SUPER_ADMIN: ROLE_ADMIN providers: fos_userbundle: id: fos_user.user_provider.username firewalls: main: pattern: ^/ form_login: provider: fos_userbundle csrf_provider: form.csrf_provider logout: true anonymous: true access_control: - { path: ^/login$, role: IS_AUTHENTICATED_ANONYMOUSLY } - { path: ^/register, role: IS_AUTHENTICATED_ANONYMOUSLY } - { path: ^/resetting, role: IS_AUTHENTICATED_ANONYMOUSLY } - { path: ^/admin/, role: ROLE_ADMIN } 配置FOSUserBundle\n# app/config/config.yml fos_user: db_driver: orm # other valid values are \u0026#39;mongodb\u0026#39;, \u0026#39;couchdb\u0026#39; and \u0026#39;propel\u0026#39; firewall_name: main user_class: Your\\UserBundle\\Entity\\User user_class需要按照自己的需求来设置。\n加载路由配置文件\n# app/config/routing.yml fos_user_security: resource: \u0026#34;@FOSUserBundle/Resources/config/routing/security.xml\u0026#34; fos_user_profile: resource: \u0026#34;@FOSUserBundle/Resources/config/routing/profile.xml\u0026#34; prefix: /profile fos_user_register: resource: \u0026#34;@FOSUserBundle/Resources/config/routing/registration.xml\u0026#34; prefix: /register fos_user_resetting: resource: \u0026#34;@FOSUserBundle/Resources/config/routing/resetting.xml\u0026#34; prefix: /resetting fos_user_change_password: resource: \u0026#34;@FOSUserBundle/Resources/config/routing/change_password.xml\u0026#34; prefix: /profile 需要注意的是，需要配置好SwiftmailerBundle后，重置密码等功能才能正常工作。\n更新数据库\n可以先看看是不是一切正常\n$ php app/console doctrine:schema:update --dump-sql 然后更新数据库\n$ php app/console doctrine:schema:update --force 如无意外，至此FOSUserBundle的功能就已经可以正常功能。可以尝试访问 /login /register 等进行测试。\n","permalink":"https://yplam.com/posts/symfony/symfony-fosuserbundle/","summary":"\u003cp\u003e这是一篇介绍FOSUserBundle的安装与配置笔记，面向Symfony2.1+，更详细的内容请参考：\u003ca href=\"https://github.com/FriendsOfSymfony/FOSUserBundle/blob/master/Resources/doc/index.md\"\u003ehttps://github.com/FriendsOfSymfony/FOSUserBundle/blob/master/Resources/doc/index.md\u003c/a\u003e\u003c/p\u003e","title":"FOSUserBundle 入门"},{"content":"这是一篇关于Symfony2服务容器实现的笔记，原文请查看文章末尾的相关资料部分。\n上一篇笔记介绍了依赖注入容器，依赖注入容器使得对各种系统功能的调用变得简便，但同时引入了一个新的问题就是容器的编写与维护变得非常复杂。Symfony2试图通过ServiceContainer、ServiceContainerBuilder以及xml、yml配置文件来使容器的实现变得简单。\nServiceContainer\n首先，引入sfServiceContainer类http://svn.symfony-project.com/components/dependency_injection/trunk/lib/sfServiceContainer.php，将上一篇笔记中的container作点修改，继承sfServiceContainer：\nclass Container extends sfServiceContainer { static protected $shared = array(); protected function getMailTransportService() { return new Zend_Mail_Transport_Smtp(\u0026#39;smtp.gmail.com\u0026#39;, array( \u0026#39;auth\u0026#39; =\u0026gt; \u0026#39;login\u0026#39;, \u0026#39;username\u0026#39; =\u0026gt; $this[\u0026#39;mailer.username\u0026#39;], \u0026#39;password\u0026#39; =\u0026gt; $this[\u0026#39;mailer.password\u0026#39;], \u0026#39;ssl\u0026#39; =\u0026gt; \u0026#39;ssl\u0026#39;, \u0026#39;port\u0026#39; =\u0026gt; 465, )); } protected function getMailerService() { if (isset(self::$shared[\u0026#39;mailer\u0026#39;])) { return self::$shared[\u0026#39;mailer\u0026#39;]; } $class = $this[\u0026#39;mailer.class\u0026#39;]; $mailer = new $class(); $mailer-\u0026gt;setDefaultTransport($this-\u0026gt;getMailTransportService()); return self::$shared[\u0026#39;mailer\u0026#39;] = $mailer; } } 然后通过这种方式来调用：\nrequire_once \u0026#39;PATH/TO/sf/lib/sfServiceContainerAutoloader.php\u0026#39;; sfServiceContainerAutoloader::register(); $sc = new Container(array( \u0026#39;mailer.username\u0026#39; =\u0026gt; \u0026#39;foo\u0026#39;, \u0026#39;mailer.password\u0026#39; =\u0026gt; \u0026#39;bar\u0026#39;, \u0026#39;mailer.class\u0026#39; =\u0026gt; \u0026#39;Zend_Mail\u0026#39;, )); $mailer = $sc-\u0026gt;mailer; 通过实现__get方法，我们可以通过container对象属性的方式来调用各种服务，可以通过setService对容器进行配置，而需要我们编写的Container类变得更加格式化，都是由一系列get\u0026hellip;Service方法组成。\nServiceContainerBuilder\n因此我们可以通过一个ServiceContainerBuilder对ServiceContainer进行动态配置，sfServiceContainerBuilder: http://svn.symfony-project.com/components/dependency_injection/trunk/lib/sfServiceContainerBuilder.php\nrequire_once \u0026#39;PATH/TO/sf/lib/sfServiceContainerAutoloader.php\u0026#39;; sfServiceContainerAutoloader::register(); $sc = new sfServiceContainerBuilder(); $sc-\u0026gt; register(\u0026#39;mail.transport\u0026#39;, \u0026#39;Zend_Mail_Transport_Smtp\u0026#39;)-\u0026gt; addArgument(\u0026#39;smtp.gmail.com\u0026#39;)-\u0026gt; addArgument(array( \u0026#39;auth\u0026#39; =\u0026gt; \u0026#39;login\u0026#39;, \u0026#39;username\u0026#39; =\u0026gt; \u0026#39;%mailer.username%\u0026#39;, \u0026#39;password\u0026#39; =\u0026gt; \u0026#39;%mailer.password%\u0026#39;, \u0026#39;ssl\u0026#39; =\u0026gt; \u0026#39;ssl\u0026#39;, \u0026#39;port\u0026#39; =\u0026gt; 465, ))-\u0026gt; setShared(false) ; $sc-\u0026gt; register(\u0026#39;mailer\u0026#39;, \u0026#39;%mailer.class%\u0026#39;)-\u0026gt; addMethodCall(\u0026#39;setDefaultTransport\u0026#39;, array(new sfServiceReference(\u0026#39;mail.transport\u0026#39;))) sfServiceContainerBuilder通过register函数来创建一个service，传入service的id以及对应的类，再通过addArgument传入将类实例化时传给构造函数的参数，通过addMethodCall来设置对象创建后调用的初始化函数，通过setShared来指定service是否全局共享。 sfServiceContainerBuilder继承自sfServiceContainer，覆写了getService方法，使得既可以调用静态设置的service，也可以使用动态添加的service。\n使用配置文件来描述Service\n既然service可以通过php动态添加，那么是否可以通过读取配置文件来动态生成呢？答案是肯定的。Symfony提供 sfServiceContainerLoader*** 类，通过读取配置文件，将配置文件转换成 sfServiceDefinition 并且对其进行配置，然后通过containerbuilder的setServiceDefinition方法来添加service，实现方式可以参考 http://svn.symfony-project.com/components/dependency_injection/trunk/lib/sfServiceContainerLoader.php 以及相关loader 的类。\n使用缓存提升性能\n使用配置文件来描述service非常强大而灵活，但会引入一个问题，如果每次运行都要读取配置文件，动态生成service，导致性能问题，而使用PHP代码扩展sfServiceContainer类则可以获得最大的性能优化。 Symfony除了有sfServiceContainerLoader来加载service以外，还可以通过sfServiceContainerDumper来将service的写入到文件中，譬如 sfServiceContainerDumperXml 可以生成上面的使用的配置文件，而sfServiceContainerDumperPhp则可以将service生成一个sfServiceContainer子类的代码。 通过这种方式，Symfony2可以将配置文件的灵活与PHP代码的性能很好的结合起来。\nSymfony2中的实现\n在Symfony2启动流程分析中，有以下的代码段：\n$container = $this-\u0026gt;buildContainer(); $container-\u0026gt;compile(); $this-\u0026gt;dumpContainer($cache, $container, $class, $this-\u0026gt;getContainerBaseClass()); 这就是Symfony对container的实现。\n相关资料：\nhttp://svn.symfony-project.com/components/dependency_injection/trunk/lib/\nhttp://fabien.potencier.org/article/13/introduction-to-the-symfony-service-container\nhttp://fabien.potencier.org/article/14/symfony-service-container-using-a-builder-to-create-services\nhttp://fabien.potencier.org/article/15/symfony-service-container-using-xml-or-yaml-to-describe-services\nhttp://fabien.potencier.org/article/16/symfony-service-container-the-need-for-speed\n","permalink":"https://yplam.com/posts/symfony/symfony-service-container/","summary":"\u003cp\u003e这是一篇关于Symfony2服务容器实现的笔记，原文请查看文章末尾的相关资料部分。\u003c/p\u003e\n\u003cp\u003e上一篇笔记介绍了依赖注入容器，依赖注入容器使得对各种系统功能的调用变得简便，但同时引入了一个新的问题就是容器的编写与维护变得非常复杂。Symfony2试图通过ServiceContainer、ServiceContainerBuilder以及xml、yml配置文件来使容器的实现变得简单。\u003c/p\u003e","title":"Symfony服务容器 ( Symfony Service Container )"},{"content":"这是一篇关于Symfony依赖注入容器 Dependency Injection Container 的笔记，原文地址：http://fabien.potencier.org/article/12/do-you-need-a-dependency-injection-container\n上一篇文章介绍过依赖注入，通过一种非常简单的方式很好的降低了类之间的耦合。但是当业务中使用的类原来越多，譬如在很多地方都需要用到User，每次创建User时都需要记住传递给User的每个参数，这是不可能的，因此就需要用到依赖注入容器。 A Dependency Injection Container is an object that knows how to instantiate and configure objects. And to be able to do its job, it needs to knows about the constructor arguments and the relationships between the objects. 依赖注入容器的作用就是初始化与配置各类对象，管理对象间的依赖关系。下面是一个简单的实现：\nclass Container { public function getMailTransport() { return new Zend_Mail_Transport_Smtp(\u0026#39;smtp.gmail.com\u0026#39;, array( \u0026#39;auth\u0026#39; =\u0026gt; \u0026#39;login\u0026#39;, \u0026#39;username\u0026#39; =\u0026gt; \u0026#39;foo\u0026#39;, \u0026#39;password\u0026#39; =\u0026gt; \u0026#39;bar\u0026#39;, \u0026#39;ssl\u0026#39; =\u0026gt; \u0026#39;ssl\u0026#39;, \u0026#39;port\u0026#39; =\u0026gt; 465, )); } public function getMailer() { $mailer = new Zend_Mail(); $mailer-\u0026gt;setDefaultTransport($this-\u0026gt;getMailTransport()); return $mailer; } } 使用起来也很简便：\n$container = new Container(); $mailer = $container-\u0026gt;getMailer(); 这样，系统的所有功能都是通过container来统一管理。为了是container更加实用，需要添加一些配置参数：\nclass Container { protected $parameters = array(); public function __construct(array $parameters = array()) { $this-\u0026gt;parameters = $parameters; } public function getMailTransport() { return new Zend_Mail_Transport_Smtp(\u0026#39;smtp.gmail.com\u0026#39;, array( \u0026#39;auth\u0026#39; =\u0026gt; \u0026#39;login\u0026#39;, \u0026#39;username\u0026#39; =\u0026gt; $this-\u0026gt;parameters[\u0026#39;mailer.username\u0026#39;], \u0026#39;password\u0026#39; =\u0026gt; $this-\u0026gt;parameters[\u0026#39;mailer.password\u0026#39;], \u0026#39;ssl\u0026#39; =\u0026gt; \u0026#39;ssl\u0026#39;, \u0026#39;port\u0026#39; =\u0026gt; 465, )); } public function getMailer() { $mailer = new Zend_Mail(); $mailer-\u0026gt;setDefaultTransport($this-\u0026gt;getMailTransport()); return $mailer; } } 然后这样初始化：\n$container = new Container(array( \u0026#39;mailer.username\u0026#39; =\u0026gt; \u0026#39;foo\u0026#39;, \u0026#39;mailer.password\u0026#39; =\u0026gt; \u0026#39;bar\u0026#39;, )); $mailer = $container-\u0026gt;getMailer(); 为了不用每次使用某个功能时都新建一个对象，再对container进行一些改进：\nclass Container { static protected $shared = array(); // ... public function getMailer() { if (isset(self::$shared[\u0026#39;mailer\u0026#39;])) { return self::$shared[\u0026#39;mailer\u0026#39;]; } $class = $this-\u0026gt;parameters[\u0026#39;mailer.class\u0026#39;]; $mailer = new $class(); $mailer-\u0026gt;setDefaultTransport($this-\u0026gt;getMailTransport()); return self::$shared[\u0026#39;mailer\u0026#39;] = $mailer; } } 使用依赖注入容器后，对系统功能的初始化与调用变得非常简单，但同时很明显的，当系统变得庞大后，创建与维护Contianer类将是一个噩梦，因此Symfony2提供了一个ContainerBuilder类，根据用户的配置自动生成Container类的代码。\n参考资料：\nhttp://fabien.potencier.org/article/12/do-you-need-a-dependency-injection-container\n","permalink":"https://yplam.com/posts/symfony/dependency-injection-container/","summary":"\u003cp\u003e这是一篇关于Symfony依赖注入容器 Dependency Injection Container 的笔记，原文地址：\u003ca href=\"http://fabien.potencier.org/article/12/do-you-need-a-dependency-injection-container\"\u003ehttp://fabien.potencier.org/article/12/do-you-need-a-dependency-injection-container\u003c/a\u003e\u003c/p\u003e","title":"依赖注入容器（Dependency Injection Container）"},{"content":"这是一篇关于Symfony依赖注入（Dependency Injection）的笔记，原文地址：http://fabien.potencier.org/article/11/what-is-dependency-injection\n假设需要实现下面的需求：编写一个User类，需要实现Session的相关操作 下面是一种简单的实现方式：\nclass SessionStorage { function __construct($cookieName = \u0026#39;PHP_SESS_ID\u0026#39;) { session_name($cookieName); session_start(); } function set($key, $value) { $_SESSION[$key] = $value; } function get($key) { return $_SESSION[$key]; } // ... } class User { protected $storage; function __construct() { $this-\u0026gt;storage = new SessionStorage(); } function setLanguage($language) { $this-\u0026gt;storage-\u0026gt;set(\u0026#39;language\u0026#39;, $language); } function getLanguage() { return $this-\u0026gt;storage-\u0026gt;get(\u0026#39;language\u0026#39;); } // ... } 我们可以这样调用上面的代码：\n$user = new User(); $user-\u0026gt;setLanguage(\u0026#39;fr\u0026#39;); $user_language = $user-\u0026gt;getLanguage(); 但这里有一个问题：代码中将User的storage属性写死了，第三方调用User时无法对storage进行配置。因此，对User代码进行下面的修改：\nclass User { function __construct($storage) { $this-\u0026gt;storage = $storage; } // ... } 不在User类中创建SessionStorage对象，而是将storage对象作为参数传递给User的构造函数，这就是依赖注入。 \u0026ldquo;Dependency Injection is where components are given their dependencies through their constructors, methods, or directly into fields.\u0026rdquo; 上面就是依赖注入的定义，根据其定义，依赖注入可以通过下面三种方式进行：\n构造器注入 Constructor Injection：\nclass User { function __construct($storage) { $this-\u0026gt;storage = $storage; } // ... } 设值注入 Setter Injection：\nclass User { function setSessionStorage($storage) { $this-\u0026gt;storage = $storage; } // ... } 属性 Property Injection：\nclass User { public $sessionStorage; } $user-\u0026gt;sessionStorage = $storage; 相关资料：\nhttp://fabien.potencier.org/article/11/what-is-dependency-injection\nhttp://www.martinfowler.com/articles/injection.html\nhttp://www.cnblogs.com/xingyukun/archive/2007/10/20/931331.html\n","permalink":"https://yplam.com/posts/symfony/dependency-injection/","summary":"\u003cp\u003e这是一篇关于Symfony依赖注入（Dependency Injection）的笔记，原文地址：\u003ca href=\"http://fabien.potencier.org/article/11/what-is-dependency-injection\"\u003ehttp://fabien.potencier.org/article/11/what-is-dependency-injection\u003c/a\u003e\u003c/p\u003e","title":"依赖注入 ( Dependency Injection )"},{"content":"Symfony2 启动流程分析\n入口文件app.php\n\u0026lt;?php use Symfony\\Component\\ClassLoader\\ApcClassLoader; use Symfony\\Component\\HttpFoundation\\Request; $loader = require_once __DIR__.\u0026#39;/../app/bootstrap.php.cache\u0026#39;; // Use APC for autoloading to improve performance. // Change \u0026#39;sf2\u0026#39; to a unique prefix in order to prevent cache key conflicts // with other applications also using APC. /* $loader = new ApcClassLoader(\u0026#39;sf2\u0026#39;, $loader); $loader-\u0026gt;register(true); */ require_once __DIR__.\u0026#39;/../app/AppKernel.php\u0026#39;; //require_once __DIR__.\u0026#39;/../app/AppCache.php\u0026#39;; $kernel = new AppKernel(\u0026#39;prod\u0026#39;, false); $kernel-\u0026gt;loadClassCache(); //$kernel = new AppCache($kernel); Request::enableHttpMethodParameterOverride(); $request = Request::createFromGlobals(); $response = $kernel-\u0026gt;handle($request); $response-\u0026gt;send(); $kernel-\u0026gt;terminate($request, $response); 入口文件app_dev.php\n\u0026lt;?php use Symfony\\Component\\HttpFoundation\\Request; use Symfony\\Component\\Debug\\Debug; // If you don\u0026#39;t want to setup permissions the proper way, just uncomment the following PHP line // read http://symfony.com/doc/current/book/installation.html#configuration-and-setup for more information //umask(0000); // This check prevents access to debug front controllers that are deployed by accident to production servers. // Feel free to remove this, extend it, or make something more sophisticated. if (isset($_SERVER[\u0026#39;HTTP_CLIENT_IP\u0026#39;]) || isset($_SERVER[\u0026#39;HTTP_X_FORWARDED_FOR\u0026#39;]) || !in_array(@$_SERVER[\u0026#39;REMOTE_ADDR\u0026#39;], array(\u0026#39;127.0.0.1\u0026#39;, \u0026#39;fe80::1\u0026#39;, \u0026#39;::1\u0026#39;)) ) { header(\u0026#39;HTTP/1.0 403 Forbidden\u0026#39;); exit(\u0026#39;You are not allowed to access this file. Check \u0026#39;.basename(__FILE__).\u0026#39; for more information.\u0026#39;); } $loader = require_once __DIR__.\u0026#39;/../app/bootstrap.php.cache\u0026#39;; Debug::enable(); require_once __DIR__.\u0026#39;/../app/AppKernel.php\u0026#39;; $kernel = new AppKernel(\u0026#39;dev\u0026#39;, true); $kernel-\u0026gt;loadClassCache(); Request::enableHttpMethodParameterOverride(); $request = Request::createFromGlobals(); $response = $kernel-\u0026gt;handle($request); $response-\u0026gt;send(); $kernel-\u0026gt;terminate($request, $response); app_dev.php相对于app.php的主要区别在于 environment 与 debug 参数。\napp/bootstrap.php.cache：\nbootstrap.php.cache 在运行composer update或者composer install 的时候由脚本生成，主要的功能是将Symfony中必须要用到的核心类打包到单个文件中，同时提供classloader。\napp/AppKernel.php\n扩展自Kernel类，对系统进行配置。创建AppKernel的时候会传入environment 与 debug 参数，environment参数会影响配置文件路径，缓存文件路径，debug参数会影响到缓存文件路径以及系统对cache的处理。\n\u0026lt;?php use Symfony\\Component\\HttpKernel\\Kernel; use Symfony\\Component\\Config\\Loader\\LoaderInterface; class AppKernel extends Kernel { public function registerBundles() { $bundles = array( new Symfony\\Bundle\\FrameworkBundle\\FrameworkBundle(), new Symfony\\Bundle\\SecurityBundle\\SecurityBundle(), new Symfony\\Bundle\\TwigBundle\\TwigBundle(), new Symfony\\Bundle\\MonologBundle\\MonologBundle(), new Symfony\\Bundle\\SwiftmailerBundle\\SwiftmailerBundle(), new Symfony\\Bundle\\AsseticBundle\\AsseticBundle(), new Doctrine\\Bundle\\DoctrineBundle\\DoctrineBundle(), new Sensio\\Bundle\\FrameworkExtraBundle\\SensioFrameworkExtraBundle(), ); if (in_array($this-\u0026gt;getEnvironment(), array(\u0026#39;dev\u0026#39;, \u0026#39;test\u0026#39;))) { $bundles[] = new Acme\\DemoBundle\\AcmeDemoBundle(); $bundles[] = new Symfony\\Bundle\\WebProfilerBundle\\WebProfilerBundle(); $bundles[] = new Sensio\\Bundle\\DistributionBundle\\SensioDistributionBundle(); $bundles[] = new Sensio\\Bundle\\GeneratorBundle\\SensioGeneratorBundle(); } return $bundles; } public function registerContainerConfiguration(LoaderInterface $loader) { $loader-\u0026gt;load(__DIR__.\u0026#39;/config/config_\u0026#39;.$this-\u0026gt;getEnvironment().\u0026#39;.yml\u0026#39;); } } $kernel-\u0026gt;loadClassCache();\n做一个需要加载cache的标记，但不会进行加载工作。\nRequest::enableHttpMethodParameterOverride()\n是否允许通过发送的参数来修改请求的方法，只对POST有效。\n$request = Request::createFromGlobals();\n创建request对象，通过获取$_GET,$_POST等数据，创建request对象。\n$response = $kernel-\u0026gt;handle($request);\n处理请求。symfony内核在此处启动。\npublic function handle(Request $request, $type = HttpKernelInterface::MASTER_REQUEST, $catch = true) { if (false === $this-\u0026gt;booted) { $this-\u0026gt;boot(); } return $this-\u0026gt;getHttpKernel()-\u0026gt;handle($request, $type, $catch); } boot方法启动内核，进行初始化配置\npublic function boot() { if (true === $this-\u0026gt;booted) { return; } if ($this-\u0026gt;loadClassCache) { $this-\u0026gt;doLoadClassCache($this-\u0026gt;loadClassCache[0], $this-\u0026gt;loadClassCache[1]); } // init bundles $this-\u0026gt;initializeBundles(); // init container $this-\u0026gt;initializeContainer(); foreach ($this-\u0026gt;getBundles() as $bundle) { $bundle-\u0026gt;setContainer($this-\u0026gt;container); $bundle-\u0026gt;boot(); } $this-\u0026gt;booted = true; } doLoadClassCache会根据前面loadClassCache的调用，将加载cache目录下的classes.php，如果缓存不存在，则根据classes.map文件来生成。如果debug=true则还会检测每个classes对应原文件的修改时间来判断是否需要重新生成。 初始化bundle，主要是处理bundle的继承关系\n/** * Initializes the data structures related to the bundle management. * * - the bundles property maps a bundle name to the bundle instance, * - the bundleMap property maps a bundle name to the bundle inheritance hierarchy (most derived bundle first). * * @throws \\LogicException if two bundles share a common name * @throws \\LogicException if a bundle tries to extend a non-registered bundle * @throws \\LogicException if a bundle tries to extend itself * @throws \\LogicException if two bundles extend the same ancestor */ protected function initializeBundles() { // init bundles $this-\u0026gt;bundles = array(); $topMostBundles = array(); $directChildren = array(); foreach ($this-\u0026gt;registerBundles() as $bundle) { $name = $bundle-\u0026gt;getName(); if (isset($this-\u0026gt;bundles[$name])) { throw new \\LogicException(sprintf(\u0026#39;Trying to register two bundles with the same name \u0026#34;%s\u0026#34;\u0026#39;, $name)); } $this-\u0026gt;bundles[$name] = $bundle; if ($parentName = $bundle-\u0026gt;getParent()) { if (isset($directChildren[$parentName])) { throw new \\LogicException(sprintf(\u0026#39;Bundle \u0026#34;%s\u0026#34; is directly extended by two bundles \u0026#34;%s\u0026#34; and \u0026#34;%s\u0026#34;.\u0026#39;, $parentName, $name, $directChildren[$parentName])); } if ($parentName == $name) { throw new \\LogicException(sprintf(\u0026#39;Bundle \u0026#34;%s\u0026#34; can not extend itself.\u0026#39;, $name)); } $directChildren[$parentName] = $name; } else { $topMostBundles[$name] = $bundle; } } // look for orphans if (count($diff = array_values(array_diff(array_keys($directChildren), array_keys($this-\u0026gt;bundles))))) { throw new \\LogicException(sprintf(\u0026#39;Bundle \u0026#34;%s\u0026#34; extends bundle \u0026#34;%s\u0026#34;, which is not registered.\u0026#39;, $directChildren[$diff[0]], $diff[0])); } // inheritance $this-\u0026gt;bundleMap = array(); foreach ($topMostBundles as $name =\u0026gt; $bundle) { $bundleMap = array($bundle); $hierarchy = array($name); while (isset($directChildren[$name])) { $name = $directChildren[$name]; array_unshift($bundleMap, $this-\u0026gt;bundles[$name]); $hierarchy[] = $name; } foreach ($hierarchy as $bundle) { $this-\u0026gt;bundleMap[$bundle] = $bundleMap; array_pop($bundleMap); } } } 初始化container，为symfony的核心，原理与实现方式请参考下面的文章。基本流程为：如果container缓存存在，则直接使用缓存，如果不存在则创建container，获取每个bundle与container相关的信息，加载配置文件，配置每个bundle，打包生成缓存。 Introduction to the Symfony Service Container Dependency Injection /** * Initializes the service container. * * The cached version of the service container is used when fresh, otherwise the * container is built. */ protected function initializeContainer() { $class = $this-\u0026gt;getContainerClass(); $cache = new ConfigCache($this-\u0026gt;getCacheDir().\u0026#39;/\u0026#39;.$class.\u0026#39;.php\u0026#39;, $this-\u0026gt;debug); $fresh = true; if (!$cache-\u0026gt;isFresh()) { $container = $this-\u0026gt;buildContainer(); $container-\u0026gt;compile(); $this-\u0026gt;dumpContainer($cache, $container, $class, $this-\u0026gt;getContainerBaseClass()); $fresh = false; } require_once $cache; $this-\u0026gt;container = new $class(); $this-\u0026gt;container-\u0026gt;set(\u0026#39;kernel\u0026#39;, $this); if (!$fresh \u0026amp;\u0026amp; $this-\u0026gt;container-\u0026gt;has(\u0026#39;cache_warmer\u0026#39;)) { $this-\u0026gt;container-\u0026gt;get(\u0026#39;cache_warmer\u0026#39;)-\u0026gt;warmUp($this-\u0026gt;container-\u0026gt;getParameter(\u0026#39;kernel.cache_dir\u0026#39;)); } } getHttpKernel()-\u0026gt;handle()，此时可以通过contianer来获取http_kernel服务对请求进行处理。 $response-\u0026gt;send(); 发送内容 $kernel-\u0026gt;terminate($request, $response); 结束 ","permalink":"https://yplam.com/posts/symfony/symfony-bootstrap/","summary":"\u003cp\u003eSymfony2 启动流程分析\u003c/p\u003e","title":"Symfony2 启动流程分析"},{"content":"以前一直使用Drupal来搭建网站，由于需要定制的代码量不是很大，所以每次修改都是直接用sftp传到服务器，再到Drupal后台清一下缓存。最近使用Symfony2进行开发，到了发布环节遇到了问题。Symfony代码的发布并不像其他CMS那么方便，因为更新代码后还需要assetic:dump，assets:install，cache:clear等一系列操作，因此每次更新往往需要登录到服务器去更新代码，运行清理cache的一系列命令。 capifony是针对Symfony开发的应用部署脚本，基于Capistrano。使用capifony只需要进行简单的配置，就可以很方便的将代码部署到不同的服务器上。\n安装\ngem install capifony 设置项目\n在项目中生成初始化配置\ncd path/to/your/project capifony . 这会在你的项目根目录中生成一个Capfile文件，在config/（Symfony 1.x）或者app/config/(Symfony 2)目录中生成deploy.rb配置文件。\n配置\n首先，你需要选择你的发布方式，然后将你的服务器的连接信息填到config/deploy.rb (或者 app/config/deploy.rb)。\na) deployment → scm → production\n第一种方式是通过git库来发布到产线，在这种情况下，产线服务器必须可以访问到git库并且可以运行pull；你还必须可以在发布服务器上通过ssh访问产线服务器。\n# deploy.rb set :application, \u0026#34;My App\u0026#34; set :deploy_to, \u0026#34;/var/www/my-app.com\u0026#34; set :domain, \u0026#34;my-app.com\u0026#34; set :scm, :git set :repository, \u0026#34;ssh-gitrepo-domain.com:/path/to/repo.git\u0026#34; role :web, domain role :app, domain, :primary =\u0026gt; true set :use_sudo, false set :keep_releases, 3 在这种情况下，运行 cap deploy, capifony 会进行以下步骤:\nssh 登录产线服务器 (my-app.com) 创建一个新的版本目录 (/var/www/my-app.com/releases/\u0026hellip;) 从git版本库 clone 最新的项目版本 (ssh-gitrepo-domain.com) 复制代码。pull git 版本到新版本目录 运行发布钩子(cache:warmup, cc, 等。) 注意：默认情况下 capifony 不会清除旧版本，你必须设置 keep_releases 参数，并且在 deploy.rb 中添加任务来使其运行，如： after \u0026ldquo;deploy\u0026rdquo;, \u0026ldquo;deploy:cleanup\u0026rdquo; 。\n如果你不想每次都 clone 整个版本库，你可以设置 :deploy_via 参数：\nset :deploy_via, :remote_cache 这样，服务端会保存一个git版本库，而 Capifony 只会 fetch 上一次发布以来的修改。\nb) deployment → production (通过复制)\n第二种方式通过复制开发机到产线来发布。这种情况下，开发机（可能是你的本地电脑）需要有访问git版本库的权限，并且可以执行pull操作。\n由于产线服务器也需要安装vendors，因此如果你的vendors使用远程的私有源，那么产线服务器也必须拥有这些源的pull权限，否则 composer 或者 bin/vendors 安装时会失败。如果你想在发布前在本地安装 vendors ，请参考下面的手册：Install vendors locally before deploy。\n使用此方式时发布服务器也必须可以 ssh 访问产线服务器：\n# deploy.rb set :application, \u0026#34;My App\u0026#34; set :deploy_to, \u0026#34;/var/www/my-app.com\u0026#34; set :domain, \u0026#34;my-app.com\u0026#34; set :scm, :git set :repository, \u0026#34;file:///Users/deployer/sites/my-app\u0026#34; set :deploy_via, :copy role :web, domain role :app, domain, :primary =\u0026gt; true set :use_sudo, false set :keep_releases, 3 在这种情况下，运行 cap deploy, capifony 会进行以下步骤:\nssh 登录产线服务器 (my-app.com) 创建一个新的版本目录 (/var/www/my-app.com/releases/\u0026hellip;) 从本地git版本库 clone 最新的项目版本 复制代码。pull git 版本到产线服务器 运行发布钩子(cache:warmup, cc, 等。) 当然，每次发布都要复制整个项目，是昂贵而且缓慢的，幸好你可以通过 capistrano_rsync_with_remote_cache gem 来优化流程:\ngem install capistrano_rsync_with_remote_cache 然后，在 deploy.rb 中修改发布流程:\nset :deploy_via, :rsync_with_remote_cache 这样，rsync会在你的产线服务器上生成缓存，并且只提交两次发布简修改的文件。\n4. 配置服务器\n现在你可以开始发布了！cd 到你的本地项目目录，运行下面命令来使产线服务器设置好 Capistrano 要求的目录结构：\ncap deploy:setup ( 你只需要运行这个命令一次 )\n此命令会在你的服务器上创建类似的目录结构。详细的结构会根据你发布的是 symfony 1.x 还是 symfony 2 而有所不同：\n`-- /var/www/my-app.com |-- current → /var/www/my-app.com/releases/20100512131539 |-- releases | `-- 20100512131539 | `-- 20100509150741 | `-- 20100509145325 `-- shared |-- web | `-- uploads |-- log `-- config `-- databases.yml release 目录下的是实际的发布代码，以时间戳来命名。以 symfony 1.x 为例，Capistrano 链接 app 中的 log 与 web/uploads 目录到一个共享目录，这样你发布一个新版本后这些内容不会被清除。\n你可以使用以下命令来快速设置一个新服务器：\ncap HOSTS=new.server.com deploy:setup 5. 发布\n运行下面命令来发布：\ncap deploy 根据配置的不同，你可能需要 ssh 登录到你的服务器来进行一些附加的配置，在第一次发布后共享文件（如 app/config/parameters.yml，如果你是使用下面的方式来发布 Symfony2 的话）。\nSomething went wrong??? cap deploy:rollback Symfony2 发布\n如果你需要发布 Symfony2 应用，那么此部分内容是为你而设的。本节介绍如何配置 capifony 来发布一个使用 bin/vendors 来管理 vendor 库，并且使用 app/config/parameters.yml 来进行服务器相关配置（如数据库连接信息）的应用。\n首先，在 app/config/deploy.rb 添加以下内容，设置 parameters.yml 在不同的发布版本简时共享的：\nset :shared_files, [\u0026#34;app/config/parameters.yml\u0026#34;] 然后，在不同发布简共享 vendor 目录，这样发布起来会快一点：\nset :shared_children, [app_path + \u0026#34;/logs\u0026#34;, web_path + \u0026#34;/uploads\u0026#34;, \u0026#34;vendor\u0026#34;] capifony 默认情况下依赖于 bin/verdors 来安装第三方库。然而现在默认的依赖管理工具时 Composer，你可以使用下面的配置来使用： set :use_composer, true\n如果你想升级第三方包，请配置以下参数:\nset :update_vendors, true 这样它会运行 composer.phar（如果你使用Composer） 或者 bin/vendors。需要注意的时 bin/vendors 可以通过配置 :vendors_mode 参数来指定运行哪个操作(upgrade, install, 或者 reinstall)。\n最后一步时配置你的 app/config/parameters.yml 文件。最好的方式是手动在服务器的共享目录中创建：\nssh your_deploy_server mkdir -p /var/www/my-app.com/shared/app/config vim /var/www/my-app.com/shared/app/config/parameters.yml parameters.yml文件正确配置后，你应该可以测试你发布的应用。每次新的发布后，同一个 app/config/parameters.yml 会链接到你的应用，因此你只需要在初次发布时配置它。\n有用的任务\n如果你需要发布并且运行迁移命令，运行：\ncap deploy:migrations 运行以下命令，在产线运行测试:\ncap deploy:test_all 通过下面命令来运行任务/命令:\ncap symfony 通过下面命令获取所有可用任务的信息:\ncap -vT Capifony 自动重启Apache\n如果你的服务器安装了APC，你会发现每次 Deploy 完后都需要重启 Apache（php-fpm）来使新代码生效。 Capifony 提供了重启的任务，你只需要进行覆写：\n# Custom(ised) tasks namespace :deploy do # Apache needs to be restarted to make sure that the APC cache is cleared. # This overwrites the :restart task in the parent config which is empty. desc \u0026#34;Restart Apache\u0026#34; task :restart, :except =\u0026gt; { :no_release =\u0026gt; true }, :roles =\u0026gt; :app do run \u0026#34;sudo /etc/init.d/php5-fpm restart\u0026#34; puts \u0026#34;--\u0026gt; PHP successfully restarted\u0026#34;.green end end 更新：Symfony3 发布\n现时（2016-05）Capifony只支持Symfony 1或者Symfony 2的发布，而由于Symfony 3的更改并不大，可以通过修改配置的方式让其兼容。\nSymfony 3主要的更改在于原来位于app目录中的console，logs，cache等目录，现在变成了更加规范的结构，console在bin目录下，而其他几个可写目录则存放在独立的var目录\n对 deploy.rb 配置文件进行以下修改\nset :symfony_console, \u0026#34;bin/console\u0026#34; set :cache_path, \u0026#34;var/cache\u0026#34; set :log_path, \u0026#34;var/logs\u0026#34; set :shared_children, [\u0026#34;var/logs\u0026#34;, web_path + \u0026#34;/files\u0026#34;, web_path + \u0026#34;/uploads\u0026#34;, \u0026#34;vendor\u0026#34;, \u0026#34;var/sessions\u0026#34;, \u0026#34;var/cache\u0026#34;] set :writable_dirs, [\u0026#34;var/cache\u0026#34;, \u0026#34;var/logs\u0026#34;, \u0026#34;var/sessions\u0026#34;] 以上具体的项根据项目的不同可能有所区别。\n","permalink":"https://yplam.com/posts/symfony/symfony-capifony/","summary":"\u003cp\u003e以前一直使用Drupal来搭建网站，由于需要定制的代码量不是很大，所以每次修改都是直接用sftp传到服务器，再到Drupal后台清一下缓存。最近使用Symfony2进行开发，到了发布环节遇到了问题。Symfony代码的发布并不像其他CMS那么方便，因为更新代码后还需要assetic:dump，assets:install，cache:clear等一系列操作，因此每次更新往往需要登录到服务器去更新代码，运行清理cache的一系列命令。 \u003ca href=\"http://capifony.org/\"\u003ecapifony\u003c/a\u003e是针对Symfony开发的应用部署脚本，基于\u003ca href=\"https://github.com/capistrano/capistrano\"\u003eCapistrano\u003c/a\u003e。使用capifony只需要进行简单的配置，就可以很方便的将代码部署到不同的服务器上。\u003c/p\u003e","title":"使用Capifony对Symfony网站进行发布"},{"content":"此笔记记录 Linux 下的一些命令使用技巧，作为工作中的备忘。\n导入数据库时跳过某个表 找出最近修改、创建的文件 自动压缩旧日志文件的shell脚本 Linux 初始化 SSH 会话慢的解决方法 Crontab 控制脚本运行时间段 rsync 只同步匹配的目录文件 Ubuntu 下切换 PHP 版本 ttyACM 插入后被占用问题 P52 Manjaro 外接显示器输出问题 Manjaro zsh 新标签页保持路径 导入数据库时跳过某个表 有时我们需要将某天的数据库备份恢复到内网的机器，用来分析数据，但备份中的某些很大的表对我们的数据分析作用不大，却要占用大量的导入时间（譬如session表，message表），我们可以用简单的sed命令跳过对这些表的插入操作。\nsed \u0026#39;/INSERT INTO `sessions`/d\u0026#39; db.sql \u0026gt; db_new.sql 找出最近修改、创建的文件 以下命令可以用来简单的检查最近目录下哪些文件被修改过。\nfind . -newermt \u0026#34;2013-01-01 00:00:00\u0026#34; ! -newermt \u0026#34;2013-01-02 00:00:00\u0026#34; find . -mtime -10 -mtime +4 自动压缩旧日志文件的shell脚本 logrotate 是 Linux 自带的日志分割压缩工具，但它有个比较让人不爽的缺点就是无法精确的按时间点分割（譬如日志严格的按天）。因此考虑App日志直接按 ×××-Y-m-d.log的方式来按天记录，然后用crontab定时压缩。\n下面是自动gzip压缩多个目录下log文件，并且自动跳过当天文件的shell脚本：\n#!/bin/sh FOLDERS=(/data/logs/view/ /data/logs/search/) NOW=\u0026#34;$(date +\u0026#34;%Y-%m-%d\u0026#34;)\u0026#34; for FOLDER in ${FOLDERS[@]} do echo \u0026#34;Zipping $FOLDER\u0026#34; for FILE in ${FOLDER}*.log do if [[ ! $FILE =~ $NOW ]]; then echo \u0026#34;$FILE\u0026#34; gzip -9 $FILE fi done done Linux 初始化 SSH 会话慢的解决方法 使用ssh登录Linux服务器，就算是在内网环境中，也需要等待比较长的时间才弹出密码输入界面。\n检查：\nssh -vvv 加上 v参数，通过分析ssh打印的debug信息，即可找到时间消耗的环节。\n$ ssh -vvv root@***** OpenSSH_6.6.1, OpenSSL 1.0.1f 6 Jan 2014 debug1: Reading configuration data /etc/ssh/ssh_config debug1: /etc/ssh/ssh_config line 19: Applying options for * debug2: ssh_connect: needpriv 0 debug1: Connecting to @***** port 22. debug1: Connection established. debug3: Incorrect RSA1 identifier debug1: Enabling compatibility mode for protocol 2.0 debug1: Local version string SSH-2.0-OpenSSH_6.6.1p1 Ubuntu-2ubuntu2.8 debug1: Remote protocol version 2.0, remote software version OpenSSH_5.3 debug1: match: OpenSSH_5.3 pat OpenSSH_5* compat 0x0c000000 debug2: fd 3 setting O_NONBLOCK 可能原因：\n服务端 /etc/ssh/sshd_config，修改 \u0026ldquo;UseDNS no\u0026rdquo;\n客户端 /etc/ssh/ssh_config，修改 \u0026ldquo;GSSAPIAuthentication no\u0026rdquo;\nCrontab 控制脚本运行时间段 Cronjob 通常用来在指定时间点运行某个命令（脚本），而有时我们不但需要定时启动脚本，还需要定时关闭，譬如需要在空闲时段备份服务器文件到新机器。\n我们可以使用两个cronjob，一个定时启动，一个定时关闭，或者使用类似下面的脚本，启动后后台运行一个进程，通过获取时间来定时关闭：\n#!/bin/bash rsync ... \u0026amp; pid=$! while /bin/true; do if [ $(date +%H) -ge 8 ]; then kill -TERM $pid exit 0 else sleep 60 fi done rsync 只同步匹配的目录文件 通常我们的图片、文件会根据某中规则（譬如2016-09-09）的格式存储在文件系统中，有时我们需要将适合某个\nrsync -aPv --include=\u0026#39;**/2016-09-09/*\u0026#39; --include=\u0026#39;*/\u0026#39; --exclude=\u0026#39;*\u0026#39; rsync://... Ubuntu 下切换 PHP 版本 偶尔需要维护一些旧项目，而这些项目无法做到php7兼容，此时就需要安装多个PHP版本，并且用类似下面的命令进行切换\nsudo a2dismod php7.1 ; sudo a2enmod php5.6 ; sudo service apache2 restart ; sudo update-alternatives --set php /usr/bin/php5.6 ; sudo update-alternatives --set phar /usr/bin/phar5.6 ; sudo update-alternatives --set phar.phar /usr/bin/phar.phar5.6 ; sudo update-alternatives --set phpize /usr/bin/phpize5.6 ; sudo update-alternatives --set php-config /usr/bin/php-config5.6 ttyACM 插入后被占用问题 最近在调试 STM32 的 USB 功能的过程中发现，将 STM32 插入电脑的 USB 口后 STM32 模拟出来的串口 ttyACM0 会被占用，使用 lsof 也看不出问题，十几秒中后又会自动释放。\n后来将 USB 口收到的数据包 printf 出来后发现是一堆 AT 指令，看了一下系统进程发现一个可以的 ModemManager。\nGoogle 了一下，大概就是 ModemManager 检测到 ttyACM* 接入后会尝试进行通讯，看对方是否为合法的 Modem。\n解决方法：将 ModemManager 禁用，或者将设备 id 加入忽略列表。\nP52 Manjaro 外接显示器输出问题 按官方文档安装相关软件后，修改 /etc/bumblebee/xorg.conf.nvidia\n## ## Generated by mhwd - Manjaro Hardware Detection ## Section \u0026#34;ServerLayout\u0026#34; Identifier \u0026#34;Layout0\u0026#34; Option \u0026#34;AutoAddDevices\u0026#34; \u0026#34;true\u0026#34; EndSection Section \u0026#34;Device\u0026#34; Identifier \u0026#34;Device1\u0026#34; Driver \u0026#34;nvidia\u0026#34; BusID \u0026#34;PCI:1:0:0\u0026#34; VendorName \u0026#34;NVIDIA Corporation\u0026#34; Option \u0026#34;NoLogo\u0026#34; \u0026#34;true\u0026#34; Option \u0026#34;UseEDID\u0026#34; \u0026#34;true\u0026#34; #Option \u0026#34;AllowEmptyInitialConfiguration\u0026#34; #Option \u0026#34;ConnectedMonitor\u0026#34; \u0026#34;DFP\u0026#34; EndSection Manjaro zsh 新标签页保持路径 Manjaro 下默认配置的 zsh，当使用 ctrl-T 打开新标签时，会自动将路径变成用户主目录，会稍微影响效率，修改 ~/.zshrc , 增加下面配置行，可以使新标签依然保持原路径：\n[[ -f /etc/profile.d/vte.sh ]] \u0026amp;\u0026amp; . /etc/profile.d/vte.sh ","permalink":"https://yplam.com/posts/linux/linux-command-collection/","summary":"\u003cp\u003e此笔记记录 Linux 下的一些命令使用技巧，作为工作中的备忘。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"/posts/linux/linux-command-collection/#no1\"\u003e导入数据库时跳过某个表\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/posts/linux/linux-command-collection/#no2\"\u003e找出最近修改、创建的文件\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/posts/linux/linux-command-collection/#no3\"\u003e自动压缩旧日志文件的shell脚本\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/posts/linux/linux-command-collection/#no4\"\u003eLinux 初始化 SSH 会话慢的解决方法\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/posts/linux/linux-command-collection/#no5\"\u003eCrontab 控制脚本运行时间段\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/posts/linux/linux-command-collection/#no6\"\u003ersync 只同步匹配的目录文件\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/posts/linux/linux-command-collection/#no7\"\u003eUbuntu 下切换 PHP 版本\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/posts/linux/linux-command-collection/#no8\"\u003ettyACM 插入后被占用问题\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/posts/linux/linux-command-collection/#no9\"\u003eP52 Manjaro 外接显示器输出问题\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/posts/linux/linux-command-collection/#no10\"\u003eManjaro zsh 新标签页保持路径\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"Linux 小笔记"},{"content":"此笔记基于Linode Centos 5.x 64 bit 系统，安装与配置LNMP服务器环境，此配置主要用于运行Drupal。\n安装Mysql：\nyum install mysql-server mysql-devel 安装编译库：\nmake gcc patch flex bison autoconf libjpeg libjpeg-devel libpng libpng-devel gd gd-devel libxml2 libxml2-devel zlib zlib-devel glib2 glib2-devel bzip2 bzip2-devel libevent libevent-devel ncurses ncurses-devel curl curl-devel openssl openssl-devel libmcrypt libmcrypt-devel mhash-devel libxslt-devel pcre-devel 下载、编译、安装PHP-FPM\nwget http://us.php.net/distributions/php-5.2.17.tar.gz tar -xvzf php-5.2.17.tar.gz wget http://php-fpm.org/downloads/php-5.2.17-fpm-0.5.14.diff.gz gzip -cd php-5.2.17-fpm-0.5.14.diff.gz | patch -d php-5.2.17 -p1 cd php-5.2.17 #对于64位系统注意要指定--with-libdir=lib64 ./configure --enable-fastcgi --enable-fpm --with-mcrypt --with-zlib --enable-mbstring --enable-pdo --with-mysql --with-mysqli --with-curl --disable-debug --with-pic --disable-rpath --enable-inline-optimization --with-bz2 --enable-xml --with-zlib --enable-sockets --enable-sysvsem --enable-sysvshm --enable-pcntl --enable-mbregex --with-mhash --with-xsl --enable-zip --with-pcre-regex --without-pdo-sqlite --with-pdo-mysql --without-sqlite --with-jpeg-dir --with-png-dir --with-gd --with-openssl --with-libdir=lib64 make make install strip /usr/local/bin/php-cgi cp sapi/cgi/fpm/php-fpm /etc/init.d/ chmod +x /etc/init.d/php-fpm wget --no-check-certificate https://github.com/downloads/indeyets/syck/syck-0.70.tar.gz #编译安装syck-0.70（略） pecl install memcache pecl install apc pecl install syck-beta cp php.ini-recommended /usr/local/lib/php.ini 更改php-fpm.conf配置，设置运行用户。位置大概在51、52、63、66行。\n\u0026lt;value name=\u0026#34;owner\u0026#34;\u0026gt;www\u0026lt;/value\u0026gt; \u0026lt;value name=\u0026#34;group\u0026#34;\u0026gt;www\u0026lt;/value\u0026gt; \u0026lt;value name=\u0026#34;user\u0026#34;\u0026gt;www\u0026lt;/value\u0026gt; \u0026lt;value name=\u0026#34;group\u0026#34;\u0026gt;www\u0026lt;/value\u0026gt; 安装nginx\nwget ...nginx ./configure --sbin-path=/usr/local/sbin --with-http_ssl_module --user=www --group=www --with-http_gzip_static_module make make install nginx 与 drupal 的配置可以参考 github项目 https://github.com/yhager/nginx_drupal\n","permalink":"https://yplam.com/posts/linux/centos-php-fpm-52/","summary":"\u003cp\u003e此笔记基于Linode Centos 5.x 64 bit 系统，安装与配置LNMP服务器环境，此配置主要用于运行Drupal。\u003c/p\u003e","title":"Centos Nginx PHP-FPM Mysql 服务器环境配置"},{"content":"\nYPLam 是一名后端工程师，也是一名骑行爱好者，目前就职于广州一家物联网行业公司。\n欢迎与我交流：yplam#yplam.com\n","permalink":"https://yplam.com/about/","summary":"\u003cp\u003e\u003cimg alt=\"yplam\" loading=\"lazy\" src=\"/assets/yplam.jpg\"\u003e\u003c/p\u003e\n\u003cp\u003eYPLam 是一名后端工程师，也是一名骑行爱好者，目前就职于广州一家物联网行业公司。\u003c/p\u003e\n\u003cp\u003e欢迎与我交流：yplam#yplam.com\u003c/p\u003e","title":"关于YPLam"}]