<!DOCTYPE html>
<html>
<section class="g-bg-gray-light-v5"><head>
	
	<title>YP.Lam  | PredictionIO实现论坛广告贴过滤</title>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
	<meta http-equiv="x-ua-compatible" content="ie=edge">

	<link rel="stylesheet" href="//stackpath.bootstrapcdn.com/bootstrap/4.2.1/css/bootstrap.min.css">
	
	<link rel="stylesheet" href="https://yplam.com/scss/unify.min.css">

	

	
	
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-83586141-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

	
</head>

<body>    <div class="container">
        <div class="d-sm-flex text-center">
            <div class="align-self-center ml-auto">
                <ul class="u-list-inline float-right g-py-20">
                    <li class="list-inline-item g-mr-5">
                        <a class="u-link-v5 g-color-gray-dark-v5 g-color-primary--hover" href="/">HOME</a>
                        <i class="g-color-gray-light-v2 g-ml-5">/</i>
                    </li>
                    <li class="list-inline-item g-color-primary g-mr-5">
                        <a class="u-link-v5 g-color-gray-dark-v5 g-color-primary" href="/about/">ABOUT</a>
                        <i class="g-color-gray-light-v2 g-ml-5">/</i>
                    </li>
                    <li class="list-inline-item g-color-primary g-mr-5">
                        <a class="u-link-v5 g-color-gray-dark-v5 g-color-primary" href="https://github.com/yplam">GITHUB</a>
                    </li>
                </ul>
            </div>
        </div>
    </div>
<div class="container" aria-label="Content">
            <div class="g-bg-white">
                <div class="g-px-35 g-py-30 g-mb-30">
<article>
    <ul class="list-inline g-color-gray-dark-v4">
        <li class="list-inline-item mr-0">
            In
             
            
            
            
            <a href="https://yplam.com/tags/machinelearning/">MachineLearning</a>
            
            
            
            
            <a href="https://yplam.com/tags/predictionio/">PredictionIO</a>
            
            
        </li>
        <li class="list-inline-item mx-2">/</li>
        <li class="list-inline-item">Posted 2018-04-28</li>
    </ul>
    <h1 class="g-mb-30">PredictionIO实现论坛广告贴过滤</h1>
    <div class="justify-content-center article-content">
        <p>关注 Apache PredictionIO 已有一段时间，最近需要做一个过滤论坛广告贴的功能，调研了一番市面上提供文本检测的API服务，发现靠谱的公司都比较贵，并且准确率不高（一个可能性是他们使用的训练数据集是互联网上的通用信息，而我们是一个垂直行业论坛，攻击来源也可能是固定的那么若干个），于是尝试自己实现个文本分类器来过滤广告。</p>

<p>关于文本分类，首先想到的就是朴素贝叶斯分类器，其理论清晰简单，并且各大机器学习框架均支持。</p>

<p><strong>朴素贝叶斯分类器</strong> 关于贝叶斯分类器的的原理可以参考以下文档：<a href="http://www.cnblogs.com/leoo2sk/archive/2010/09/17/naive-bayesian-classifier.html">算法杂货铺——分类算法之朴素贝叶斯分类(Naive Bayesian classification)</a></p>

<h3 id="spark实现">Spark实现</h3>

<p>下面是 Spark 贝叶斯分类器的实现，主要流程为:</p>

<ol>
<li>读入数据集</li>
<li>使用 ansj 分词，生成 (label, words) 结构的 dataframe</li>
<li>分割训练集与测试集</li>
<li>创建 HashingTF，IDF，NaiveBayes 的 Pipeline 模型</li>
<li>设置参数矩阵，然后使用 TrainValidationSplit 进行模型训练与参数选择</li>
<li>训练出 bestModal，保存到指定路径</li>
<li>通过最佳模型与测试集得出模型评估</li>
</ol>

<p>实现代码如下：</p>

<pre><code>
package com.yplam

import org.apache.log4j.{Level, Logger}
import org.apache.spark.sql.{Row, SparkSession}
import scopt.OptionParser
import org.ansj.recognition.impl.StopRecognition
import org.ansj.splitWord.analysis.ToAnalysis
import org.apache.spark.ml.{Pipeline, PipelineModel}
import org.apache.spark.ml.classification.NaiveBayes
import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator
import org.apache.spark.ml.feature.{HashingTF, IDF}
import org.apache.spark.ml.tuning.{ParamGridBuilder, TrainValidationSplit}
import org.apache.spark.mllib.evaluation.MulticlassMetrics

object SpamFilterTrainer {

  /**
    * 运行参数
    * @param trainInput 训练数据集路径，格式为 label;content
    */
  case class SpamFilterParams(
               trainInput: String = null,
               modelOutput: String = null
             )

  def main(args: Array[String]): Unit = {
    Logger.getLogger(&quot;org&quot;).setLevel(Level.WARN)
    val spark = SparkSession
      .builder()
      .appName(this.getClass.getSimpleName)
      .master(&quot;local[*]&quot;)
      .getOrCreate()

    val defaultParam = SpamFilterParams()
    val parser = new OptionParser[SpamFilterParams](this.getClass.getSimpleName) {
      head(s&quot;${this.getClass.getSimpleName}: BBS Spam filter.&quot;)
      opt[String](&quot;train&quot;)
        .text(&quot;train input&quot;)
        .action((x, c) =&gt; c.copy(trainInput = x))
        .required()
      opt[String](&quot;output&quot;)
        .text(&quot;model output&quot;)
        .action((x, c) =&gt; c.copy(modelOutput = x))
        .optional()
    }
    parser.parse(args, defaultParam).map { params =&gt;
      run(spark, params.trainInput, params.modelOutput)
      sys.exit(0)
    } getOrElse {
      sys.exit(1)
    }
  }

  def run(spark: SparkSession, trainInput: String, modelOutput: String) : Unit = {
    import spark.implicits._
    import scala.collection.JavaConversions._

    val logger = Logger.getLogger(&quot;app&quot;)
    logger.warn(&quot;Start:&quot; + System.currentTimeMillis().toString)

    val filter = new StopRecognition()
    filter.insertStopWords(&quot; &quot;, &quot;,&quot;)

    // 读取数据集，使用 ansj 分词，生成 (label, words) 结构的 dataframe
    val inputData = spark.sparkContext.textFile(trainInput).map{ line =&gt;
      val splits = line.split(&quot;;&quot;, 2)
      val content = if(splits(1).length &gt; 0){
        ToAnalysis.parse(splits(1)).recognition(filter).getTerms.map(_.getRealName)
      }
      else List(&quot;&quot;)
      (splits(0).toInt, content)
    }.toDF(&quot;label&quot;, &quot;words&quot;)
    inputData.show()

    // 分割训练集与测试集
    val Array(train, test) = inputData.randomSplit(Array(0.9, 0.1), seed = 12345).map(_.cache())

    // 创建 HashingTF，IDF，NaiveBayes 的 Pipeline 模型
    val hashingTF = new HashingTF().setInputCol(&quot;words&quot;).setOutputCol(&quot;rawFeatures&quot;).setNumFeatures(5000)
    val idf = new IDF().setInputCol(&quot;rawFeatures&quot;).setOutputCol(&quot;features&quot;)
    val nb = new NaiveBayes()
      .setModelType(&quot;multinomial&quot;)
      .setFeaturesCol(&quot;features&quot;)
      .setLabelCol(&quot;label&quot;)
    val pipeline = new Pipeline()
      .setStages(Array(hashingTF, idf, nb))

    // 设置参数矩阵，然后使用 TrainValidationSplit 进行模型训练与参数选择
    val paramGrid = new ParamGridBuilder()
      .addGrid(hashingTF.numFeatures, Array(50000, 100000))
      .addGrid(nb.smoothing, Array(1.0))
      .build()

    val trainValidationSplit = new TrainValidationSplit()
      .setEstimator(pipeline)
      .setEvaluator(new MulticlassClassificationEvaluator)
      .setEstimatorParamMaps(paramGrid)
      .setTrainRatio(0.8)


    val model = trainValidationSplit.fit(train)

    logger.warn(&quot;Train end:&quot; + System.currentTimeMillis().toString)

    // 训练出 bestModal，保存到指定路径
    if(modelOutput != null)
      model.bestModel.asInstanceOf[PipelineModel].write.overwrite().save(modelOutput)

    // 将参数与评估结果打印出来
    model.getEstimatorParamMaps.zip(model.validationMetrics).foreach(println)

    val testResult = model.transform(test)
      .select(&quot;features&quot;, &quot;label&quot;, &quot;prediction&quot;)
    testResult.show()
    val testPredictionAndLabels = testResult.select(&quot;prediction&quot;, &quot;label&quot;).rdd.map{
      case Row(prediction: Double, label: Int) =&gt; (prediction, label.toDouble)
    }
    val metrics = new MulticlassMetrics(testPredictionAndLabels)
    println(metrics.confusionMatrix)
    println(&quot;accuracy:&quot; + metrics.accuracy)
    println(&quot;weightedPrecision:&quot; + metrics.weightedPrecision)
    println(&quot;weightedRecall:&quot; + metrics.weightedRecall)

    logger.warn(&quot;Finish:&quot; + System.currentTimeMillis().toString)

    spark.stop()
  }
}


</code></pre>

<p>打包，然后在 Spark 中训练：</p>

<pre><code>
spark-submit --class com.yplam.SpamFilterTrainer spark-scala-playground.jar --train /home/yplam/spark/work/data/bbs --output /home/yplam/spark/work/model/bbs

</code></pre>

<p>结果还算可以，约 93% 的准确率。由于我们之前已经保存好最佳模型，可以编写一个简单的json API接口对外提供服务，而另一个可能更加适合的方式就是将模型移到 PredictionIO 上。</p>

<h3 id="predictionio-简介">PredictionIO 简介</h3>

<p><a href="https://predictionio.apache.org">PredictionIO</a> 是一个开源的机器学习平台，用于构建、评估与发布机器学习算法引擎。PredictionIO 提供事件服务器( Event Server ) 用于接收与保存数据，用于生成训练数据集；引擎模板( engine template )提供各种不同场景应用所需的机器学习算法模板。模型训练出来后 PredictionIO 提供保存与发布服务，发布后的模型可以通过接收 REST API 提供预测结果。对开发者而言，只需要按照 PredictionIO 提供的 DASE 模式实现数据源与预处理(D)、算法(A)、服务(S)、评估指标(E)。PredictionIO 使开发者专注于模型本身，其他的事情它都已经帮你实现。</p>

<p><img src="{{ site.url }}/assets/2018/predictionio-intro.png" alt="PredictionIO" title="PredictionIO" /></p>

<p>上面为 PredictionIO 的单模型引擎框架图。</p>

<p>事件服务器接收与存储事件数据，数据可以有多种格式，譬如对于文本分类器可以是 { &ldquo;entityId&rdquo; : 123, &ldquo;entityType&rdquo; : &ldquo;content&rdquo;, &ldquo;event&rdquo; : &ldquo;$set&rdquo;, &ldquo;properties&rdquo; : { &ldquo;label&rdquo; : &ldquo;spam&rdquo;, &ldquo;text&rdquo; : &ldquo;哈哈哈&rdquo;} }，对于推荐引擎可以是 { &ldquo;entityId&rdquo; : 1, &ldquo;entityType&rdquo; : &ldquo;user&rdquo;, &ldquo;event&rdquo; : &ldquo;buy&rdquo;, &ldquo;targetEntityType&rdquo;:&ldquo;item&rdquo;, &ldquo;targetEntityId&rdquo;:&ldquo;123&rdquo; } 等。关于事件模型的更多内容可以参考 <a href="https://predictionio.apache.org/datacollection/eventmodel/">Events Modeling</a> 。 PredictionIO 提供 REST 接口用于接收事件 多种存储后端，包括mysql，pgsql 跟 hbase。</p>

<h3 id="predictionio-实现">PredictionIO 实现</h3>

<p>由于 PredictionIO 社区提供了大量的引擎模板，因此实现自己模型的最简单方式就是在官方模板的基础上进行修改，譬如 <a href="https://github.com/apache/predictionio-template-text-classifier">Text Classification</a>中就包含基于贝叶斯算法的文本分类器实现，得益于 PredictionIO 的 DASE 模型，我们只需要拷贝此项目，根据项目实际情况做小修改，然后加入 ansj 分词功能，完成。</p>

<p>针对 DataSource，我们需要根据我们模型实际数据结构，设定 entityType，eventNames，以及对 Observation 结构的处理。</p>

<p>针对 Preparator，我们用 ansj 替换原有的分词方式，同时限制了内容长度。</p>

<p>相关代码地址：<a href="https://github.com/yplam/predictionio-spam-detection-cn">https://github.com/yplam/predictionio-spam-detection-cn</a></p>

<p>后记：通过分析“漏网之鱼”的内容，发现已经有针对贝叶斯算法的攻击，也就是在长篇内容中夹入少量垃圾信息，通过只截取标题+内容头尾各500个字的方式，可以有一定的效果提升。</p>
    </div>


</article>
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.6.0/styles/darcula.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.6.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>


                </div>

            </div>
        </div><div id="footer-default" class="g-bg-gray-dark-v1 g-color-white-opacity-0_8 text-center g-py-20">
    <div class="container">
        <div class="g-font-size-default g-mr-10 g-mb-10 g-mb-0--md">
            <p>本站内容如非特别说明，均基于<a rel="license" target="_blank" href="http://creativecommons.org/licenses/by-sa/3.0/">Creative Commons Attribution-Share Alike 3.0 Unported License</a>发布。</p>
        </div>
    </div>
</div></body>
</section>
</html>
