<!DOCTYPE html>
<html>
<section class="g-bg-gray-light-v5"><head>
	
	<title>YP.Lam  | PredictionIO实现论坛广告贴过滤</title>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
	<meta http-equiv="x-ua-compatible" content="ie=edge">

	<link rel="stylesheet" href="//stackpath.bootstrapcdn.com/bootstrap/4.2.1/css/bootstrap.min.css">
	
	<link rel="stylesheet" href="https://yplam.com/scss/unify.min.css">

	
	
  
    
      <script async src="https://www.googletagmanager.com/gtag/js?id=G-960JLZS3KY"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-960JLZS3KY');
        }
      </script>
    
  


	
</head>

<body>    <div class="container">
        <div class="d-sm-flex text-center">
            <div class="align-self-center ml-auto">
                <ul class="u-list-inline float-right g-py-20">
                    <li class="list-inline-item g-mr-5">
                        <a class="u-link-v5 g-color-gray-dark-v5 g-color-primary--hover" href="/">HOME</a>
                        <i class="g-color-gray-light-v2 g-ml-5">/</i>
                    </li>
                    <li class="list-inline-item g-mr-5">
                        <a class="u-link-v5 g-color-gray-dark-v5 g-color-primary--hover" href="/about/">ABOUT</a>
                        <i class="g-color-gray-light-v2 g-ml-5">/</i>
                    </li>
                    <li class="list-inline-item">
                        <a class="u-link-v5 g-color-gray-dark-v5 g-color-primary--hover" href="https://github.com/yplam">GITHUB</a>
                    </li>
                </ul>
            </div>
        </div>
    </div>
<div class="container" aria-label="Content">
            <div class="g-bg-white">
                <div class="g-px-35 g-py-30 g-mb-30">
<article>
    <ul class="list-inline g-color-gray-dark-v4">
        <li class="list-inline-item mr-0">
            In
             
            
            
            
            <a href="https://yplam.com/tags/machinelearning/">MachineLearning</a>
            
            
            
            
            <a href="https://yplam.com/tags/predictionio/">PredictionIO</a>
            
            
        </li>
        <li class="list-inline-item mx-2">/</li>
        <li class="list-inline-item">Posted 2018-04-28</li>
    </ul>
    <h1 class="g-mb-30">PredictionIO实现论坛广告贴过滤</h1>
    <div class="justify-content-center article-content">
        <p>关注 Apache PredictionIO 已有一段时间，最近需要做一个过滤论坛广告贴的功能，调研了一番市面上提供文本检测的API服务，发现靠谱的公司都比较贵，并且准确率不高（一个可能性是他们使用的训练数据集是互联网上的通用信息，而我们是一个垂直行业论坛，攻击来源也可能是固定的那么若干个），于是尝试自己实现个文本分类器来过滤广告。</p>
<p>关于文本分类，首先想到的就是朴素贝叶斯分类器，其理论清晰简单，并且各大机器学习框架均支持。</p>
<p><strong>朴素贝叶斯分类器</strong> 关于贝叶斯分类器的的原理可以参考以下文档：<a href="http://www.cnblogs.com/leoo2sk/archive/2010/09/17/naive-bayesian-classifier.html">算法杂货铺——分类算法之朴素贝叶斯分类(Naive Bayesian classification)</a></p>
<h3 id="spark实现">Spark实现</h3>
<p>下面是 Spark 贝叶斯分类器的实现，主要流程为:</p>
<ol>
<li>读入数据集</li>
<li>使用 ansj 分词，生成 (label, words) 结构的 dataframe</li>
<li>分割训练集与测试集</li>
<li>创建 HashingTF，IDF，NaiveBayes 的 Pipeline 模型</li>
<li>设置参数矩阵，然后使用 TrainValidationSplit 进行模型训练与参数选择</li>
<li>训练出 bestModal，保存到指定路径</li>
<li>通过最佳模型与测试集得出模型评估</li>
</ol>
<p>实现代码如下：</p>
<pre tabindex="0"><code>
package com.yplam

import org.apache.log4j.{Level, Logger}
import org.apache.spark.sql.{Row, SparkSession}
import scopt.OptionParser
import org.ansj.recognition.impl.StopRecognition
import org.ansj.splitWord.analysis.ToAnalysis
import org.apache.spark.ml.{Pipeline, PipelineModel}
import org.apache.spark.ml.classification.NaiveBayes
import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator
import org.apache.spark.ml.feature.{HashingTF, IDF}
import org.apache.spark.ml.tuning.{ParamGridBuilder, TrainValidationSplit}
import org.apache.spark.mllib.evaluation.MulticlassMetrics

object SpamFilterTrainer {

  /**
    * 运行参数
    * @param trainInput 训练数据集路径，格式为 label;content
    */
  case class SpamFilterParams(
               trainInput: String = null,
               modelOutput: String = null
             )

  def main(args: Array[String]): Unit = {
    Logger.getLogger(&#34;org&#34;).setLevel(Level.WARN)
    val spark = SparkSession
      .builder()
      .appName(this.getClass.getSimpleName)
      .master(&#34;local[*]&#34;)
      .getOrCreate()

    val defaultParam = SpamFilterParams()
    val parser = new OptionParser[SpamFilterParams](this.getClass.getSimpleName) {
      head(s&#34;${this.getClass.getSimpleName}: BBS Spam filter.&#34;)
      opt[String](&#34;train&#34;)
        .text(&#34;train input&#34;)
        .action((x, c) =&gt; c.copy(trainInput = x))
        .required()
      opt[String](&#34;output&#34;)
        .text(&#34;model output&#34;)
        .action((x, c) =&gt; c.copy(modelOutput = x))
        .optional()
    }
    parser.parse(args, defaultParam).map { params =&gt;
      run(spark, params.trainInput, params.modelOutput)
      sys.exit(0)
    } getOrElse {
      sys.exit(1)
    }
  }

  def run(spark: SparkSession, trainInput: String, modelOutput: String) : Unit = {
    import spark.implicits._
    import scala.collection.JavaConversions._

    val logger = Logger.getLogger(&#34;app&#34;)
    logger.warn(&#34;Start:&#34; + System.currentTimeMillis().toString)

    val filter = new StopRecognition()
    filter.insertStopWords(&#34; &#34;, &#34;,&#34;)

    // 读取数据集，使用 ansj 分词，生成 (label, words) 结构的 dataframe
    val inputData = spark.sparkContext.textFile(trainInput).map{ line =&gt;
      val splits = line.split(&#34;;&#34;, 2)
      val content = if(splits(1).length &gt; 0){
        ToAnalysis.parse(splits(1)).recognition(filter).getTerms.map(_.getRealName)
      }
      else List(&#34;&#34;)
      (splits(0).toInt, content)
    }.toDF(&#34;label&#34;, &#34;words&#34;)
    inputData.show()

    // 分割训练集与测试集
    val Array(train, test) = inputData.randomSplit(Array(0.9, 0.1), seed = 12345).map(_.cache())

    // 创建 HashingTF，IDF，NaiveBayes 的 Pipeline 模型
    val hashingTF = new HashingTF().setInputCol(&#34;words&#34;).setOutputCol(&#34;rawFeatures&#34;).setNumFeatures(5000)
    val idf = new IDF().setInputCol(&#34;rawFeatures&#34;).setOutputCol(&#34;features&#34;)
    val nb = new NaiveBayes()
      .setModelType(&#34;multinomial&#34;)
      .setFeaturesCol(&#34;features&#34;)
      .setLabelCol(&#34;label&#34;)
    val pipeline = new Pipeline()
      .setStages(Array(hashingTF, idf, nb))

    // 设置参数矩阵，然后使用 TrainValidationSplit 进行模型训练与参数选择
    val paramGrid = new ParamGridBuilder()
      .addGrid(hashingTF.numFeatures, Array(50000, 100000))
      .addGrid(nb.smoothing, Array(1.0))
      .build()

    val trainValidationSplit = new TrainValidationSplit()
      .setEstimator(pipeline)
      .setEvaluator(new MulticlassClassificationEvaluator)
      .setEstimatorParamMaps(paramGrid)
      .setTrainRatio(0.8)


    val model = trainValidationSplit.fit(train)

    logger.warn(&#34;Train end:&#34; + System.currentTimeMillis().toString)

    // 训练出 bestModal，保存到指定路径
    if(modelOutput != null)
      model.bestModel.asInstanceOf[PipelineModel].write.overwrite().save(modelOutput)

    // 将参数与评估结果打印出来
    model.getEstimatorParamMaps.zip(model.validationMetrics).foreach(println)

    val testResult = model.transform(test)
      .select(&#34;features&#34;, &#34;label&#34;, &#34;prediction&#34;)
    testResult.show()
    val testPredictionAndLabels = testResult.select(&#34;prediction&#34;, &#34;label&#34;).rdd.map{
      case Row(prediction: Double, label: Int) =&gt; (prediction, label.toDouble)
    }
    val metrics = new MulticlassMetrics(testPredictionAndLabels)
    println(metrics.confusionMatrix)
    println(&#34;accuracy:&#34; + metrics.accuracy)
    println(&#34;weightedPrecision:&#34; + metrics.weightedPrecision)
    println(&#34;weightedRecall:&#34; + metrics.weightedRecall)

    logger.warn(&#34;Finish:&#34; + System.currentTimeMillis().toString)

    spark.stop()
  }
}
</code></pre><p>打包，然后在 Spark 中训练：</p>
<pre tabindex="0"><code>
spark-submit --class com.yplam.SpamFilterTrainer spark-scala-playground.jar --train /home/yplam/spark/work/data/bbs --output /home/yplam/spark/work/model/bbs
</code></pre><p>结果还算可以，约 93% 的准确率。由于我们之前已经保存好最佳模型，可以编写一个简单的json API接口对外提供服务，而另一个可能更加适合的方式就是将模型移到 PredictionIO 上。</p>
<h3 id="predictionio-简介">PredictionIO 简介</h3>
<p><a href="https://predictionio.apache.org">PredictionIO</a> 是一个开源的机器学习平台，用于构建、评估与发布机器学习算法引擎。PredictionIO 提供事件服务器( Event Server ) 用于接收与保存数据，用于生成训练数据集；引擎模板( engine template )提供各种不同场景应用所需的机器学习算法模板。模型训练出来后 PredictionIO 提供保存与发布服务，发布后的模型可以通过接收 REST API 提供预测结果。对开发者而言，只需要按照 PredictionIO 提供的 DASE 模式实现数据源与预处理(D)、算法(A)、服务(S)、评估指标(E)。PredictionIO 使开发者专注于模型本身，其他的事情它都已经帮你实现。</p>
<p>![PredictionIO]({{ site.url }}/assets/2018/predictionio-intro.png &ldquo;PredictionIO&rdquo;)</p>
<p>上面为 PredictionIO 的单模型引擎框架图。</p>
<p>事件服务器接收与存储事件数据，数据可以有多种格式，譬如对于文本分类器可以是 { &ldquo;entityId&rdquo; : 123, &ldquo;entityType&rdquo; : &ldquo;content&rdquo;, &ldquo;event&rdquo; : &ldquo;$set&rdquo;, &ldquo;properties&rdquo; : { &ldquo;label&rdquo; : &ldquo;spam&rdquo;, &ldquo;text&rdquo; : &ldquo;哈哈哈&rdquo;} }，对于推荐引擎可以是 { &ldquo;entityId&rdquo; : 1, &ldquo;entityType&rdquo; : &ldquo;user&rdquo;, &ldquo;event&rdquo; : &ldquo;buy&rdquo;, &ldquo;targetEntityType&rdquo;:&ldquo;item&rdquo;, &ldquo;targetEntityId&rdquo;:&ldquo;123&rdquo; } 等。关于事件模型的更多内容可以参考 <a href="https://predictionio.apache.org/datacollection/eventmodel/">Events Modeling</a> 。 PredictionIO 提供 REST 接口用于接收事件 多种存储后端，包括mysql，pgsql 跟 hbase。</p>
<h3 id="predictionio-实现">PredictionIO 实现</h3>
<p>由于 PredictionIO 社区提供了大量的引擎模板，因此实现自己模型的最简单方式就是在官方模板的基础上进行修改，譬如 <a href="https://github.com/apache/predictionio-template-text-classifier">Text Classification</a>中就包含基于贝叶斯算法的文本分类器实现，得益于 PredictionIO 的 DASE 模型，我们只需要拷贝此项目，根据项目实际情况做小修改，然后加入 ansj 分词功能，完成。</p>
<p>针对 DataSource，我们需要根据我们模型实际数据结构，设定 entityType，eventNames，以及对 Observation 结构的处理。</p>
<p>针对 Preparator，我们用 ansj 替换原有的分词方式，同时限制了内容长度。</p>
<p>相关代码地址：<a href="https://github.com/yplam/predictionio-spam-detection-cn">https://github.com/yplam/predictionio-spam-detection-cn</a></p>
<p>后记：通过分析“漏网之鱼”的内容，发现已经有针对贝叶斯算法的攻击，也就是在长篇内容中夹入少量垃圾信息，通过只截取标题+内容头尾各500个字的方式，可以有一定的效果提升。</p>
    </div>


</article>
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.5.1/styles/base16/darcula.min.css" integrity="sha512-GfRggx2Wc+POEPR0asMTNTyNug3rWJ9Jp4wxnHZ5VApMOUJRK4cEaRriXsx5tV1DakKHQWQ2noCbuzFiPJaYqA==" crossorigin="anonymous" referrerpolicy="no-referrer" />
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.5.1/highlight.min.js" integrity="sha512-yUUc0qWm2rhM7X0EFe82LNnv2moqArj5nro/w1bi05A09hRVeIZbN6jlMoyu0+4I/Bu4Ck/85JQIU82T82M28w==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlightjs-line-numbers.js/2.8.0/highlightjs-line-numbers.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>


                </div>

            </div>
        </div><div id="footer-default" class="g-bg-gray-dark-v1 g-color-white-opacity-0_8 text-center g-py-20">
    <div class="container">
        <div class="g-font-size-default g-mr-10 g-mb-10 g-mb-0--md">
            <p>本站内容如非特别说明，均基于 <a rel="license" target="_blank" href="http://creativecommons.org/licenses/by-sa/3.0/">Creative Commons Attribution-Share Alike 3.0 Unported License</a> 发布。</p>
        </div>
    </div>
</div></body>
</section>
</html>
